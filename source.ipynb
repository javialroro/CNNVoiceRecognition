{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5793bd2c",
   "metadata": {},
   "source": [
    "# Dataset Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da012a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando train:   0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando train: 100%|██████████| 1200/1200 [00:11<00:00, 102.19it/s]\n",
      "Procesando val: 100%|██████████| 400/400 [00:04<00:00, 95.61it/s] \n",
      "Procesando test: 100%|██████████| 400/400 [00:03<00:00, 103.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Espectrogramas generados y organizados por división.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "CSV_PATH = \"data/ESC-50-master/meta/esc50.csv\"\n",
    "AUDIO_DIR = \"data/ESC-50-master/audio\"\n",
    "OUTPUT_DIR = \"data/spectrograms1/base\"\n",
    "SR = 22050\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Divisiones basadas en folds\n",
    "TRAIN_FOLDS = [1, 2, 3]\n",
    "VAL_FOLDS   = [4]\n",
    "TEST_FOLDS  = [5]\n",
    "\n",
    "# Crear carpetas base\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split), exist_ok=True)\n",
    "\n",
    "# Leer metadatos\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "def wav_to_spectrogram(wav_path, save_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=SR)\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        S_norm = (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "        S_img = (S_norm * 255).astype(np.uint8)\n",
    "\n",
    "        img = Image.fromarray(S_img).resize(IMG_SIZE).convert(\"L\")\n",
    "        img.save(save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error procesando {wav_path}: {e}\")\n",
    "\n",
    "def process_split(split_name, folds):\n",
    "    df_split = df[df[\"fold\"].isin(folds)]\n",
    "    for _, row in tqdm(df_split.iterrows(), total=len(df_split), desc=f\"Procesando {split_name}\"):\n",
    "        file_name = row[\"filename\"]\n",
    "        label = row[\"category\"]\n",
    "\n",
    "        # Crear carpeta por clase\n",
    "        class_dir = os.path.join(OUTPUT_DIR, split_name, label)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        wav_path = os.path.join(AUDIO_DIR, file_name)\n",
    "        save_path = os.path.join(class_dir, file_name.replace(\".wav\", \".png\"))\n",
    "\n",
    "        if not os.path.exists(save_path):\n",
    "            wav_to_spectrogram(wav_path, save_path)\n",
    "\n",
    "# Generar los tres splits\n",
    "process_split(\"train\", TRAIN_FOLDS)\n",
    "process_split(\"val\", VAL_FOLDS)\n",
    "process_split(\"test\", TEST_FOLDS)\n",
    "\n",
    "print(\"✅ Espectrogramas generados y organizados por división.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bda9cb",
   "metadata": {},
   "source": [
    "# Dataset Aumentado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6178f7",
   "metadata": {},
   "source": [
    "# Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c26731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=50, dropout=0.5):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        # --- Bloque 1 ---\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        # --- Bloque 2 ---\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        # --- Bloque 3 ---\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.pool3 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        # --- Normalización por capa (importante para tanh) ---\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # --- Capas densas ---\n",
    "        self.fc1 = nn.Linear(32 * 26 * 26, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Inicialización recomendada para tanh\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normalización ligera antes de tanh para evitar saturación\n",
    "        x = self.pool1(torch.tanh(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.tanh(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.tanh(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a0b11",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Raw Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afe49b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Normalización [-1,1] porque LeNet usa tanh\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/spectrograms1/base/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(\"data/spectrograms1/base/val\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e03b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_173428-gr6grlrd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/gr6grlrd' target=\"_blank\">run_1_opt-Adam_lr-0.001_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/gr6grlrd' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/gr6grlrd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Epoch 1/40 | Train Acc: 0.034 | Val Acc: 0.068 | Train Loss: 3.9295 | Val Loss: 3.6987\n",
      "[Run 1] Epoch 2/40 | Train Acc: 0.057 | Val Acc: 0.087 | Train Loss: 3.7290 | Val Loss: 3.5789\n",
      "[Run 1] Epoch 3/40 | Train Acc: 0.058 | Val Acc: 0.083 | Train Loss: 3.6872 | Val Loss: 3.5148\n",
      "[Run 1] Epoch 4/40 | Train Acc: 0.071 | Val Acc: 0.080 | Train Loss: 3.5888 | Val Loss: 3.4973\n",
      "[Run 1] Epoch 5/40 | Train Acc: 0.068 | Val Acc: 0.095 | Train Loss: 3.5743 | Val Loss: 3.4500\n",
      "[Run 1] Epoch 6/40 | Train Acc: 0.083 | Val Acc: 0.138 | Train Loss: 3.5056 | Val Loss: 3.4336\n",
      "[Run 1] Epoch 7/40 | Train Acc: 0.079 | Val Acc: 0.105 | Train Loss: 3.4617 | Val Loss: 3.4517\n",
      "[Run 1] Epoch 8/40 | Train Acc: 0.100 | Val Acc: 0.122 | Train Loss: 3.4467 | Val Loss: 3.3805\n",
      "[Run 1] Epoch 9/40 | Train Acc: 0.116 | Val Acc: 0.128 | Train Loss: 3.3888 | Val Loss: 3.3584\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.104 | Val Acc: 0.105 | Train Loss: 3.3447 | Val Loss: 3.3703\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.108 | Val Acc: 0.140 | Train Loss: 3.3120 | Val Loss: 3.3091\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.139 | Val Acc: 0.135 | Train Loss: 3.2629 | Val Loss: 3.3335\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.152 | Val Acc: 0.130 | Train Loss: 3.1895 | Val Loss: 3.3361\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.145 | Val Acc: 0.145 | Train Loss: 3.1597 | Val Loss: 3.2760\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.170 | Val Acc: 0.130 | Train Loss: 3.1479 | Val Loss: 3.3171\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.151 | Val Acc: 0.172 | Train Loss: 3.1620 | Val Loss: 3.2346\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.174 | Val Acc: 0.180 | Train Loss: 3.0907 | Val Loss: 3.2147\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.191 | Val Acc: 0.130 | Train Loss: 3.0181 | Val Loss: 3.3587\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.204 | Val Acc: 0.193 | Train Loss: 2.9437 | Val Loss: 3.1718\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.218 | Val Acc: 0.182 | Train Loss: 2.8582 | Val Loss: 3.1488\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.242 | Val Acc: 0.203 | Train Loss: 2.8284 | Val Loss: 3.1544\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.233 | Val Acc: 0.237 | Train Loss: 2.8495 | Val Loss: 3.0934\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.248 | Val Acc: 0.207 | Train Loss: 2.7860 | Val Loss: 3.1260\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.274 | Val Acc: 0.220 | Train Loss: 2.7258 | Val Loss: 3.1127\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.312 | Val Acc: 0.205 | Train Loss: 2.6124 | Val Loss: 3.0813\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.334 | Val Acc: 0.212 | Train Loss: 2.5118 | Val Loss: 3.1145\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.330 | Val Acc: 0.217 | Train Loss: 2.5102 | Val Loss: 3.0668\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.335 | Val Acc: 0.220 | Train Loss: 2.5009 | Val Loss: 3.0655\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.364 | Val Acc: 0.220 | Train Loss: 2.4403 | Val Loss: 3.0892\n",
      "[Run 1] Early stopping triggered at epoch 29.\n",
      "✅ [Run 1] Mejor Val Acc: 0.237\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▂▂▂▂▃▂▃▃▄▃▄▃▄▄▅▅▅▅▆▆▇▇▇▇█</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▂▂▄▃▃▃▃▄▄▄▄▄▅▆▄▆▆▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▅▅▄▄▄▄▄▄▃▄▃▃▄▂▂▂▁▂▂▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.2375</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>lr</td><td>0.00034</td></tr><tr><td>train_acc</td><td>0.36417</td></tr><tr><td>train_loss</td><td>2.44026</td></tr><tr><td>val_acc</td><td>0.22</td></tr><tr><td>val_loss</td><td>3.08921</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-Adam_lr-0.001_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/gr6grlrd' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/gr6grlrd</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_173428-gr6grlrd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_173548-bg14rfzm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/bg14rfzm' target=\"_blank\">run_2_opt-Adam_lr-0.0005_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/bg14rfzm' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/bg14rfzm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Epoch 1/40 | Train Acc: 0.037 | Val Acc: 0.065 | Train Loss: 3.9351 | Val Loss: 3.7292\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.081 | Val Acc: 0.062 | Train Loss: 3.6508 | Val Loss: 3.6222\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.086 | Val Acc: 0.102 | Train Loss: 3.5910 | Val Loss: 3.5173\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.113 | Val Acc: 0.072 | Train Loss: 3.4666 | Val Loss: 3.5185\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.139 | Val Acc: 0.138 | Train Loss: 3.3611 | Val Loss: 3.3752\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.175 | Val Acc: 0.128 | Train Loss: 3.1466 | Val Loss: 3.3270\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.191 | Val Acc: 0.165 | Train Loss: 3.0949 | Val Loss: 3.2721\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.242 | Val Acc: 0.152 | Train Loss: 2.9327 | Val Loss: 3.2244\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.301 | Val Acc: 0.240 | Train Loss: 2.7776 | Val Loss: 3.1278\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.352 | Val Acc: 0.210 | Train Loss: 2.6358 | Val Loss: 3.1583\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.355 | Val Acc: 0.188 | Train Loss: 2.5431 | Val Loss: 3.1404\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.418 | Val Acc: 0.203 | Train Loss: 2.4200 | Val Loss: 3.0788\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.443 | Val Acc: 0.217 | Train Loss: 2.3450 | Val Loss: 3.1716\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.468 | Val Acc: 0.240 | Train Loss: 2.2402 | Val Loss: 3.0249\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.521 | Val Acc: 0.230 | Train Loss: 2.1405 | Val Loss: 3.0433\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.542 | Val Acc: 0.228 | Train Loss: 2.0534 | Val Loss: 3.0403\n",
      "[Run 2] Early stopping triggered at epoch 16.\n",
      "✅ [Run 2] Mejor Val Acc: 0.240\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>███████▄▄▄▄▄▄▄▄▁</td></tr><tr><td>train_acc</td><td>▁▂▂▂▂▃▃▄▅▅▅▆▇▇██</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▄▄▃▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▁▃▁▄▄▅▅█▇▆▇▇███</td></tr><tr><td>val_loss</td><td>█▇▆▆▄▄▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.24</td></tr><tr><td>epoch</td><td>16</td></tr><tr><td>lr</td><td>0.00024</td></tr><tr><td>train_acc</td><td>0.5425</td></tr><tr><td>train_loss</td><td>2.05337</td></tr><tr><td>val_acc</td><td>0.2275</td></tr><tr><td>val_loss</td><td>3.04026</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-Adam_lr-0.0005_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/bg14rfzm' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/bg14rfzm</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_173548-bg14rfzm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_173637-ubqxyriu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/ubqxyriu' target=\"_blank\">run_3_opt-Adam_lr-0.001_bs-64</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/ubqxyriu' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/ubqxyriu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Epoch 1/40 | Train Acc: 0.042 | Val Acc: 0.052 | Train Loss: 3.8913 | Val Loss: 3.6283\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.062 | Val Acc: 0.075 | Train Loss: 3.6672 | Val Loss: 3.6555\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.076 | Val Acc: 0.100 | Train Loss: 3.5469 | Val Loss: 3.4305\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.094 | Val Acc: 0.077 | Train Loss: 3.4478 | Val Loss: 3.5750\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.126 | Val Acc: 0.095 | Train Loss: 3.3213 | Val Loss: 3.3700\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.135 | Val Acc: 0.092 | Train Loss: 3.2323 | Val Loss: 3.4694\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.173 | Val Acc: 0.145 | Train Loss: 3.1337 | Val Loss: 3.2705\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.190 | Val Acc: 0.115 | Train Loss: 3.0740 | Val Loss: 3.2601\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.232 | Val Acc: 0.138 | Train Loss: 2.9410 | Val Loss: 3.3745\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.247 | Val Acc: 0.155 | Train Loss: 2.9035 | Val Loss: 3.1471\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.261 | Val Acc: 0.155 | Train Loss: 2.8337 | Val Loss: 3.1567\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.302 | Val Acc: 0.158 | Train Loss: 2.6740 | Val Loss: 3.2120\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.349 | Val Acc: 0.188 | Train Loss: 2.5402 | Val Loss: 3.1522\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.367 | Val Acc: 0.193 | Train Loss: 2.4707 | Val Loss: 3.1121\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.429 | Val Acc: 0.175 | Train Loss: 2.3475 | Val Loss: 3.1528\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.437 | Val Acc: 0.180 | Train Loss: 2.2594 | Val Loss: 3.0842\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.471 | Val Acc: 0.170 | Train Loss: 2.1777 | Val Loss: 3.0224\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.489 | Val Acc: 0.212 | Train Loss: 2.1408 | Val Loss: 3.0193\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.515 | Val Acc: 0.217 | Train Loss: 2.0407 | Val Loss: 3.0363\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.540 | Val Acc: 0.235 | Train Loss: 1.9454 | Val Loss: 2.9663\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.572 | Val Acc: 0.220 | Train Loss: 1.8518 | Val Loss: 2.9512\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.606 | Val Acc: 0.225 | Train Loss: 1.7728 | Val Loss: 2.9888\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.624 | Val Acc: 0.225 | Train Loss: 1.7094 | Val Loss: 2.9763\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.633 | Val Acc: 0.242 | Train Loss: 1.6647 | Val Loss: 2.9800\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.679 | Val Acc: 0.228 | Train Loss: 1.5607 | Val Loss: 2.9447\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.692 | Val Acc: 0.255 | Train Loss: 1.5212 | Val Loss: 2.9213\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.708 | Val Acc: 0.247 | Train Loss: 1.4403 | Val Loss: 2.9366\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.718 | Val Acc: 0.245 | Train Loss: 1.4097 | Val Loss: 2.9595\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.723 | Val Acc: 0.230 | Train Loss: 1.3391 | Val Loss: 2.9397\n",
      "[Run 3] Epoch 30/40 | Train Acc: 0.748 | Val Acc: 0.228 | Train Loss: 1.3091 | Val Loss: 2.9342\n",
      "[Run 3] Epoch 31/40 | Train Acc: 0.744 | Val Acc: 0.250 | Train Loss: 1.2869 | Val Loss: 2.9153\n",
      "[Run 3] Epoch 32/40 | Train Acc: 0.776 | Val Acc: 0.235 | Train Loss: 1.2097 | Val Loss: 2.9237\n",
      "[Run 3] Epoch 33/40 | Train Acc: 0.782 | Val Acc: 0.255 | Train Loss: 1.1756 | Val Loss: 2.9062\n",
      "[Run 3] Early stopping triggered at epoch 33.\n",
      "✅ [Run 3] Mejor Val Acc: 0.255\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▂▂▂▄▃▄▅▅▅▆▆▅▅▅▇▇▇▇▇▇█▇███▇▇█▇█</td></tr><tr><td>val_loss</td><td>██▆▇▅▆▄▄▅▃▃▄▃▃▃▃▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.255</td></tr><tr><td>epoch</td><td>33</td></tr><tr><td>lr</td><td>0.00024</td></tr><tr><td>train_acc</td><td>0.78167</td></tr><tr><td>train_loss</td><td>1.17559</td></tr><tr><td>val_acc</td><td>0.255</td></tr><tr><td>val_loss</td><td>2.90617</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-Adam_lr-0.001_bs-64</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/ubqxyriu' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/ubqxyriu</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_173637-ubqxyriu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_173820-h57o529u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/h57o529u' target=\"_blank\">run_4_opt-SGD_lr-0.01_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/h57o529u' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/h57o529u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Epoch 1/40 | Train Acc: 0.051 | Val Acc: 0.072 | Train Loss: 3.8103 | Val Loss: 3.5579\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.062 | Val Acc: 0.102 | Train Loss: 3.6062 | Val Loss: 3.4179\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.084 | Val Acc: 0.110 | Train Loss: 3.4747 | Val Loss: 3.4026\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.093 | Val Acc: 0.087 | Train Loss: 3.4965 | Val Loss: 3.4209\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.102 | Val Acc: 0.102 | Train Loss: 3.4517 | Val Loss: 3.3115\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.104 | Val Acc: 0.098 | Train Loss: 3.3477 | Val Loss: 3.4356\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.122 | Val Acc: 0.120 | Train Loss: 3.2667 | Val Loss: 3.3543\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.164 | Val Acc: 0.140 | Train Loss: 3.1502 | Val Loss: 3.2528\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.168 | Val Acc: 0.147 | Train Loss: 3.1375 | Val Loss: 3.2193\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.188 | Val Acc: 0.182 | Train Loss: 3.0133 | Val Loss: 3.1430\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.201 | Val Acc: 0.190 | Train Loss: 2.9572 | Val Loss: 3.1439\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.194 | Val Acc: 0.195 | Train Loss: 2.9383 | Val Loss: 3.0885\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.237 | Val Acc: 0.175 | Train Loss: 2.8108 | Val Loss: 3.1154\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.260 | Val Acc: 0.235 | Train Loss: 2.6862 | Val Loss: 2.9347\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.294 | Val Acc: 0.182 | Train Loss: 2.6218 | Val Loss: 3.3223\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.323 | Val Acc: 0.235 | Train Loss: 2.4997 | Val Loss: 2.9181\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.357 | Val Acc: 0.223 | Train Loss: 2.3937 | Val Loss: 2.9235\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.381 | Val Acc: 0.240 | Train Loss: 2.3021 | Val Loss: 2.8185\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.419 | Val Acc: 0.207 | Train Loss: 2.1876 | Val Loss: 3.1093\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.467 | Val Acc: 0.207 | Train Loss: 2.1009 | Val Loss: 3.1337\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.470 | Val Acc: 0.302 | Train Loss: 1.9930 | Val Loss: 2.8069\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.507 | Val Acc: 0.312 | Train Loss: 1.9442 | Val Loss: 2.7231\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.520 | Val Acc: 0.263 | Train Loss: 1.8258 | Val Loss: 2.7639\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.537 | Val Acc: 0.278 | Train Loss: 1.8113 | Val Loss: 2.8303\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.574 | Val Acc: 0.290 | Train Loss: 1.6462 | Val Loss: 2.7097\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.618 | Val Acc: 0.278 | Train Loss: 1.5703 | Val Loss: 2.7811\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.620 | Val Acc: 0.275 | Train Loss: 1.5115 | Val Loss: 2.7243\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.640 | Val Acc: 0.263 | Train Loss: 1.4524 | Val Loss: 2.7676\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.673 | Val Acc: 0.275 | Train Loss: 1.3815 | Val Loss: 2.7454\n",
      "[Run 4] Early stopping triggered at epoch 29.\n",
      "✅ [Run 4] Mejor Val Acc: 0.312\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▆▆▆▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▁▂▂▂▃▃▄▄▅▄▆▄▆▅▆▅▅██▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▇▇▆▇▆▅▅▅▅▄▄▃▆▃▃▂▄▄▂▁▁▂▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.3125</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>lr</td><td>0.00343</td></tr><tr><td>train_acc</td><td>0.67333</td></tr><tr><td>train_loss</td><td>1.38152</td></tr><tr><td>val_acc</td><td>0.275</td></tr><tr><td>val_loss</td><td>2.74535</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-SGD_lr-0.01_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/h57o529u' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/h57o529u</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_173820-h57o529u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_173953-wjpsdhz7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/wjpsdhz7' target=\"_blank\">run_5_opt-SGD_lr-0.001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/wjpsdhz7' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/wjpsdhz7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Epoch 1/40 | Train Acc: 0.035 | Val Acc: 0.100 | Train Loss: 3.8702 | Val Loss: 3.6151\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.079 | Val Acc: 0.120 | Train Loss: 3.6342 | Val Loss: 3.5556\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.125 | Val Acc: 0.122 | Train Loss: 3.4576 | Val Loss: 3.4018\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.147 | Val Acc: 0.147 | Train Loss: 3.3080 | Val Loss: 3.3948\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.201 | Val Acc: 0.145 | Train Loss: 3.1169 | Val Loss: 3.2962\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.259 | Val Acc: 0.115 | Train Loss: 2.9525 | Val Loss: 3.5551\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.301 | Val Acc: 0.168 | Train Loss: 2.7603 | Val Loss: 3.2648\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.405 | Val Acc: 0.190 | Train Loss: 2.5829 | Val Loss: 3.1689\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.468 | Val Acc: 0.215 | Train Loss: 2.3906 | Val Loss: 3.0755\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.543 | Val Acc: 0.233 | Train Loss: 2.2448 | Val Loss: 3.0441\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.584 | Val Acc: 0.263 | Train Loss: 2.1065 | Val Loss: 2.9798\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.613 | Val Acc: 0.245 | Train Loss: 2.0446 | Val Loss: 2.9857\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.634 | Val Acc: 0.292 | Train Loss: 1.9170 | Val Loss: 2.9388\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.681 | Val Acc: 0.287 | Train Loss: 1.8095 | Val Loss: 2.9265\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.689 | Val Acc: 0.278 | Train Loss: 1.7316 | Val Loss: 2.8845\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.742 | Val Acc: 0.292 | Train Loss: 1.6319 | Val Loss: 2.8483\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.763 | Val Acc: 0.287 | Train Loss: 1.5471 | Val Loss: 2.8694\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.791 | Val Acc: 0.273 | Train Loss: 1.4627 | Val Loss: 2.9033\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.807 | Val Acc: 0.318 | Train Loss: 1.3667 | Val Loss: 2.8372\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.834 | Val Acc: 0.300 | Train Loss: 1.3197 | Val Loss: 2.8421\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.859 | Val Acc: 0.312 | Train Loss: 1.2440 | Val Loss: 2.8023\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.853 | Val Acc: 0.305 | Train Loss: 1.2228 | Val Loss: 2.8691\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.868 | Val Acc: 0.325 | Train Loss: 1.1358 | Val Loss: 2.8221\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.872 | Val Acc: 0.292 | Train Loss: 1.1106 | Val Loss: 2.8594\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.909 | Val Acc: 0.310 | Train Loss: 1.0475 | Val Loss: 2.7927\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.915 | Val Acc: 0.338 | Train Loss: 0.9900 | Val Loss: 2.7693\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.903 | Val Acc: 0.307 | Train Loss: 0.9705 | Val Loss: 2.8242\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.921 | Val Acc: 0.338 | Train Loss: 0.9227 | Val Loss: 2.7751\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.927 | Val Acc: 0.328 | Train Loss: 0.8944 | Val Loss: 2.7996\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.923 | Val Acc: 0.310 | Train Loss: 0.8877 | Val Loss: 2.7783\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.938 | Val Acc: 0.318 | Train Loss: 0.8316 | Val Loss: 2.7865\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.943 | Val Acc: 0.323 | Train Loss: 0.8043 | Val Loss: 2.7847\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.955 | Val Acc: 0.333 | Train Loss: 0.7761 | Val Loss: 2.7607\n",
      "[Run 5] Early stopping triggered at epoch 33.\n",
      "✅ [Run 5] Mejor Val Acc: 0.338\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▂▂▁▃▄▄▅▆▅▇▇▆▇▇▆▇▇▇▇█▇▇█▇██▇▇██</td></tr><tr><td>val_loss</td><td>██▆▆▅█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.3375</td></tr><tr><td>epoch</td><td>33</td></tr><tr><td>lr</td><td>0.00024</td></tr><tr><td>train_acc</td><td>0.955</td></tr><tr><td>train_loss</td><td>0.77609</td></tr><tr><td>val_acc</td><td>0.3325</td></tr><tr><td>val_loss</td><td>2.76072</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/wjpsdhz7' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/wjpsdhz7</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_173953-wjpsdhz7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === ENTRENAR 5 RUNS (versión mejorada con tanh, BN y scheduler) ===\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === EXPERIMENTOS ===\n",
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,  \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001, \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "# === CICLO DE EXPERIMENTOS ===\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    wandb.init(\n",
    "        project=\"esc50-lenet\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    # --- Loaders dinámicos según batch size ---\n",
    "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_data, batch_size=config.batch_size)\n",
    "\n",
    "    # --- Modelo ---\n",
    "    model = LeNet5(num_classes=len(train_data.classes)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # --- Optimizador y Scheduler ---\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "\n",
    "    # --- Entrenamiento ---\n",
    "    EPOCHS = 40\n",
    "    best_val_acc = 0.0\n",
    "    patience = 6\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # --- Validación ---\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # --- Log y monitor ---\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # --- Early stopping ---\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/lenet5_tanh_bn_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter > patience:\n",
    "            print(f\"[Run {i}] Early stopping triggered at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e1870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162231-hq5ddrea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea' target=\"_blank\">run_1_opt-Adam_lr-0.001_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Epoch 1/40 | Train Acc: 0.046 | Val Acc: 0.110\n",
      "[Run 1] Epoch 2/40 | Train Acc: 0.097 | Val Acc: 0.113\n",
      "[Run 1] Epoch 3/40 | Train Acc: 0.130 | Val Acc: 0.143\n",
      "[Run 1] Epoch 4/40 | Train Acc: 0.161 | Val Acc: 0.167\n",
      "[Run 1] Epoch 5/40 | Train Acc: 0.189 | Val Acc: 0.203\n",
      "[Run 1] Epoch 6/40 | Train Acc: 0.236 | Val Acc: 0.210\n",
      "[Run 1] Epoch 7/40 | Train Acc: 0.271 | Val Acc: 0.223\n",
      "[Run 1] Epoch 8/40 | Train Acc: 0.264 | Val Acc: 0.270\n",
      "[Run 1] Epoch 9/40 | Train Acc: 0.305 | Val Acc: 0.260\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.368 | Val Acc: 0.277\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.386 | Val Acc: 0.267\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.442 | Val Acc: 0.290\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.473 | Val Acc: 0.300\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.501 | Val Acc: 0.297\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.546 | Val Acc: 0.283\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.591 | Val Acc: 0.307\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.634 | Val Acc: 0.290\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.671 | Val Acc: 0.290\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.710 | Val Acc: 0.313\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.750 | Val Acc: 0.317\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.754 | Val Acc: 0.310\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.799 | Val Acc: 0.307\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.826 | Val Acc: 0.323\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.846 | Val Acc: 0.343\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.856 | Val Acc: 0.327\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.876 | Val Acc: 0.347\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.876 | Val Acc: 0.287\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.896 | Val Acc: 0.310\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.911 | Val Acc: 0.323\n",
      "[Run 1] Epoch 30/40 | Train Acc: 0.921 | Val Acc: 0.353\n",
      "[Run 1] Epoch 31/40 | Train Acc: 0.933 | Val Acc: 0.327\n",
      "[Run 1] Epoch 32/40 | Train Acc: 0.944 | Val Acc: 0.337\n",
      "[Run 1] Epoch 33/40 | Train Acc: 0.948 | Val Acc: 0.330\n",
      "[Run 1] Epoch 34/40 | Train Acc: 0.949 | Val Acc: 0.333\n",
      "[Run 1] Epoch 35/40 | Train Acc: 0.966 | Val Acc: 0.323\n",
      "[Run 1] Epoch 36/40 | Train Acc: 0.968 | Val Acc: 0.340\n",
      "[Run 1] Epoch 37/40 | Train Acc: 0.974 | Val Acc: 0.327\n",
      "[Run 1] Epoch 38/40 | Train Acc: 0.976 | Val Acc: 0.327\n",
      "[Run 1] Epoch 39/40 | Train Acc: 0.974 | Val Acc: 0.317\n",
      "[Run 1] Epoch 40/40 | Train Acc: 0.980 | Val Acc: 0.310\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▄▄▄▆▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇█▇█▆▇▇█▇█▇▇▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▃▃▂▂▂▁▂▁▁▁▁▁▁▂▂▂▂▁▂▂▃▂▃▃▃▃▃▃▄▄▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.35333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.98</td></tr><tr><td>train_loss</td><td>0.17417</td></tr><tr><td>val_acc</td><td>0.31</td></tr><tr><td>val_loss</td><td>3.0484</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-Adam_lr-0.001_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162231-hq5ddrea/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162435-xrkc46ot</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot' target=\"_blank\">run_2_opt-Adam_lr-0.0005_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Epoch 1/40 | Train Acc: 0.049 | Val Acc: 0.080\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.096 | Val Acc: 0.080\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.120 | Val Acc: 0.150\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.160 | Val Acc: 0.187\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.205 | Val Acc: 0.180\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.254 | Val Acc: 0.237\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.291 | Val Acc: 0.230\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.340 | Val Acc: 0.267\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.393 | Val Acc: 0.283\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.458 | Val Acc: 0.273\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.515 | Val Acc: 0.297\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.551 | Val Acc: 0.300\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.622 | Val Acc: 0.337\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.655 | Val Acc: 0.297\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.686 | Val Acc: 0.323\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.732 | Val Acc: 0.323\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.779 | Val Acc: 0.333\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.802 | Val Acc: 0.323\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.821 | Val Acc: 0.317\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.854 | Val Acc: 0.323\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.852 | Val Acc: 0.330\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.876 | Val Acc: 0.320\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.903 | Val Acc: 0.323\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.907 | Val Acc: 0.310\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.917 | Val Acc: 0.317\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.933 | Val Acc: 0.317\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.940 | Val Acc: 0.323\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.949 | Val Acc: 0.343\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.957 | Val Acc: 0.333\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.964 | Val Acc: 0.317\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.968 | Val Acc: 0.337\n",
      "[Run 2] Epoch 32/40 | Train Acc: 0.977 | Val Acc: 0.323\n",
      "[Run 2] Epoch 33/40 | Train Acc: 0.979 | Val Acc: 0.327\n",
      "[Run 2] Epoch 34/40 | Train Acc: 0.979 | Val Acc: 0.340\n",
      "[Run 2] Epoch 35/40 | Train Acc: 0.976 | Val Acc: 0.320\n",
      "[Run 2] Epoch 36/40 | Train Acc: 0.986 | Val Acc: 0.330\n",
      "[Run 2] Epoch 37/40 | Train Acc: 0.988 | Val Acc: 0.313\n",
      "[Run 2] Epoch 38/40 | Train Acc: 0.981 | Val Acc: 0.303\n",
      "[Run 2] Epoch 39/40 | Train Acc: 0.989 | Val Acc: 0.320\n",
      "[Run 2] Epoch 40/40 | Train Acc: 0.991 | Val Acc: 0.320\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▃▄▄▅▅▆▆▆▇▇█▇▇▇█▇▇▇█▇▇▇▇▇▇██▇█▇██▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.34333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.99143</td></tr><tr><td>train_loss</td><td>0.17701</td></tr><tr><td>val_acc</td><td>0.32</td></tr><tr><td>val_loss</td><td>2.81106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-Adam_lr-0.0005_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162435-xrkc46ot/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162651-kpvuo89q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q' target=\"_blank\">run_3_opt-Adam_lr-0.001_bs-64</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Epoch 1/40 | Train Acc: 0.049 | Val Acc: 0.103\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.094 | Val Acc: 0.100\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.126 | Val Acc: 0.150\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.156 | Val Acc: 0.170\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.187 | Val Acc: 0.197\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.219 | Val Acc: 0.173\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.228 | Val Acc: 0.190\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.261 | Val Acc: 0.227\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.311 | Val Acc: 0.280\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.314 | Val Acc: 0.253\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.371 | Val Acc: 0.267\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.399 | Val Acc: 0.277\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.472 | Val Acc: 0.297\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.489 | Val Acc: 0.307\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.543 | Val Acc: 0.280\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.576 | Val Acc: 0.337\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.621 | Val Acc: 0.303\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.676 | Val Acc: 0.337\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.691 | Val Acc: 0.320\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.716 | Val Acc: 0.323\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.721 | Val Acc: 0.323\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.751 | Val Acc: 0.323\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.777 | Val Acc: 0.327\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.800 | Val Acc: 0.333\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.831 | Val Acc: 0.337\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.843 | Val Acc: 0.343\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.849 | Val Acc: 0.360\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.861 | Val Acc: 0.373\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.865 | Val Acc: 0.337\n",
      "[Run 3] Epoch 30/40 | Train Acc: 0.873 | Val Acc: 0.353\n",
      "[Run 3] Epoch 31/40 | Train Acc: 0.892 | Val Acc: 0.373\n",
      "[Run 3] Epoch 32/40 | Train Acc: 0.905 | Val Acc: 0.340\n",
      "[Run 3] Epoch 33/40 | Train Acc: 0.918 | Val Acc: 0.350\n",
      "[Run 3] Epoch 34/40 | Train Acc: 0.925 | Val Acc: 0.360\n",
      "[Run 3] Epoch 35/40 | Train Acc: 0.917 | Val Acc: 0.357\n",
      "[Run 3] Epoch 36/40 | Train Acc: 0.931 | Val Acc: 0.353\n",
      "[Run 3] Epoch 37/40 | Train Acc: 0.946 | Val Acc: 0.360\n",
      "[Run 3] Epoch 38/40 | Train Acc: 0.942 | Val Acc: 0.343\n",
      "[Run 3] Epoch 39/40 | Train Acc: 0.947 | Val Acc: 0.333\n",
      "[Run 3] Epoch 40/40 | Train Acc: 0.950 | Val Acc: 0.343\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▃▃▄▆▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██▇▇█▇▇██▇█▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.37333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.95</td></tr><tr><td>train_loss</td><td>0.32957</td></tr><tr><td>val_acc</td><td>0.34333</td></tr><tr><td>val_loss</td><td>2.63842</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-Adam_lr-0.001_bs-64</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162651-kpvuo89q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162908-sk1okcp1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1' target=\"_blank\">run_4_opt-SGD_lr-0.01_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Epoch 1/40 | Train Acc: 0.053 | Val Acc: 0.070\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.114 | Val Acc: 0.123\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.156 | Val Acc: 0.157\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.195 | Val Acc: 0.187\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.229 | Val Acc: 0.227\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.238 | Val Acc: 0.270\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.272 | Val Acc: 0.243\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.284 | Val Acc: 0.257\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.304 | Val Acc: 0.260\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.344 | Val Acc: 0.280\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.373 | Val Acc: 0.277\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.372 | Val Acc: 0.297\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.431 | Val Acc: 0.297\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.484 | Val Acc: 0.300\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.496 | Val Acc: 0.293\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.571 | Val Acc: 0.330\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.606 | Val Acc: 0.337\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.664 | Val Acc: 0.330\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.671 | Val Acc: 0.330\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.746 | Val Acc: 0.333\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.776 | Val Acc: 0.323\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.818 | Val Acc: 0.350\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.861 | Val Acc: 0.343\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.863 | Val Acc: 0.323\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.904 | Val Acc: 0.330\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.911 | Val Acc: 0.340\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.936 | Val Acc: 0.317\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.942 | Val Acc: 0.340\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.962 | Val Acc: 0.323\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.967 | Val Acc: 0.330\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.970 | Val Acc: 0.330\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.975 | Val Acc: 0.310\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.976 | Val Acc: 0.330\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.985 | Val Acc: 0.330\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.986 | Val Acc: 0.313\n",
      "[Run 4] Epoch 36/40 | Train Acc: 0.984 | Val Acc: 0.353\n",
      "[Run 4] Epoch 37/40 | Train Acc: 0.993 | Val Acc: 0.333\n",
      "[Run 4] Epoch 38/40 | Train Acc: 0.992 | Val Acc: 0.340\n",
      "[Run 4] Epoch 39/40 | Train Acc: 0.989 | Val Acc: 0.347\n",
      "[Run 4] Epoch 40/40 | Train Acc: 0.993 | Val Acc: 0.343\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇██████████████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▄▅▆▅▆▆▆▆▇▇▇▇▇█▇▇█▇██▇▇█▇█▇▇▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▂▂▂▃▂▃▂▃▃▄▃▄▄▄▄▄▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.35333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.99286</td></tr><tr><td>train_loss</td><td>0.09715</td></tr><tr><td>val_acc</td><td>0.34333</td></tr><tr><td>val_loss</td><td>2.93547</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-SGD_lr-0.01_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162908-sk1okcp1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_163129-p4f9num9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9' target=\"_blank\">run_5_opt-SGD_lr-0.001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Epoch 1/40 | Train Acc: 0.039 | Val Acc: 0.067\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.056 | Val Acc: 0.083\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.083 | Val Acc: 0.090\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.107 | Val Acc: 0.100\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.130 | Val Acc: 0.147\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.159 | Val Acc: 0.157\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.185 | Val Acc: 0.180\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.210 | Val Acc: 0.210\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.216 | Val Acc: 0.217\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.257 | Val Acc: 0.227\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.256 | Val Acc: 0.223\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.265 | Val Acc: 0.243\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.266 | Val Acc: 0.270\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.281 | Val Acc: 0.257\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.302 | Val Acc: 0.247\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.302 | Val Acc: 0.273\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.323 | Val Acc: 0.277\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.322 | Val Acc: 0.287\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.346 | Val Acc: 0.267\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.356 | Val Acc: 0.303\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.356 | Val Acc: 0.283\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.364 | Val Acc: 0.307\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.377 | Val Acc: 0.323\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.383 | Val Acc: 0.300\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.386 | Val Acc: 0.313\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.418 | Val Acc: 0.300\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.417 | Val Acc: 0.313\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.422 | Val Acc: 0.317\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.431 | Val Acc: 0.330\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.437 | Val Acc: 0.333\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.454 | Val Acc: 0.310\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.466 | Val Acc: 0.327\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.482 | Val Acc: 0.313\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.499 | Val Acc: 0.313\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.498 | Val Acc: 0.327\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.511 | Val Acc: 0.327\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.517 | Val Acc: 0.313\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.535 | Val Acc: 0.340\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.556 | Val Acc: 0.327\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.553 | Val Acc: 0.317\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▂▃▃▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇█▇▇▇▇▇██▇█▇▇██▇██▇</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.34</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.55286</td></tr><tr><td>train_loss</td><td>1.79318</td></tr><tr><td>val_acc</td><td>0.31667</td></tr><tr><td>val_loss</td><td>2.46487</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_163129-p4f9num9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Transformaciones ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/spectrograms1_split/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(\"data/spectrograms1_split/val\", transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "# === LISTA DE EXPERIMENTOS ===\n",
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 32, \"weight_decay\": 0},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 0.0001},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 64, \"weight_decay\": 0},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,  \"batch_size\": 32, \"weight_decay\": 0.0001},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001, \"batch_size\": 16, \"weight_decay\": 0},\n",
    "]\n",
    "\n",
    "# === ENTRENAR 5 RUNS ===\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    wandb.init(\n",
    "        project=\"esc50-lenet\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    # Actualizar batch size dinámicamente\n",
    "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_data, batch_size=config.batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LeNet5(num_classes=len(train_data.classes)).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    EPOCHS = 40\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1}/{EPOCHS} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f\"models/lenet_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444df42",
   "metadata": {},
   "source": [
    "## Dataset Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26467187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando TRAIN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando VAL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando TEST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset aumentado generado con SpecAugment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "BASE_DIR = \"data/spectrograms1/base\"\n",
    "AUG_DIR = \"data/spectrograms1/augmented\"\n",
    "\n",
    "# Parámetros de SpecAugment (según Park et al., 2019)\n",
    "FREQ_MASK_PARAM = 20      # ancho máximo de bandas de frecuencia a enmascarar\n",
    "TIME_MASK_PARAM = 25      # ancho máximo de regiones de tiempo a enmascarar\n",
    "NUM_FREQ_MASKS = 2        # número de máscaras de frecuencia\n",
    "NUM_TIME_MASKS = 2        # número de máscaras de tiempo\n",
    "\n",
    "# Crear carpetas base del dataset aumentado\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(AUG_DIR, split), exist_ok=True)\n",
    "\n",
    "\n",
    "# === FUNCIÓN PRINCIPAL ===\n",
    "def apply_specaugment(image_path, save_path):\n",
    "    \"\"\"Aplica SpecAugment a una imagen de espectrograma (grises).\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"L\")\n",
    "        spec = np.array(img)\n",
    "\n",
    "        # --- Frequency masking (vertical) ---\n",
    "        for _ in range(NUM_FREQ_MASKS):\n",
    "            f = random.randint(0, FREQ_MASK_PARAM)\n",
    "            if f == 0:\n",
    "                continue\n",
    "            f0 = random.randint(0, spec.shape[0] - f)\n",
    "            spec[f0:f0 + f, :] = 0  # borra bandas de frecuencia\n",
    "\n",
    "        # --- Time masking (horizontal) ---\n",
    "        for _ in range(NUM_TIME_MASKS):\n",
    "            t = random.randint(0, TIME_MASK_PARAM)\n",
    "            if t == 0:\n",
    "                continue\n",
    "            t0 = random.randint(0, spec.shape[1] - t)\n",
    "            spec[:, t0:t0 + t] = 0  # borra regiones de tiempo\n",
    "\n",
    "        aug_img = Image.fromarray(spec)\n",
    "        aug_img.save(save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error procesando {image_path}: {e}\")\n",
    "\n",
    "\n",
    "# === RECORRER TODAS LAS PARTICIONES ===\n",
    "def process_split(split_name):\n",
    "    base_split_path = os.path.join(BASE_DIR, split_name)\n",
    "    aug_split_path = os.path.join(AUG_DIR, split_name)\n",
    "\n",
    "    # recorrer las clases\n",
    "    for class_name in os.listdir(base_split_path):\n",
    "        class_base_path = os.path.join(base_split_path, class_name)\n",
    "        class_aug_path = os.path.join(aug_split_path, class_name)\n",
    "        os.makedirs(class_aug_path, exist_ok=True)\n",
    "\n",
    "        # recorrer las imágenes\n",
    "        images = [f for f in os.listdir(class_base_path) if f.endswith(\".png\")]\n",
    "\n",
    "        for img_file in tqdm(images, desc=f\"{split_name}/{class_name}\", leave=False):\n",
    "            src_path = os.path.join(class_base_path, img_file)\n",
    "            dst_path = os.path.join(class_aug_path, img_file)\n",
    "\n",
    "            # aplicar SpecAugment y guardar\n",
    "            apply_specaugment(src_path, dst_path)\n",
    "\n",
    "\n",
    "# === EJECUCIÓN ===\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"\\nProcesando {split.upper()}...\")\n",
    "    process_split(split)\n",
    "\n",
    "print(\"\\n✅ Dataset aumentado generado con SpecAugment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a85f92b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javialroro/miniconda3/envs/ml/lib/python3.13/site-packages/torchaudio/functional/functional.py:582: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n",
      "Procesando train: 100%|██████████| 1200/1200 [00:18<00:00, 64.59it/s]\n",
      "Procesando val: 100%|██████████| 400/400 [00:06<00:00, 64.95it/s]\n",
      "Procesando test: 100%|██████████| 400/400 [00:05<00:00, 67.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset aumentado con SpecAugment generado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "CSV_PATH = \"data/ESC-50-master/meta/esc50.csv\"\n",
    "AUDIO_DIR = \"data/ESC-50-master/audio\"\n",
    "OUTPUT_DIR = \"data/spectrograms1/augmented1\"\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "N_MELS = 128\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Folds por división\n",
    "TRAIN_FOLDS = [1, 2, 3]\n",
    "VAL_FOLDS   = [4]\n",
    "TEST_FOLDS  = [5]\n",
    "\n",
    "# === TRANSFORMACIONES ===\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_mels=N_MELS\n",
    ")\n",
    "\n",
    "specaugment = torchaudio.transforms.SpecAugment(\n",
    "    freq_mask_param=15,      # enmascaramiento de frecuencia\n",
    "    time_mask_param=35,      # enmascaramiento de tiempo\n",
    "    n_freq_masks=2,\n",
    "    n_time_masks=2\n",
    ")\n",
    "\n",
    "# === FUNCIONES ===\n",
    "def save_spec_image(tensor, save_path):\n",
    "    \"\"\"Convierte un tensor de espectrograma a imagen PNG.\"\"\"\n",
    "    tensor = tensor.squeeze().numpy()\n",
    "    tensor_db = torchaudio.functional.amplitude_to_DB(\n",
    "        torch.tensor(tensor), multiplier=10, amin=1e-10, db_multiplier=0\n",
    "    ).numpy()\n",
    "    tensor_norm = (tensor_db - tensor_db.min()) / (tensor_db.max() - tensor_db.min())\n",
    "    img = (tensor_norm * 255).astype(np.uint8)\n",
    "    Image.fromarray(img).resize(IMG_SIZE).convert(\"L\").save(save_path)\n",
    "\n",
    "def process_split(df, split_name):\n",
    "    \"\"\"Procesa un subconjunto del dataset aplicando SpecAugment.\"\"\"\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Procesando {split_name}\"):\n",
    "        file_name = row[\"filename\"]\n",
    "        label = row[\"category\"]\n",
    "\n",
    "        class_dir = os.path.join(OUTPUT_DIR, split_name, label)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        wav_path = os.path.join(AUDIO_DIR, file_name)\n",
    "        save_path = os.path.join(class_dir, file_name.replace(\".wav\", \".png\"))\n",
    "\n",
    "        try:\n",
    "            # Cargar audio\n",
    "            waveform, sr = torchaudio.load(wav_path)\n",
    "            if sr != SAMPLE_RATE:\n",
    "                waveform = torchaudio.functional.resample(waveform, sr, SAMPLE_RATE)\n",
    "\n",
    "            # Crear mel-espectrograma\n",
    "            mel_spec = mel_transform(waveform)\n",
    "\n",
    "            # Aplicar SpecAugment\n",
    "            augmented_spec = specaugment(mel_spec)\n",
    "\n",
    "            # Guardar como imagen\n",
    "            save_spec_image(augmented_spec, save_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error con {wav_path}: {e}\")\n",
    "\n",
    "# === MAIN ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "splits = {\n",
    "    \"train\": df[df[\"fold\"].isin(TRAIN_FOLDS)],\n",
    "    \"val\":   df[df[\"fold\"].isin(VAL_FOLDS)],\n",
    "    \"test\":  df[df[\"fold\"].isin(TEST_FOLDS)]\n",
    "}\n",
    "\n",
    "for split_name, subset in splits.items():\n",
    "    process_split(subset, split_name)\n",
    "\n",
    "print(\"\\n✅ Dataset aumentado con SpecAugment generado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637852f",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Augmented Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4087f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/spectrograms1/augmented\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==============================\n",
    "# TRANSFORMACIONES\n",
    "# ==============================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3ad64dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181523-3ewxjhu6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6' target=\"_blank\">run_1_opt-Adam_lr-0.001_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Epoch 1/40 | Train Acc: 0.048 | Val Acc: 0.058 | Train Loss: 3.7720 | Val Loss: 3.6313\n",
      "[Run 1] Epoch 2/40 | Train Acc: 0.072 | Val Acc: 0.090 | Train Loss: 3.5444 | Val Loss: 3.5044\n",
      "[Run 1] Epoch 3/40 | Train Acc: 0.098 | Val Acc: 0.083 | Train Loss: 3.4440 | Val Loss: 3.4397\n",
      "[Run 1] Epoch 4/40 | Train Acc: 0.132 | Val Acc: 0.120 | Train Loss: 3.3288 | Val Loss: 3.3846\n",
      "[Run 1] Epoch 5/40 | Train Acc: 0.141 | Val Acc: 0.133 | Train Loss: 3.2640 | Val Loss: 3.3304\n",
      "[Run 1] Epoch 6/40 | Train Acc: 0.138 | Val Acc: 0.140 | Train Loss: 3.2181 | Val Loss: 3.2802\n",
      "[Run 1] Epoch 7/40 | Train Acc: 0.160 | Val Acc: 0.170 | Train Loss: 3.1562 | Val Loss: 3.2503\n",
      "[Run 1] Epoch 8/40 | Train Acc: 0.172 | Val Acc: 0.140 | Train Loss: 3.1305 | Val Loss: 3.2696\n",
      "[Run 1] Epoch 9/40 | Train Acc: 0.194 | Val Acc: 0.128 | Train Loss: 3.0511 | Val Loss: 3.2524\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.204 | Val Acc: 0.130 | Train Loss: 2.9838 | Val Loss: 3.2430\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.219 | Val Acc: 0.140 | Train Loss: 2.9362 | Val Loss: 3.2626\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.247 | Val Acc: 0.150 | Train Loss: 2.8694 | Val Loss: 3.2395\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.261 | Val Acc: 0.175 | Train Loss: 2.7973 | Val Loss: 3.1705\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.282 | Val Acc: 0.160 | Train Loss: 2.7306 | Val Loss: 3.1579\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.294 | Val Acc: 0.185 | Train Loss: 2.6747 | Val Loss: 3.1475\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.324 | Val Acc: 0.203 | Train Loss: 2.5764 | Val Loss: 3.1343\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.350 | Val Acc: 0.170 | Train Loss: 2.4961 | Val Loss: 3.1788\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.375 | Val Acc: 0.160 | Train Loss: 2.3998 | Val Loss: 3.1873\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.400 | Val Acc: 0.177 | Train Loss: 2.3404 | Val Loss: 3.1302\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.431 | Val Acc: 0.190 | Train Loss: 2.2514 | Val Loss: 3.1296\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.453 | Val Acc: 0.198 | Train Loss: 2.1718 | Val Loss: 3.1221\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.473 | Val Acc: 0.195 | Train Loss: 2.1216 | Val Loss: 3.1269\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.521 | Val Acc: 0.190 | Train Loss: 2.0341 | Val Loss: 3.1419\n",
      "[Run 1] Early stopping triggered at epoch 23.\n",
      "✅ [Run 1] Mejor Val Acc: 0.203\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>███████▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▂▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▃▂▄▅▅▆▅▄▄▅▅▇▆▇█▆▆▇▇██▇</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▃▃▃▃▃▃▃▂▁▁▁▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.2025</td></tr><tr><td>epoch</td><td>23</td></tr><tr><td>lr</td><td>0.00049</td></tr><tr><td>train_acc</td><td>0.52083</td></tr><tr><td>train_loss</td><td>2.03415</td></tr><tr><td>val_acc</td><td>0.19</td></tr><tr><td>val_loss</td><td>3.14192</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-Adam_lr-0.001_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181523-3ewxjhu6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181631-jvqdd1fb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb' target=\"_blank\">run_2_opt-Adam_lr-0.0005_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Epoch 1/40 | Train Acc: 0.043 | Val Acc: 0.052 | Train Loss: 3.8529 | Val Loss: 3.7090\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.082 | Val Acc: 0.068 | Train Loss: 3.5996 | Val Loss: 3.5511\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.147 | Val Acc: 0.110 | Train Loss: 3.4077 | Val Loss: 3.4791\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.174 | Val Acc: 0.125 | Train Loss: 3.2858 | Val Loss: 3.4160\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.231 | Val Acc: 0.163 | Train Loss: 3.1617 | Val Loss: 3.3699\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.286 | Val Acc: 0.145 | Train Loss: 3.0103 | Val Loss: 3.3281\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.345 | Val Acc: 0.138 | Train Loss: 2.8824 | Val Loss: 3.3323\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.368 | Val Acc: 0.170 | Train Loss: 2.7625 | Val Loss: 3.2698\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.438 | Val Acc: 0.170 | Train Loss: 2.5974 | Val Loss: 3.2337\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.487 | Val Acc: 0.203 | Train Loss: 2.4682 | Val Loss: 3.2199\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.544 | Val Acc: 0.185 | Train Loss: 2.3319 | Val Loss: 3.1940\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.574 | Val Acc: 0.193 | Train Loss: 2.2301 | Val Loss: 3.1899\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.597 | Val Acc: 0.188 | Train Loss: 2.1403 | Val Loss: 3.1952\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.616 | Val Acc: 0.172 | Train Loss: 2.0400 | Val Loss: 3.1872\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.661 | Val Acc: 0.193 | Train Loss: 1.9276 | Val Loss: 3.1541\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.703 | Val Acc: 0.203 | Train Loss: 1.8124 | Val Loss: 3.1598\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.714 | Val Acc: 0.195 | Train Loss: 1.7108 | Val Loss: 3.1498\n",
      "[Run 2] Early stopping triggered at epoch 17.\n",
      "✅ [Run 2] Mejor Val Acc: 0.203\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>███████▄▄▄▄▄▄▄▄▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▃▄▄▄▅▆▆▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▂▄▄▆▅▅▆▆█▇█▇▇███</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.2025</td></tr><tr><td>epoch</td><td>17</td></tr><tr><td>lr</td><td>0.00024</td></tr><tr><td>train_acc</td><td>0.71417</td></tr><tr><td>train_loss</td><td>1.71079</td></tr><tr><td>val_acc</td><td>0.195</td></tr><tr><td>val_loss</td><td>3.14979</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-Adam_lr-0.0005_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181631-jvqdd1fb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181724-qbtr0d4y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y' target=\"_blank\">run_3_opt-Adam_lr-0.001_bs-64</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Epoch 1/40 | Train Acc: 0.043 | Val Acc: 0.058 | Train Loss: 3.8034 | Val Loss: 3.6058\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.091 | Val Acc: 0.092 | Train Loss: 3.5447 | Val Loss: 3.4712\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.136 | Val Acc: 0.102 | Train Loss: 3.4030 | Val Loss: 3.3887\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.169 | Val Acc: 0.135 | Train Loss: 3.2755 | Val Loss: 3.3231\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.218 | Val Acc: 0.133 | Train Loss: 3.1499 | Val Loss: 3.2539\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.241 | Val Acc: 0.147 | Train Loss: 3.0370 | Val Loss: 3.2316\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.282 | Val Acc: 0.158 | Train Loss: 2.8991 | Val Loss: 3.1809\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.324 | Val Acc: 0.165 | Train Loss: 2.7669 | Val Loss: 3.1441\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.366 | Val Acc: 0.163 | Train Loss: 2.6337 | Val Loss: 3.1664\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.425 | Val Acc: 0.172 | Train Loss: 2.4882 | Val Loss: 3.1387\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.478 | Val Acc: 0.165 | Train Loss: 2.3758 | Val Loss: 3.1374\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.510 | Val Acc: 0.155 | Train Loss: 2.2650 | Val Loss: 3.1412\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.550 | Val Acc: 0.168 | Train Loss: 2.1278 | Val Loss: 3.1063\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.568 | Val Acc: 0.165 | Train Loss: 2.0408 | Val Loss: 3.1384\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.632 | Val Acc: 0.163 | Train Loss: 1.9175 | Val Loss: 3.1161\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.664 | Val Acc: 0.170 | Train Loss: 1.7933 | Val Loss: 3.1537\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.702 | Val Acc: 0.170 | Train Loss: 1.6758 | Val Loss: 3.1255\n",
      "[Run 3] Early stopping triggered at epoch 17.\n",
      "✅ [Run 3] Mejor Val Acc: 0.172\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>███████▄▄▄▄▄▄▄▄▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▅▄▄▃▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▆▆▆▇█▇██▇██▇██</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▃▂▂▂▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.1725</td></tr><tr><td>epoch</td><td>17</td></tr><tr><td>lr</td><td>0.00049</td></tr><tr><td>train_acc</td><td>0.70167</td></tr><tr><td>train_loss</td><td>1.67584</td></tr><tr><td>val_acc</td><td>0.17</td></tr><tr><td>val_loss</td><td>3.12547</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-Adam_lr-0.001_bs-64</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181724-qbtr0d4y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181818-j3lr4kiq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq' target=\"_blank\">run_4_opt-SGD_lr-0.01_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Epoch 1/40 | Train Acc: 0.030 | Val Acc: 0.055 | Train Loss: 3.8714 | Val Loss: 3.7322\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.069 | Val Acc: 0.107 | Train Loss: 3.6054 | Val Loss: 3.4959\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.114 | Val Acc: 0.138 | Train Loss: 3.4025 | Val Loss: 3.4217\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.163 | Val Acc: 0.147 | Train Loss: 3.2395 | Val Loss: 3.3113\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.180 | Val Acc: 0.138 | Train Loss: 3.1176 | Val Loss: 3.2709\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.217 | Val Acc: 0.125 | Train Loss: 2.9857 | Val Loss: 3.3042\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.239 | Val Acc: 0.175 | Train Loss: 2.9135 | Val Loss: 3.1644\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.273 | Val Acc: 0.177 | Train Loss: 2.7594 | Val Loss: 3.1090\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.338 | Val Acc: 0.168 | Train Loss: 2.5928 | Val Loss: 3.1228\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.374 | Val Acc: 0.190 | Train Loss: 2.4608 | Val Loss: 3.0803\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.407 | Val Acc: 0.198 | Train Loss: 2.3363 | Val Loss: 3.0756\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.458 | Val Acc: 0.168 | Train Loss: 2.1976 | Val Loss: 3.0809\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.497 | Val Acc: 0.177 | Train Loss: 2.0757 | Val Loss: 3.0507\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.540 | Val Acc: 0.188 | Train Loss: 1.9183 | Val Loss: 3.0512\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.574 | Val Acc: 0.172 | Train Loss: 1.8057 | Val Loss: 3.1272\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.612 | Val Acc: 0.182 | Train Loss: 1.6817 | Val Loss: 3.0522\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.668 | Val Acc: 0.203 | Train Loss: 1.5133 | Val Loss: 3.0164\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.738 | Val Acc: 0.182 | Train Loss: 1.3499 | Val Loss: 3.0610\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.757 | Val Acc: 0.175 | Train Loss: 1.2552 | Val Loss: 3.0540\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.783 | Val Acc: 0.193 | Train Loss: 1.1626 | Val Loss: 3.0529\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.812 | Val Acc: 0.198 | Train Loss: 1.0500 | Val Loss: 3.0404\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.836 | Val Acc: 0.203 | Train Loss: 0.9570 | Val Loss: 3.0874\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.836 | Val Acc: 0.203 | Train Loss: 0.9112 | Val Loss: 3.1102\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.871 | Val Acc: 0.175 | Train Loss: 0.8196 | Val Loss: 3.1616\n",
      "[Run 4] Early stopping triggered at epoch 24.\n",
      "✅ [Run 4] Mejor Val Acc: 0.203\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▅▅▄▇▇▆▇█▆▇▇▇▇█▇▇████▇</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▄▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.2025</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>lr</td><td>0.00343</td></tr><tr><td>train_acc</td><td>0.87083</td></tr><tr><td>train_loss</td><td>0.81957</td></tr><tr><td>val_acc</td><td>0.175</td></tr><tr><td>val_loss</td><td>3.1616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-SGD_lr-0.01_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181818-j3lr4kiq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181930-6zc8df1r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r' target=\"_blank\">run_5_opt-SGD_lr-0.001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Epoch 1/40 | Train Acc: 0.030 | Val Acc: 0.033 | Train Loss: 3.8964 | Val Loss: 3.8509\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.052 | Val Acc: 0.065 | Train Loss: 3.7887 | Val Loss: 3.7278\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.077 | Val Acc: 0.070 | Train Loss: 3.6700 | Val Loss: 3.6275\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.102 | Val Acc: 0.098 | Train Loss: 3.5662 | Val Loss: 3.5627\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.113 | Val Acc: 0.102 | Train Loss: 3.4968 | Val Loss: 3.5199\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.136 | Val Acc: 0.100 | Train Loss: 3.4331 | Val Loss: 3.4835\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.162 | Val Acc: 0.128 | Train Loss: 3.3715 | Val Loss: 3.4573\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.168 | Val Acc: 0.135 | Train Loss: 3.3202 | Val Loss: 3.4273\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.192 | Val Acc: 0.140 | Train Loss: 3.2668 | Val Loss: 3.4107\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.212 | Val Acc: 0.145 | Train Loss: 3.2205 | Val Loss: 3.3904\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.199 | Val Acc: 0.147 | Train Loss: 3.1988 | Val Loss: 3.3770\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.233 | Val Acc: 0.142 | Train Loss: 3.1552 | Val Loss: 3.3622\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.244 | Val Acc: 0.163 | Train Loss: 3.1179 | Val Loss: 3.3390\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.240 | Val Acc: 0.158 | Train Loss: 3.0899 | Val Loss: 3.3280\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.259 | Val Acc: 0.165 | Train Loss: 3.0391 | Val Loss: 3.3157\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.277 | Val Acc: 0.165 | Train Loss: 3.0109 | Val Loss: 3.3039\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.292 | Val Acc: 0.168 | Train Loss: 2.9642 | Val Loss: 3.2855\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.309 | Val Acc: 0.170 | Train Loss: 2.9411 | Val Loss: 3.2824\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.304 | Val Acc: 0.165 | Train Loss: 2.9185 | Val Loss: 3.2721\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.307 | Val Acc: 0.163 | Train Loss: 2.8912 | Val Loss: 3.2679\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.318 | Val Acc: 0.163 | Train Loss: 2.8666 | Val Loss: 3.2556\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.323 | Val Acc: 0.158 | Train Loss: 2.8452 | Val Loss: 3.2533\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.330 | Val Acc: 0.158 | Train Loss: 2.8209 | Val Loss: 3.2512\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.334 | Val Acc: 0.170 | Train Loss: 2.7976 | Val Loss: 3.2268\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.344 | Val Acc: 0.163 | Train Loss: 2.7624 | Val Loss: 3.2317\n",
      "[Run 5] Early stopping triggered at epoch 25.\n",
      "✅ [Run 5] Mejor Val Acc: 0.170\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▃▄▅▄▆▆▆▇▇▇█▇███████▇▇██</td></tr><tr><td>val_loss</td><td>█▇▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.17</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>lr</td><td>0.00034</td></tr><tr><td>train_acc</td><td>0.34417</td></tr><tr><td>train_loss</td><td>2.76239</td></tr><tr><td>val_acc</td><td>0.1625</td></tr><tr><td>val_loss</td><td>3.23165</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181930-6zc8df1r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,  \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001, \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# CICLO DE ENTRENAMIENTO (IGUAL AL DATASET 1)\n",
    "# ==============================\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    wandb.init(\n",
    "        project=\"esc50-lenet-augmented\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_data, batch_size=config.batch_size)\n",
    "\n",
    "    model = LeNet5(num_classes=len(train_data.classes)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "\n",
    "    EPOCHS = 40\n",
    "    best_val_acc = 0.0\n",
    "    patience = 6\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # === VALIDACIÓN ===\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # === Early stopping ===\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/lenet5_aug_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > patience:\n",
    "                print(f\"[Run {i}] Early stopping triggered at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f633eb",
   "metadata": {},
   "source": [
    "# Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca37970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Type, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utilidades de convolución\n",
    "# -------------------------\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"Conv 3×3 con padding=1, sin bias (BN lo compensa).\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"Conv 1×1 para proyección en atajos (ajustar canales/stride).\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Bloque residual \"básico\"\n",
    "# -------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Estructura:\n",
    "        Conv3x3 → BN → ReLU → Conv3x3 → BN → (Suma con atajo) → ReLU\n",
    "    Donde el atajo (identity) puede incluir una proyección 1×1 si cambia\n",
    "    la resolución (stride > 1) o el número de canales.\n",
    "    \"\"\"\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1   = norm_layer(planes)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2   = norm_layer(planes)\n",
    "\n",
    "        self.downsample = downsample  # Proyección para el atajo, si aplica\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x  # Atajo\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Alinear dimensiones del atajo si cambió stride o # de canales\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# -----------\n",
    "# ResNet base\n",
    "# -----------\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Constructor general de ResNet con BasicBlock y configuración [2,2,2,2].\n",
    "    Parámetros clave:\n",
    "        - small_input=True: conv1=3×3 s=1 y sin MaxPool (mejor para 64–224 px).\n",
    "        - small_input=False: conv1=7×7 s=2 + MaxPool (clásico de ResNet).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[BasicBlock],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 50,\n",
    "        in_channels: int = 1,\n",
    "        small_input: bool = True,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "\n",
    "        # Capa inicial: variante \"small_input\" recomendada para espectrogramas\n",
    "        if small_input:\n",
    "            # Preserva más detalle inicial (sin MaxPool temprano)\n",
    "            self.conv1   = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.maxpool = nn.Identity()\n",
    "        else:\n",
    "            # Estilo ResNet clásico para entradas grandes\n",
    "            self.conv1   = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.bn1  = norm_layer(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Stages: [64, 128, 256, 512] con [2, 2, 2, 2] bloques\n",
    "        self.layer1 = self._make_layer(block,  64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        # Cabeza de clasificación\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Global Average Pooling\n",
    "        self.fc      = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Inicialización recomendada para ReLU/BN\n",
    "        self._init_weights()\n",
    "\n",
    "    def _make_layer(self, block: Type[BasicBlock], planes: int, blocks: int, stride: int = 1) -> nn.Sequential:\n",
    "        \"\"\"\n",
    "        Crea un stage con 'blocks' bloques. El primer bloque puede hacer downsample\n",
    "        (stride=2) para reducir resolución y duplicar canales.\n",
    "        \"\"\"\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "\n",
    "        # Si cambia resolución o # de canales, proyectamos el atajo (1×1)\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _init_weights(self) -> None:\n",
    "        \"\"\"Inicialización Kaiming para conv; constantes para BN; normal para FC.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Entrada → conv1 → BN → ReLU → (posible MaxPool/Identity)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Stages residuales\n",
    "        x = self.layer1(x)  # 64\n",
    "        x = self.layer2(x)  # 128\n",
    "        x = self.layer3(x)  # 256\n",
    "        x = self.layer4(x)  # 512\n",
    "\n",
    "        # Cabeza\n",
    "        x = self.avgpool(x)           # (B, 512, 1, 1)\n",
    "        x = torch.flatten(x, 1)       # (B, 512)\n",
    "        x = self.fc(x)                # (B, num_classes)\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Fábrica de ResNet-18\n",
    "# -------------------------\n",
    "def resnet18_audio(num_classes: int = 50, in_channels: int = 1, small_input: bool = True) -> ResNet:\n",
    "    \"\"\"\n",
    "    Retorna una ResNet-18 lista para espectrogramas:\n",
    "        - num_classes: # de clases del dataset (ESC-50 → 50)\n",
    "        - in_channels: 1 para grises; 3 si usas RGB (replicar canal)\n",
    "        - small_input: True recomendado para ~128–224 px\n",
    "    \"\"\"\n",
    "    return ResNet(\n",
    "        block=BasicBlock,\n",
    "        layers=[2, 2, 2, 2],\n",
    "        num_classes=num_classes,\n",
    "        in_channels=in_channels,\n",
    "        small_input=small_input,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf849e1",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Raw Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# ENTRENAMIENTO - MODELO B (TU ResNet-18 Audio)\n",
    "# Dataset: data/spectrograms1/base (RAW, sin augment)\n",
    "# ===========================================\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Configuración y utilidades\n",
    "# -----------------------------\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Data (RAW, sin SpecAugment)\n",
    "# -----------------------------\n",
    "DATA_DIR = \"data/spectrograms1/base\"\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])   # [-1,1] coherente con A\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\",   transform=transform)\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "print(\"Clases:\", num_classes)\n",
    "\n",
    "# Estos se re-crean según el batch_size de cada experimento\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_data,   batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Experimentos (estilo similar a A)\n",
    "# -----------------------------\n",
    "experiments = [\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 3e-4,  \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 1e-4,  \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",   \"lr\": 0.01,  \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",   \"lr\": 0.005, \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 5e-4,  \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "EPOCHS   = 40\n",
    "PATIENCE = 6\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Loop de entreno multi-run\n",
    "# -----------------------------\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    # Inicia W&B (si no querés subir a la nube, agrega mode=\"offline\")\n",
    "    wandb.init(\n",
    "        project=\"esc50-modelB\",\n",
    "        name=f\"resnet18B_run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp,\n",
    "        # mode=\"offline\",\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    # Loaders con batch_size del experimento\n",
    "    train_loader = DataLoader(\n",
    "        train_data, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    "    )\n",
    "    val_loader   = DataLoader(\n",
    "        val_data,   batch_size=config.batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # ------- Modelo (TU ResNet-18) -------\n",
    "    model = resnet18_audio(num_classes=num_classes, in_channels=1, small_input=True).to(device)\n",
    "\n",
    "    # Criterio\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizador\n",
    "    if config.optimizer == \"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:  # \"SGD\"\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    # Scheduler (igual estilo que A)\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # --------- Entrenamiento ---------\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "\n",
    "        # --------- Validación ---------\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss = val_loss / max(1, len(val_loader))\n",
    "\n",
    "        # Step del scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Log\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Ep {epoch+1:02d}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping + guardar mejor\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/MODEL_B_resnet18_audio_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > PATIENCE:\n",
    "                print(f\"[Run {i}] Early stopping en epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2e509",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Augmented Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# ENTRENAMIENTO - MODELO B (ResNet-18 Audio)\n",
    "# Dataset: data/spectrograms1/augmented\n",
    "# ===========================================\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# ---- 0) Setup\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---- 1) Data (AUMENTADO en disco; no aplicamos augment extra aquí)\n",
    "DATA_DIR = \"data/spectrograms1/augmented\"\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # [-1, 1] como en A\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\",   transform=transform)\n",
    "\n",
    "# Se sobrescriben adentro del loop según batch_size del experimento\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_data,   batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "print(\"Clases:\", num_classes)\n",
    "\n",
    "# ---- 2) Tu modelo (ya definido arriba en tu notebook)\n",
    "# from resnet18_audio import resnet18_audio  # Usa esta import si lo tienes como .py\n",
    "# Si lo definiste en una celda anterior, simplemente llama resnet18_audio(...)\n",
    "# (No re-importar si está en la misma sesión de Colab)\n",
    "\n",
    "# ---- 3) Experimentos (igual estilo que A)\n",
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001,  \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001,  \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,   \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001,  \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "EPOCHS   = 40\n",
    "PATIENCE = 6\n",
    "\n",
    "# ---- 4) Loop multi-run\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    wandb.init(\n",
    "        project=\"esc50-modelB-augmented\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp,\n",
    "        # mode=\"offline\",  # <- Descomenta si no querés usar API key\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    # Loaders con batch size del experimento\n",
    "    train_loader = DataLoader(\n",
    "        train_data, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    "    )\n",
    "    val_loader   = DataLoader(\n",
    "        val_data,   batch_size=config.batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # --- Modelo B (tu ResNet-18)\n",
    "    model = resnet18_audio(num_classes=num_classes, in_channels=1, small_input=True).to(device)\n",
    "\n",
    "    # --- Criterio / Optimizador / Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "\n",
    "    # --- Entrenamiento con early stopping\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "\n",
    "        # Val\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss = val_loss / max(1, len(val_loader))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping + guardar mejor\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/resnet18_audio_AUG_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > PATIENCE:\n",
    "                print(f\"[Run {i}] Early stopping triggered at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
