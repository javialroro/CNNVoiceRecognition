{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5793bd2c",
   "metadata": {},
   "source": [
    "# Dataset Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da012a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando train: 100%|██████████| 1200/1200 [01:04<00:00, 18.71it/s]\n",
      "Procesando val: 100%|██████████| 400/400 [00:10<00:00, 36.41it/s]\n",
      "Procesando test: 100%|██████████| 400/400 [00:10<00:00, 36.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Espectrogramas generados y organizados por división.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "CSV_PATH = \"data/ESC-50-master/meta/esc50.csv\"\n",
    "AUDIO_DIR = \"data/ESC-50-master/audio\"\n",
    "OUTPUT_DIR = \"data/spectrograms1/base\"\n",
    "SR = 22050\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Divisiones basadas en folds\n",
    "TRAIN_FOLDS = [1, 2, 3]\n",
    "VAL_FOLDS   = [4]\n",
    "TEST_FOLDS  = [5]\n",
    "\n",
    "# Crear carpetas base\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split), exist_ok=True)\n",
    "\n",
    "# Leer metadatos\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "def wav_to_spectrogram(wav_path, save_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=SR)\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        S_norm = (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "        S_img = (S_norm * 255).astype(np.uint8)\n",
    "\n",
    "        img = Image.fromarray(S_img).resize(IMG_SIZE).convert(\"L\")\n",
    "        img.save(save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error procesando {wav_path}: {e}\")\n",
    "\n",
    "def process_split(split_name, folds):\n",
    "    df_split = df[df[\"fold\"].isin(folds)]\n",
    "    for _, row in tqdm(df_split.iterrows(), total=len(df_split), desc=f\"Procesando {split_name}\"):\n",
    "        file_name = row[\"filename\"]\n",
    "        label = row[\"category\"]\n",
    "\n",
    "        # Crear carpeta por clase\n",
    "        class_dir = os.path.join(OUTPUT_DIR, split_name, label)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        wav_path = os.path.join(AUDIO_DIR, file_name)\n",
    "        save_path = os.path.join(class_dir, file_name.replace(\".wav\", \".png\"))\n",
    "\n",
    "        if not os.path.exists(save_path):\n",
    "            wav_to_spectrogram(wav_path, save_path)\n",
    "\n",
    "# Generar los tres splits\n",
    "process_split(\"train\", TRAIN_FOLDS)\n",
    "process_split(\"val\", VAL_FOLDS)\n",
    "process_split(\"test\", TEST_FOLDS)\n",
    "\n",
    "print(\"✅ Espectrogramas generados y organizados por división.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6178f7",
   "metadata": {},
   "source": [
    "# Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c26731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=50, dropout=0.5):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        # --- Bloque 1 ---\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        # --- Bloque 2 ---\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        # --- Bloque 3 ---\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.pool3 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        # --- Normalización por capa (importante para tanh) ---\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # --- Capas densas ---\n",
    "        self.fc1 = nn.Linear(32 * 26 * 26, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Inicialización recomendada para tanh\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normalización ligera antes de tanh para evitar saturación\n",
    "        x = self.pool1(torch.tanh(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.tanh(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.tanh(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a0b11",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Raw Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afe49b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Normalización [-1,1] porque LeNet usa tanh\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/spectrograms1/base/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(\"data/spectrograms1/base/val\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e1870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162231-hq5ddrea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea' target=\"_blank\">run_1_opt-Adam_lr-0.001_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Epoch 1/40 | Train Acc: 0.046 | Val Acc: 0.110\n",
      "[Run 1] Epoch 2/40 | Train Acc: 0.097 | Val Acc: 0.113\n",
      "[Run 1] Epoch 3/40 | Train Acc: 0.130 | Val Acc: 0.143\n",
      "[Run 1] Epoch 4/40 | Train Acc: 0.161 | Val Acc: 0.167\n",
      "[Run 1] Epoch 5/40 | Train Acc: 0.189 | Val Acc: 0.203\n",
      "[Run 1] Epoch 6/40 | Train Acc: 0.236 | Val Acc: 0.210\n",
      "[Run 1] Epoch 7/40 | Train Acc: 0.271 | Val Acc: 0.223\n",
      "[Run 1] Epoch 8/40 | Train Acc: 0.264 | Val Acc: 0.270\n",
      "[Run 1] Epoch 9/40 | Train Acc: 0.305 | Val Acc: 0.260\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.368 | Val Acc: 0.277\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.386 | Val Acc: 0.267\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.442 | Val Acc: 0.290\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.473 | Val Acc: 0.300\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.501 | Val Acc: 0.297\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.546 | Val Acc: 0.283\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.591 | Val Acc: 0.307\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.634 | Val Acc: 0.290\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.671 | Val Acc: 0.290\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.710 | Val Acc: 0.313\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.750 | Val Acc: 0.317\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.754 | Val Acc: 0.310\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.799 | Val Acc: 0.307\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.826 | Val Acc: 0.323\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.846 | Val Acc: 0.343\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.856 | Val Acc: 0.327\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.876 | Val Acc: 0.347\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.876 | Val Acc: 0.287\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.896 | Val Acc: 0.310\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.911 | Val Acc: 0.323\n",
      "[Run 1] Epoch 30/40 | Train Acc: 0.921 | Val Acc: 0.353\n",
      "[Run 1] Epoch 31/40 | Train Acc: 0.933 | Val Acc: 0.327\n",
      "[Run 1] Epoch 32/40 | Train Acc: 0.944 | Val Acc: 0.337\n",
      "[Run 1] Epoch 33/40 | Train Acc: 0.948 | Val Acc: 0.330\n",
      "[Run 1] Epoch 34/40 | Train Acc: 0.949 | Val Acc: 0.333\n",
      "[Run 1] Epoch 35/40 | Train Acc: 0.966 | Val Acc: 0.323\n",
      "[Run 1] Epoch 36/40 | Train Acc: 0.968 | Val Acc: 0.340\n",
      "[Run 1] Epoch 37/40 | Train Acc: 0.974 | Val Acc: 0.327\n",
      "[Run 1] Epoch 38/40 | Train Acc: 0.976 | Val Acc: 0.327\n",
      "[Run 1] Epoch 39/40 | Train Acc: 0.974 | Val Acc: 0.317\n",
      "[Run 1] Epoch 40/40 | Train Acc: 0.980 | Val Acc: 0.310\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▄▄▄▆▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇█▇█▆▇▇█▇█▇▇▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▃▃▂▂▂▁▂▁▁▁▁▁▁▂▂▂▂▁▂▂▃▂▃▃▃▃▃▃▄▄▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.35333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.98</td></tr><tr><td>train_loss</td><td>0.17417</td></tr><tr><td>val_acc</td><td>0.31</td></tr><tr><td>val_loss</td><td>3.0484</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-Adam_lr-0.001_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162231-hq5ddrea/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162435-xrkc46ot</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot' target=\"_blank\">run_2_opt-Adam_lr-0.0005_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Epoch 1/40 | Train Acc: 0.049 | Val Acc: 0.080\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.096 | Val Acc: 0.080\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.120 | Val Acc: 0.150\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.160 | Val Acc: 0.187\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.205 | Val Acc: 0.180\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.254 | Val Acc: 0.237\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.291 | Val Acc: 0.230\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.340 | Val Acc: 0.267\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.393 | Val Acc: 0.283\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.458 | Val Acc: 0.273\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.515 | Val Acc: 0.297\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.551 | Val Acc: 0.300\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.622 | Val Acc: 0.337\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.655 | Val Acc: 0.297\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.686 | Val Acc: 0.323\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.732 | Val Acc: 0.323\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.779 | Val Acc: 0.333\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.802 | Val Acc: 0.323\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.821 | Val Acc: 0.317\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.854 | Val Acc: 0.323\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.852 | Val Acc: 0.330\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.876 | Val Acc: 0.320\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.903 | Val Acc: 0.323\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.907 | Val Acc: 0.310\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.917 | Val Acc: 0.317\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.933 | Val Acc: 0.317\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.940 | Val Acc: 0.323\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.949 | Val Acc: 0.343\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.957 | Val Acc: 0.333\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.964 | Val Acc: 0.317\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.968 | Val Acc: 0.337\n",
      "[Run 2] Epoch 32/40 | Train Acc: 0.977 | Val Acc: 0.323\n",
      "[Run 2] Epoch 33/40 | Train Acc: 0.979 | Val Acc: 0.327\n",
      "[Run 2] Epoch 34/40 | Train Acc: 0.979 | Val Acc: 0.340\n",
      "[Run 2] Epoch 35/40 | Train Acc: 0.976 | Val Acc: 0.320\n",
      "[Run 2] Epoch 36/40 | Train Acc: 0.986 | Val Acc: 0.330\n",
      "[Run 2] Epoch 37/40 | Train Acc: 0.988 | Val Acc: 0.313\n",
      "[Run 2] Epoch 38/40 | Train Acc: 0.981 | Val Acc: 0.303\n",
      "[Run 2] Epoch 39/40 | Train Acc: 0.989 | Val Acc: 0.320\n",
      "[Run 2] Epoch 40/40 | Train Acc: 0.991 | Val Acc: 0.320\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▃▄▄▅▅▆▆▆▇▇█▇▇▇█▇▇▇█▇▇▇▇▇▇██▇█▇██▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.34333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.99143</td></tr><tr><td>train_loss</td><td>0.17701</td></tr><tr><td>val_acc</td><td>0.32</td></tr><tr><td>val_loss</td><td>2.81106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-Adam_lr-0.0005_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162435-xrkc46ot/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162651-kpvuo89q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q' target=\"_blank\">run_3_opt-Adam_lr-0.001_bs-64</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Epoch 1/40 | Train Acc: 0.049 | Val Acc: 0.103\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.094 | Val Acc: 0.100\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.126 | Val Acc: 0.150\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.156 | Val Acc: 0.170\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.187 | Val Acc: 0.197\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.219 | Val Acc: 0.173\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.228 | Val Acc: 0.190\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.261 | Val Acc: 0.227\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.311 | Val Acc: 0.280\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.314 | Val Acc: 0.253\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.371 | Val Acc: 0.267\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.399 | Val Acc: 0.277\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.472 | Val Acc: 0.297\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.489 | Val Acc: 0.307\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.543 | Val Acc: 0.280\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.576 | Val Acc: 0.337\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.621 | Val Acc: 0.303\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.676 | Val Acc: 0.337\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.691 | Val Acc: 0.320\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.716 | Val Acc: 0.323\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.721 | Val Acc: 0.323\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.751 | Val Acc: 0.323\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.777 | Val Acc: 0.327\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.800 | Val Acc: 0.333\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.831 | Val Acc: 0.337\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.843 | Val Acc: 0.343\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.849 | Val Acc: 0.360\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.861 | Val Acc: 0.373\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.865 | Val Acc: 0.337\n",
      "[Run 3] Epoch 30/40 | Train Acc: 0.873 | Val Acc: 0.353\n",
      "[Run 3] Epoch 31/40 | Train Acc: 0.892 | Val Acc: 0.373\n",
      "[Run 3] Epoch 32/40 | Train Acc: 0.905 | Val Acc: 0.340\n",
      "[Run 3] Epoch 33/40 | Train Acc: 0.918 | Val Acc: 0.350\n",
      "[Run 3] Epoch 34/40 | Train Acc: 0.925 | Val Acc: 0.360\n",
      "[Run 3] Epoch 35/40 | Train Acc: 0.917 | Val Acc: 0.357\n",
      "[Run 3] Epoch 36/40 | Train Acc: 0.931 | Val Acc: 0.353\n",
      "[Run 3] Epoch 37/40 | Train Acc: 0.946 | Val Acc: 0.360\n",
      "[Run 3] Epoch 38/40 | Train Acc: 0.942 | Val Acc: 0.343\n",
      "[Run 3] Epoch 39/40 | Train Acc: 0.947 | Val Acc: 0.333\n",
      "[Run 3] Epoch 40/40 | Train Acc: 0.950 | Val Acc: 0.343\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▃▃▄▆▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██▇▇█▇▇██▇█▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.37333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.95</td></tr><tr><td>train_loss</td><td>0.32957</td></tr><tr><td>val_acc</td><td>0.34333</td></tr><tr><td>val_loss</td><td>2.63842</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-Adam_lr-0.001_bs-64</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162651-kpvuo89q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162908-sk1okcp1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1' target=\"_blank\">run_4_opt-SGD_lr-0.01_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Epoch 1/40 | Train Acc: 0.053 | Val Acc: 0.070\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.114 | Val Acc: 0.123\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.156 | Val Acc: 0.157\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.195 | Val Acc: 0.187\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.229 | Val Acc: 0.227\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.238 | Val Acc: 0.270\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.272 | Val Acc: 0.243\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.284 | Val Acc: 0.257\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.304 | Val Acc: 0.260\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.344 | Val Acc: 0.280\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.373 | Val Acc: 0.277\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.372 | Val Acc: 0.297\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.431 | Val Acc: 0.297\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.484 | Val Acc: 0.300\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.496 | Val Acc: 0.293\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.571 | Val Acc: 0.330\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.606 | Val Acc: 0.337\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.664 | Val Acc: 0.330\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.671 | Val Acc: 0.330\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.746 | Val Acc: 0.333\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.776 | Val Acc: 0.323\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.818 | Val Acc: 0.350\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.861 | Val Acc: 0.343\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.863 | Val Acc: 0.323\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.904 | Val Acc: 0.330\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.911 | Val Acc: 0.340\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.936 | Val Acc: 0.317\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.942 | Val Acc: 0.340\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.962 | Val Acc: 0.323\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.967 | Val Acc: 0.330\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.970 | Val Acc: 0.330\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.975 | Val Acc: 0.310\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.976 | Val Acc: 0.330\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.985 | Val Acc: 0.330\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.986 | Val Acc: 0.313\n",
      "[Run 4] Epoch 36/40 | Train Acc: 0.984 | Val Acc: 0.353\n",
      "[Run 4] Epoch 37/40 | Train Acc: 0.993 | Val Acc: 0.333\n",
      "[Run 4] Epoch 38/40 | Train Acc: 0.992 | Val Acc: 0.340\n",
      "[Run 4] Epoch 39/40 | Train Acc: 0.989 | Val Acc: 0.347\n",
      "[Run 4] Epoch 40/40 | Train Acc: 0.993 | Val Acc: 0.343\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇██████████████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▄▅▆▅▆▆▆▆▇▇▇▇▇█▇▇█▇██▇▇█▇█▇▇▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▂▂▂▃▂▃▂▃▃▄▃▄▄▄▄▄▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.35333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.99286</td></tr><tr><td>train_loss</td><td>0.09715</td></tr><tr><td>val_acc</td><td>0.34333</td></tr><tr><td>val_loss</td><td>2.93547</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-SGD_lr-0.01_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162908-sk1okcp1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_163129-p4f9num9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9' target=\"_blank\">run_5_opt-SGD_lr-0.001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Epoch 1/40 | Train Acc: 0.039 | Val Acc: 0.067\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.056 | Val Acc: 0.083\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.083 | Val Acc: 0.090\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.107 | Val Acc: 0.100\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.130 | Val Acc: 0.147\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.159 | Val Acc: 0.157\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.185 | Val Acc: 0.180\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.210 | Val Acc: 0.210\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.216 | Val Acc: 0.217\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.257 | Val Acc: 0.227\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.256 | Val Acc: 0.223\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.265 | Val Acc: 0.243\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.266 | Val Acc: 0.270\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.281 | Val Acc: 0.257\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.302 | Val Acc: 0.247\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.302 | Val Acc: 0.273\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.323 | Val Acc: 0.277\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.322 | Val Acc: 0.287\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.346 | Val Acc: 0.267\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.356 | Val Acc: 0.303\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.356 | Val Acc: 0.283\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.364 | Val Acc: 0.307\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.377 | Val Acc: 0.323\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.383 | Val Acc: 0.300\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.386 | Val Acc: 0.313\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.418 | Val Acc: 0.300\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.417 | Val Acc: 0.313\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.422 | Val Acc: 0.317\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.431 | Val Acc: 0.330\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.437 | Val Acc: 0.333\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.454 | Val Acc: 0.310\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.466 | Val Acc: 0.327\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.482 | Val Acc: 0.313\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.499 | Val Acc: 0.313\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.498 | Val Acc: 0.327\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.511 | Val Acc: 0.327\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.517 | Val Acc: 0.313\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.535 | Val Acc: 0.340\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.556 | Val Acc: 0.327\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.553 | Val Acc: 0.317\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▂▃▃▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇█▇▇▇▇▇██▇█▇▇██▇██▇</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.34</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.55286</td></tr><tr><td>train_loss</td><td>1.79318</td></tr><tr><td>val_acc</td><td>0.31667</td></tr><tr><td>val_loss</td><td>2.46487</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_163129-p4f9num9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Transformaciones ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/spectrograms1_split/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(\"data/spectrograms1_split/val\", transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "# === LISTA DE EXPERIMENTOS ===\n",
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 32, \"weight_decay\": 0},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 0.0001},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 64, \"weight_decay\": 0},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,  \"batch_size\": 32, \"weight_decay\": 0.0001},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001, \"batch_size\": 16, \"weight_decay\": 0},\n",
    "]\n",
    "\n",
    "# === ENTRENAR 5 RUNS ===\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    wandb.init(\n",
    "        project=\"esc50-lenet\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    # Actualizar batch size dinámicamente\n",
    "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_data, batch_size=config.batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LeNet5(num_classes=len(train_data.classes)).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    EPOCHS = 40\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1}/{EPOCHS} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f\"models/lenet_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444df42",
   "metadata": {},
   "source": [
    "## Dataset Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26467187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando TRAIN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando VAL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando TEST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset aumentado generado con SpecAugment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "BASE_DIR = \"data/spectrograms1/base\"\n",
    "AUG_DIR = \"data/spectrograms1/augmented\"\n",
    "\n",
    "# Parámetros de SpecAugment (según Park et al., 2019)\n",
    "FREQ_MASK_PARAM = 20      # ancho máximo de bandas de frecuencia a enmascarar\n",
    "TIME_MASK_PARAM = 25      # ancho máximo de regiones de tiempo a enmascarar\n",
    "NUM_FREQ_MASKS = 2        # número de máscaras de frecuencia\n",
    "NUM_TIME_MASKS = 2        # número de máscaras de tiempo\n",
    "\n",
    "# Crear carpetas base del dataset aumentado\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(AUG_DIR, split), exist_ok=True)\n",
    "\n",
    "\n",
    "# === FUNCIÓN PRINCIPAL ===\n",
    "def apply_specaugment(image_path, save_path):\n",
    "    \"\"\"Aplica SpecAugment a una imagen de espectrograma (grises).\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"L\")\n",
    "        spec = np.array(img)\n",
    "\n",
    "        # --- Frequency masking (vertical) ---\n",
    "        for _ in range(NUM_FREQ_MASKS):\n",
    "            f = random.randint(0, FREQ_MASK_PARAM)\n",
    "            if f == 0:\n",
    "                continue\n",
    "            f0 = random.randint(0, spec.shape[0] - f)\n",
    "            spec[f0:f0 + f, :] = 0  # borra bandas de frecuencia\n",
    "\n",
    "        # --- Time masking (horizontal) ---\n",
    "        for _ in range(NUM_TIME_MASKS):\n",
    "            t = random.randint(0, TIME_MASK_PARAM)\n",
    "            if t == 0:\n",
    "                continue\n",
    "            t0 = random.randint(0, spec.shape[1] - t)\n",
    "            spec[:, t0:t0 + t] = 0  # borra regiones de tiempo\n",
    "\n",
    "        aug_img = Image.fromarray(spec)\n",
    "        aug_img.save(save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error procesando {image_path}: {e}\")\n",
    "\n",
    "\n",
    "# === RECORRER TODAS LAS PARTICIONES ===\n",
    "def process_split(split_name):\n",
    "    base_split_path = os.path.join(BASE_DIR, split_name)\n",
    "    aug_split_path = os.path.join(AUG_DIR, split_name)\n",
    "\n",
    "    # recorrer las clases\n",
    "    for class_name in os.listdir(base_split_path):\n",
    "        class_base_path = os.path.join(base_split_path, class_name)\n",
    "        class_aug_path = os.path.join(aug_split_path, class_name)\n",
    "        os.makedirs(class_aug_path, exist_ok=True)\n",
    "\n",
    "        # recorrer las imágenes\n",
    "        images = [f for f in os.listdir(class_base_path) if f.endswith(\".png\")]\n",
    "\n",
    "        for img_file in tqdm(images, desc=f\"{split_name}/{class_name}\", leave=False):\n",
    "            src_path = os.path.join(class_base_path, img_file)\n",
    "            dst_path = os.path.join(class_aug_path, img_file)\n",
    "\n",
    "            # aplicar SpecAugment y guardar\n",
    "            apply_specaugment(src_path, dst_path)\n",
    "\n",
    "\n",
    "# === EJECUCIÓN ===\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"\\nProcesando {split.upper()}...\")\n",
    "    process_split(split)\n",
    "\n",
    "print(\"\\n✅ Dataset aumentado generado con SpecAugment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85f92b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] A dynamic link library (DLL) initialization routine failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchaudio\\__init__.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize extension and backend first\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa  # usort: skip\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compliance, datasets, functional, models, pipelines, transforms, utils  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchcodec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_with_torchcodec, save_with_torchcodec\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchaudio\\_extension\\__init__.py:37\u001b[0m\n\u001b[0;32m     35\u001b[0m _IS_ALIGN_AVAILABLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_TORCHAUDIO_EXT_AVAILABLE:\n\u001b[1;32m---> 37\u001b[0m     \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchaudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchaudio\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     _check_cuda_version()\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchaudio\\_extension\\utils.py:58\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_ops.py:1478\u001b[0m, in \u001b[0;36mload_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_library\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;124;03m    Loads a shared library from the given path into the current process.\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m \n\u001b[0;32m   1468\u001b[0m \u001b[38;5;124;03m    The library being loaded may run global initialization code to register\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;124;03m    custom operators with the PyTorch JIT runtime. This allows dynamically\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;124;03m    loading custom operators. For this, you should compile your operator\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;124;03m    and the static registration code into a shared library object, and then\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;124;03m    call ``torch.ops.load_library('path/to/libcustom.so')`` to load the\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;124;03m    shared object.\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m \n\u001b[0;32m   1475\u001b[0m \u001b[38;5;124;03m    After the library is loaded, it is added to the\u001b[39;00m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;124;03m    ``torch.ops.loaded_libraries`` attribute, a set that may be inspected\u001b[39;00m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;124;03m    for the paths of all libraries loaded using this function.\u001b[39;00m\n\u001b[1;32m-> 1478\u001b[0m \n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;124;03m        path (str): A path to a shared library to load.\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m     path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m   1483\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m   1484\u001b[0m         \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m   1485\u001b[0m         \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m   1486\u001b[0m         \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ctypes\\__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1114] A dynamic link library (DLL) initialization routine failed"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "CSV_PATH = \"data/ESC-50-master/meta/esc50.csv\"\n",
    "AUDIO_DIR = \"data/ESC-50-master/audio\"\n",
    "OUTPUT_DIR = \"data/spectrograms1/augmented1\"\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "N_MELS = 128\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Folds por división\n",
    "TRAIN_FOLDS = [1, 2, 3]\n",
    "VAL_FOLDS   = [4]\n",
    "TEST_FOLDS  = [5]\n",
    "\n",
    "# === TRANSFORMACIONES ===\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_mels=N_MELS\n",
    ")\n",
    "\n",
    "specaugment = torchaudio.transforms.SpecAugment(\n",
    "    freq_mask_param=15,      # enmascaramiento de frecuencia\n",
    "    time_mask_param=35,      # enmascaramiento de tiempo\n",
    "    n_freq_masks=2,\n",
    "    n_time_masks=2\n",
    ")\n",
    "\n",
    "# === FUNCIONES ===\n",
    "def save_spec_image(tensor, save_path):\n",
    "    \"\"\"Convierte un tensor de espectrograma a imagen PNG.\"\"\"\n",
    "    tensor = tensor.squeeze().numpy()\n",
    "    tensor_db = torchaudio.functional.amplitude_to_DB(\n",
    "        torch.tensor(tensor), multiplier=10, amin=1e-10, db_multiplier=0\n",
    "    ).numpy()\n",
    "    tensor_norm = (tensor_db - tensor_db.min()) / (tensor_db.max() - tensor_db.min())\n",
    "    img = (tensor_norm * 255).astype(np.uint8)\n",
    "    Image.fromarray(img).resize(IMG_SIZE).convert(\"L\").save(save_path)\n",
    "\n",
    "def process_split(df, split_name):\n",
    "    \"\"\"Procesa un subconjunto del dataset aplicando SpecAugment.\"\"\"\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Procesando {split_name}\"):\n",
    "        file_name = row[\"filename\"]\n",
    "        label = row[\"category\"]\n",
    "\n",
    "        class_dir = os.path.join(OUTPUT_DIR, split_name, label)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        wav_path = os.path.join(AUDIO_DIR, file_name)\n",
    "        save_path = os.path.join(class_dir, file_name.replace(\".wav\", \".png\"))\n",
    "\n",
    "        try:\n",
    "            # Cargar audio\n",
    "            waveform, sr = torchaudio.load(wav_path)\n",
    "            if sr != SAMPLE_RATE:\n",
    "                waveform = torchaudio.functional.resample(waveform, sr, SAMPLE_RATE)\n",
    "\n",
    "            # Crear mel-espectrograma\n",
    "            mel_spec = mel_transform(waveform)\n",
    "\n",
    "            # Aplicar SpecAugment\n",
    "            augmented_spec = specaugment(mel_spec)\n",
    "\n",
    "            # Guardar como imagen\n",
    "            save_spec_image(augmented_spec, save_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error con {wav_path}: {e}\")\n",
    "\n",
    "# === MAIN ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "splits = {\n",
    "    \"train\": df[df[\"fold\"].isin(TRAIN_FOLDS)],\n",
    "    \"val\":   df[df[\"fold\"].isin(VAL_FOLDS)],\n",
    "    \"test\":  df[df[\"fold\"].isin(TEST_FOLDS)]\n",
    "}\n",
    "\n",
    "for split_name, subset in splits.items():\n",
    "    process_split(subset, split_name)\n",
    "\n",
    "print(\"\\n✅ Dataset aumentado con SpecAugment generado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637852f",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Augmented Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4087f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/spectrograms1/augmented\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==============================\n",
    "# TRANSFORMACIONES\n",
    "# ==============================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3ad64dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181523-3ewxjhu6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6' target=\"_blank\">run_1_opt-Adam_lr-0.001_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Epoch 1/40 | Train Acc: 0.048 | Val Acc: 0.058 | Train Loss: 3.7720 | Val Loss: 3.6313\n",
      "[Run 1] Epoch 2/40 | Train Acc: 0.072 | Val Acc: 0.090 | Train Loss: 3.5444 | Val Loss: 3.5044\n",
      "[Run 1] Epoch 3/40 | Train Acc: 0.098 | Val Acc: 0.083 | Train Loss: 3.4440 | Val Loss: 3.4397\n",
      "[Run 1] Epoch 4/40 | Train Acc: 0.132 | Val Acc: 0.120 | Train Loss: 3.3288 | Val Loss: 3.3846\n",
      "[Run 1] Epoch 5/40 | Train Acc: 0.141 | Val Acc: 0.133 | Train Loss: 3.2640 | Val Loss: 3.3304\n",
      "[Run 1] Epoch 6/40 | Train Acc: 0.138 | Val Acc: 0.140 | Train Loss: 3.2181 | Val Loss: 3.2802\n",
      "[Run 1] Epoch 7/40 | Train Acc: 0.160 | Val Acc: 0.170 | Train Loss: 3.1562 | Val Loss: 3.2503\n",
      "[Run 1] Epoch 8/40 | Train Acc: 0.172 | Val Acc: 0.140 | Train Loss: 3.1305 | Val Loss: 3.2696\n",
      "[Run 1] Epoch 9/40 | Train Acc: 0.194 | Val Acc: 0.128 | Train Loss: 3.0511 | Val Loss: 3.2524\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.204 | Val Acc: 0.130 | Train Loss: 2.9838 | Val Loss: 3.2430\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.219 | Val Acc: 0.140 | Train Loss: 2.9362 | Val Loss: 3.2626\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.247 | Val Acc: 0.150 | Train Loss: 2.8694 | Val Loss: 3.2395\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.261 | Val Acc: 0.175 | Train Loss: 2.7973 | Val Loss: 3.1705\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.282 | Val Acc: 0.160 | Train Loss: 2.7306 | Val Loss: 3.1579\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.294 | Val Acc: 0.185 | Train Loss: 2.6747 | Val Loss: 3.1475\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.324 | Val Acc: 0.203 | Train Loss: 2.5764 | Val Loss: 3.1343\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.350 | Val Acc: 0.170 | Train Loss: 2.4961 | Val Loss: 3.1788\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.375 | Val Acc: 0.160 | Train Loss: 2.3998 | Val Loss: 3.1873\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.400 | Val Acc: 0.177 | Train Loss: 2.3404 | Val Loss: 3.1302\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.431 | Val Acc: 0.190 | Train Loss: 2.2514 | Val Loss: 3.1296\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.453 | Val Acc: 0.198 | Train Loss: 2.1718 | Val Loss: 3.1221\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.473 | Val Acc: 0.195 | Train Loss: 2.1216 | Val Loss: 3.1269\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.521 | Val Acc: 0.190 | Train Loss: 2.0341 | Val Loss: 3.1419\n",
      "[Run 1] Early stopping triggered at epoch 23.\n",
      "✅ [Run 1] Mejor Val Acc: 0.203\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>███████▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▂▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▃▂▄▅▅▆▅▄▄▅▅▇▆▇█▆▆▇▇██▇</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▃▃▃▃▃▃▃▂▁▁▁▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.2025</td></tr><tr><td>epoch</td><td>23</td></tr><tr><td>lr</td><td>0.00049</td></tr><tr><td>train_acc</td><td>0.52083</td></tr><tr><td>train_loss</td><td>2.03415</td></tr><tr><td>val_acc</td><td>0.19</td></tr><tr><td>val_loss</td><td>3.14192</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-Adam_lr-0.001_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181523-3ewxjhu6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181631-jvqdd1fb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb' target=\"_blank\">run_2_opt-Adam_lr-0.0005_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Epoch 1/40 | Train Acc: 0.043 | Val Acc: 0.052 | Train Loss: 3.8529 | Val Loss: 3.7090\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.082 | Val Acc: 0.068 | Train Loss: 3.5996 | Val Loss: 3.5511\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.147 | Val Acc: 0.110 | Train Loss: 3.4077 | Val Loss: 3.4791\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.174 | Val Acc: 0.125 | Train Loss: 3.2858 | Val Loss: 3.4160\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.231 | Val Acc: 0.163 | Train Loss: 3.1617 | Val Loss: 3.3699\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.286 | Val Acc: 0.145 | Train Loss: 3.0103 | Val Loss: 3.3281\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.345 | Val Acc: 0.138 | Train Loss: 2.8824 | Val Loss: 3.3323\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.368 | Val Acc: 0.170 | Train Loss: 2.7625 | Val Loss: 3.2698\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.438 | Val Acc: 0.170 | Train Loss: 2.5974 | Val Loss: 3.2337\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.487 | Val Acc: 0.203 | Train Loss: 2.4682 | Val Loss: 3.2199\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.544 | Val Acc: 0.185 | Train Loss: 2.3319 | Val Loss: 3.1940\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.574 | Val Acc: 0.193 | Train Loss: 2.2301 | Val Loss: 3.1899\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.597 | Val Acc: 0.188 | Train Loss: 2.1403 | Val Loss: 3.1952\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.616 | Val Acc: 0.172 | Train Loss: 2.0400 | Val Loss: 3.1872\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.661 | Val Acc: 0.193 | Train Loss: 1.9276 | Val Loss: 3.1541\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.703 | Val Acc: 0.203 | Train Loss: 1.8124 | Val Loss: 3.1598\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.714 | Val Acc: 0.195 | Train Loss: 1.7108 | Val Loss: 3.1498\n",
      "[Run 2] Early stopping triggered at epoch 17.\n",
      "✅ [Run 2] Mejor Val Acc: 0.203\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>███████▄▄▄▄▄▄▄▄▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▃▄▄▄▅▆▆▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▂▄▄▆▅▅▆▆█▇█▇▇███</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.2025</td></tr><tr><td>epoch</td><td>17</td></tr><tr><td>lr</td><td>0.00024</td></tr><tr><td>train_acc</td><td>0.71417</td></tr><tr><td>train_loss</td><td>1.71079</td></tr><tr><td>val_acc</td><td>0.195</td></tr><tr><td>val_loss</td><td>3.14979</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-Adam_lr-0.0005_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181631-jvqdd1fb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181724-qbtr0d4y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y' target=\"_blank\">run_3_opt-Adam_lr-0.001_bs-64</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Epoch 1/40 | Train Acc: 0.043 | Val Acc: 0.058 | Train Loss: 3.8034 | Val Loss: 3.6058\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.091 | Val Acc: 0.092 | Train Loss: 3.5447 | Val Loss: 3.4712\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.136 | Val Acc: 0.102 | Train Loss: 3.4030 | Val Loss: 3.3887\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.169 | Val Acc: 0.135 | Train Loss: 3.2755 | Val Loss: 3.3231\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.218 | Val Acc: 0.133 | Train Loss: 3.1499 | Val Loss: 3.2539\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.241 | Val Acc: 0.147 | Train Loss: 3.0370 | Val Loss: 3.2316\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.282 | Val Acc: 0.158 | Train Loss: 2.8991 | Val Loss: 3.1809\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.324 | Val Acc: 0.165 | Train Loss: 2.7669 | Val Loss: 3.1441\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.366 | Val Acc: 0.163 | Train Loss: 2.6337 | Val Loss: 3.1664\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.425 | Val Acc: 0.172 | Train Loss: 2.4882 | Val Loss: 3.1387\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.478 | Val Acc: 0.165 | Train Loss: 2.3758 | Val Loss: 3.1374\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.510 | Val Acc: 0.155 | Train Loss: 2.2650 | Val Loss: 3.1412\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.550 | Val Acc: 0.168 | Train Loss: 2.1278 | Val Loss: 3.1063\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.568 | Val Acc: 0.165 | Train Loss: 2.0408 | Val Loss: 3.1384\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.632 | Val Acc: 0.163 | Train Loss: 1.9175 | Val Loss: 3.1161\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.664 | Val Acc: 0.170 | Train Loss: 1.7933 | Val Loss: 3.1537\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.702 | Val Acc: 0.170 | Train Loss: 1.6758 | Val Loss: 3.1255\n",
      "[Run 3] Early stopping triggered at epoch 17.\n",
      "✅ [Run 3] Mejor Val Acc: 0.172\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>███████▄▄▄▄▄▄▄▄▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▅▄▄▃▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▆▆▆▇█▇██▇██▇██</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▃▂▂▂▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.1725</td></tr><tr><td>epoch</td><td>17</td></tr><tr><td>lr</td><td>0.00049</td></tr><tr><td>train_acc</td><td>0.70167</td></tr><tr><td>train_loss</td><td>1.67584</td></tr><tr><td>val_acc</td><td>0.17</td></tr><tr><td>val_loss</td><td>3.12547</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-Adam_lr-0.001_bs-64</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181724-qbtr0d4y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181818-j3lr4kiq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq' target=\"_blank\">run_4_opt-SGD_lr-0.01_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Epoch 1/40 | Train Acc: 0.030 | Val Acc: 0.055 | Train Loss: 3.8714 | Val Loss: 3.7322\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.069 | Val Acc: 0.107 | Train Loss: 3.6054 | Val Loss: 3.4959\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.114 | Val Acc: 0.138 | Train Loss: 3.4025 | Val Loss: 3.4217\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.163 | Val Acc: 0.147 | Train Loss: 3.2395 | Val Loss: 3.3113\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.180 | Val Acc: 0.138 | Train Loss: 3.1176 | Val Loss: 3.2709\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.217 | Val Acc: 0.125 | Train Loss: 2.9857 | Val Loss: 3.3042\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.239 | Val Acc: 0.175 | Train Loss: 2.9135 | Val Loss: 3.1644\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.273 | Val Acc: 0.177 | Train Loss: 2.7594 | Val Loss: 3.1090\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.338 | Val Acc: 0.168 | Train Loss: 2.5928 | Val Loss: 3.1228\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.374 | Val Acc: 0.190 | Train Loss: 2.4608 | Val Loss: 3.0803\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.407 | Val Acc: 0.198 | Train Loss: 2.3363 | Val Loss: 3.0756\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.458 | Val Acc: 0.168 | Train Loss: 2.1976 | Val Loss: 3.0809\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.497 | Val Acc: 0.177 | Train Loss: 2.0757 | Val Loss: 3.0507\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.540 | Val Acc: 0.188 | Train Loss: 1.9183 | Val Loss: 3.0512\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.574 | Val Acc: 0.172 | Train Loss: 1.8057 | Val Loss: 3.1272\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.612 | Val Acc: 0.182 | Train Loss: 1.6817 | Val Loss: 3.0522\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.668 | Val Acc: 0.203 | Train Loss: 1.5133 | Val Loss: 3.0164\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.738 | Val Acc: 0.182 | Train Loss: 1.3499 | Val Loss: 3.0610\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.757 | Val Acc: 0.175 | Train Loss: 1.2552 | Val Loss: 3.0540\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.783 | Val Acc: 0.193 | Train Loss: 1.1626 | Val Loss: 3.0529\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.812 | Val Acc: 0.198 | Train Loss: 1.0500 | Val Loss: 3.0404\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.836 | Val Acc: 0.203 | Train Loss: 0.9570 | Val Loss: 3.0874\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.836 | Val Acc: 0.203 | Train Loss: 0.9112 | Val Loss: 3.1102\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.871 | Val Acc: 0.175 | Train Loss: 0.8196 | Val Loss: 3.1616\n",
      "[Run 4] Early stopping triggered at epoch 24.\n",
      "✅ [Run 4] Mejor Val Acc: 0.203\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▅▅▄▇▇▆▇█▆▇▇▇▇█▇▇████▇</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▄▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.2025</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>lr</td><td>0.00343</td></tr><tr><td>train_acc</td><td>0.87083</td></tr><tr><td>train_loss</td><td>0.81957</td></tr><tr><td>val_acc</td><td>0.175</td></tr><tr><td>val_loss</td><td>3.1616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-SGD_lr-0.01_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181818-j3lr4kiq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181930-6zc8df1r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r' target=\"_blank\">run_5_opt-SGD_lr-0.001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Epoch 1/40 | Train Acc: 0.030 | Val Acc: 0.033 | Train Loss: 3.8964 | Val Loss: 3.8509\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.052 | Val Acc: 0.065 | Train Loss: 3.7887 | Val Loss: 3.7278\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.077 | Val Acc: 0.070 | Train Loss: 3.6700 | Val Loss: 3.6275\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.102 | Val Acc: 0.098 | Train Loss: 3.5662 | Val Loss: 3.5627\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.113 | Val Acc: 0.102 | Train Loss: 3.4968 | Val Loss: 3.5199\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.136 | Val Acc: 0.100 | Train Loss: 3.4331 | Val Loss: 3.4835\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.162 | Val Acc: 0.128 | Train Loss: 3.3715 | Val Loss: 3.4573\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.168 | Val Acc: 0.135 | Train Loss: 3.3202 | Val Loss: 3.4273\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.192 | Val Acc: 0.140 | Train Loss: 3.2668 | Val Loss: 3.4107\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.212 | Val Acc: 0.145 | Train Loss: 3.2205 | Val Loss: 3.3904\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.199 | Val Acc: 0.147 | Train Loss: 3.1988 | Val Loss: 3.3770\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.233 | Val Acc: 0.142 | Train Loss: 3.1552 | Val Loss: 3.3622\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.244 | Val Acc: 0.163 | Train Loss: 3.1179 | Val Loss: 3.3390\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.240 | Val Acc: 0.158 | Train Loss: 3.0899 | Val Loss: 3.3280\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.259 | Val Acc: 0.165 | Train Loss: 3.0391 | Val Loss: 3.3157\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.277 | Val Acc: 0.165 | Train Loss: 3.0109 | Val Loss: 3.3039\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.292 | Val Acc: 0.168 | Train Loss: 2.9642 | Val Loss: 3.2855\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.309 | Val Acc: 0.170 | Train Loss: 2.9411 | Val Loss: 3.2824\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.304 | Val Acc: 0.165 | Train Loss: 2.9185 | Val Loss: 3.2721\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.307 | Val Acc: 0.163 | Train Loss: 2.8912 | Val Loss: 3.2679\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.318 | Val Acc: 0.163 | Train Loss: 2.8666 | Val Loss: 3.2556\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.323 | Val Acc: 0.158 | Train Loss: 2.8452 | Val Loss: 3.2533\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.330 | Val Acc: 0.158 | Train Loss: 2.8209 | Val Loss: 3.2512\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.334 | Val Acc: 0.170 | Train Loss: 2.7976 | Val Loss: 3.2268\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.344 | Val Acc: 0.163 | Train Loss: 2.7624 | Val Loss: 3.2317\n",
      "[Run 5] Early stopping triggered at epoch 25.\n",
      "✅ [Run 5] Mejor Val Acc: 0.170\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▃▄▅▄▆▆▆▇▇▇█▇███████▇▇██</td></tr><tr><td>val_loss</td><td>█▇▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.17</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>lr</td><td>0.00034</td></tr><tr><td>train_acc</td><td>0.34417</td></tr><tr><td>train_loss</td><td>2.76239</td></tr><tr><td>val_acc</td><td>0.1625</td></tr><tr><td>val_loss</td><td>3.23165</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181930-6zc8df1r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,  \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001, \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# CICLO DE ENTRENAMIENTO (IGUAL AL DATASET 1)\n",
    "# ==============================\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    wandb.init(\n",
    "        project=\"esc50-lenet-augmented\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_data, batch_size=config.batch_size)\n",
    "\n",
    "    model = LeNet5(num_classes=len(train_data.classes)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "\n",
    "    EPOCHS = 40\n",
    "    best_val_acc = 0.0\n",
    "    patience = 6\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # === VALIDACIÓN ===\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # === Early stopping ===\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/lenet5_aug_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > patience:\n",
    "                print(f\"[Run {i}] Early stopping triggered at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f633eb",
   "metadata": {},
   "source": [
    "# Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca37970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Type, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utilidades de convolución\n",
    "# -------------------------\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"Conv 3×3 con padding=1, sin bias (BN lo compensa).\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"Conv 1×1 para proyección en atajos (ajustar canales/stride).\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Bloque residual \"básico\"\n",
    "# -------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Estructura:\n",
    "        Conv3x3 → BN → ReLU → Conv3x3 → BN → (Suma con atajo) → ReLU\n",
    "    Donde el atajo (identity) puede incluir una proyección 1×1 si cambia\n",
    "    la resolución (stride > 1) o el número de canales.\n",
    "    \"\"\"\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1   = norm_layer(planes)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2   = norm_layer(planes)\n",
    "\n",
    "        self.downsample = downsample  # Proyección para el atajo, si aplica\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x  # Atajo\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Alinear dimensiones del atajo si cambió stride o # de canales\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# -----------\n",
    "# ResNet base\n",
    "# -----------\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Constructor general de ResNet con BasicBlock y configuración [2,2,2,2].\n",
    "    Parámetros clave:\n",
    "        - small_input=True: conv1=3×3 s=1 y sin MaxPool (mejor para 64–224 px).\n",
    "        - small_input=False: conv1=7×7 s=2 + MaxPool (clásico de ResNet).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[BasicBlock],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 50,\n",
    "        in_channels: int = 1,\n",
    "        small_input: bool = True,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "\n",
    "        # Capa inicial: variante \"small_input\" recomendada para espectrogramas\n",
    "        if small_input:\n",
    "            # Preserva más detalle inicial (sin MaxPool temprano)\n",
    "            self.conv1   = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.maxpool = nn.Identity()\n",
    "        else:\n",
    "            # Estilo ResNet clásico para entradas grandes\n",
    "            self.conv1   = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.bn1  = norm_layer(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Stages: [64, 128, 256, 512] con [2, 2, 2, 2] bloques\n",
    "        self.layer1 = self._make_layer(block,  64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        # Cabeza de clasificación\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Global Average Pooling\n",
    "        self.fc      = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Inicialización recomendada para ReLU/BN\n",
    "        self._init_weights()\n",
    "\n",
    "    def _make_layer(self, block: Type[BasicBlock], planes: int, blocks: int, stride: int = 1) -> nn.Sequential:\n",
    "        \"\"\"\n",
    "        Crea un stage con 'blocks' bloques. El primer bloque puede hacer downsample\n",
    "        (stride=2) para reducir resolución y duplicar canales.\n",
    "        \"\"\"\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "\n",
    "        # Si cambia resolución o # de canales, proyectamos el atajo (1×1)\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _init_weights(self) -> None:\n",
    "        \"\"\"Inicialización Kaiming para conv; constantes para BN; normal para FC.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Entrada → conv1 → BN → ReLU → (posible MaxPool/Identity)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Stages residuales\n",
    "        x = self.layer1(x)  # 64\n",
    "        x = self.layer2(x)  # 128\n",
    "        x = self.layer3(x)  # 256\n",
    "        x = self.layer4(x)  # 512\n",
    "\n",
    "        # Cabeza\n",
    "        x = self.avgpool(x)           # (B, 512, 1, 1)\n",
    "        x = torch.flatten(x, 1)       # (B, 512)\n",
    "        x = self.fc(x)                # (B, num_classes)\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Fábrica de ResNet-18\n",
    "# -------------------------\n",
    "def resnet18_audio(num_classes: int = 50, in_channels: int = 1, small_input: bool = True) -> ResNet:\n",
    "    \"\"\"\n",
    "    Retorna una ResNet-18 lista para espectrogramas:\n",
    "        - num_classes: # de clases del dataset (ESC-50 → 50)\n",
    "        - in_channels: 1 para grises; 3 si usas RGB (replicar canal)\n",
    "        - small_input: True recomendado para ~128–224 px\n",
    "    \"\"\"\n",
    "    return ResNet(\n",
    "        block=BasicBlock,\n",
    "        layers=[2, 2, 2, 2],\n",
    "        num_classes=num_classes,\n",
    "        in_channels=in_channels,\n",
    "        small_input=small_input,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf849e1",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Raw Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javialroro/miniconda3/envs/ml/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/javialroro/miniconda3/envs/ml/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Clases detectadas: 50\n",
      "\n",
      "===== Iniciando experimento 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjavialroro\u001b[0m (\u001b[33mjavialroro-tecnologico-de-costa-rica\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251024_192720-k2jxmqin</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/k2jxmqin' target=\"_blank\">resnet18B_run_1_opt-AdamW_lr-0.0003_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/k2jxmqin' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/k2jxmqin</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12046/2201489793.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/tmp/ipykernel_12046/2201489793.py:130: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/tmp/ipykernel_12046/2201489793.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Ep 01/40 | Train Acc: 0.090 | Val Acc: 0.090 | Train Loss: 3.4783 | Val Loss: 3.3165\n",
      "[Run 1] Ep 02/40 | Train Acc: 0.201 | Val Acc: 0.225 | Train Loss: 2.8735 | Val Loss: 2.8160\n",
      "[Run 1] Ep 03/40 | Train Acc: 0.250 | Val Acc: 0.258 | Train Loss: 2.6351 | Val Loss: 2.5744\n",
      "[Run 1] Ep 04/40 | Train Acc: 0.316 | Val Acc: 0.275 | Train Loss: 2.4039 | Val Loss: 2.5230\n",
      "[Run 1] Ep 05/40 | Train Acc: 0.353 | Val Acc: 0.388 | Train Loss: 2.2411 | Val Loss: 2.1187\n",
      "[Run 1] Ep 06/40 | Train Acc: 0.375 | Val Acc: 0.398 | Train Loss: 2.0770 | Val Loss: 2.1039\n",
      "[Run 1] Ep 07/40 | Train Acc: 0.418 | Val Acc: 0.432 | Train Loss: 1.9941 | Val Loss: 2.0482\n",
      "[Run 1] Ep 08/40 | Train Acc: 0.463 | Val Acc: 0.422 | Train Loss: 1.8512 | Val Loss: 2.0550\n",
      "[Run 1] Ep 09/40 | Train Acc: 0.528 | Val Acc: 0.400 | Train Loss: 1.6856 | Val Loss: 2.1561\n",
      "[Run 1] Ep 10/40 | Train Acc: 0.545 | Val Acc: 0.517 | Train Loss: 1.6215 | Val Loss: 1.7274\n",
      "[Run 1] Ep 11/40 | Train Acc: 0.569 | Val Acc: 0.487 | Train Loss: 1.5143 | Val Loss: 1.6588\n",
      "[Run 1] Ep 12/40 | Train Acc: 0.594 | Val Acc: 0.453 | Train Loss: 1.3991 | Val Loss: 1.8512\n",
      "[Run 1] Ep 13/40 | Train Acc: 0.618 | Val Acc: 0.438 | Train Loss: 1.3315 | Val Loss: 2.1018\n",
      "[Run 1] Ep 14/40 | Train Acc: 0.641 | Val Acc: 0.470 | Train Loss: 1.2629 | Val Loss: 1.7745\n",
      "[Run 1] Ep 15/40 | Train Acc: 0.650 | Val Acc: 0.505 | Train Loss: 1.1997 | Val Loss: 1.7056\n",
      "[Run 1] Ep 16/40 | Train Acc: 0.663 | Val Acc: 0.480 | Train Loss: 1.1352 | Val Loss: 1.8112\n",
      "[Run 1] Ep 17/40 | Train Acc: 0.708 | Val Acc: 0.605 | Train Loss: 1.0385 | Val Loss: 1.2790\n",
      "[Run 1] Ep 18/40 | Train Acc: 0.730 | Val Acc: 0.537 | Train Loss: 0.9906 | Val Loss: 1.5531\n",
      "[Run 1] Ep 19/40 | Train Acc: 0.756 | Val Acc: 0.573 | Train Loss: 0.9251 | Val Loss: 1.3619\n",
      "[Run 1] Ep 20/40 | Train Acc: 0.769 | Val Acc: 0.585 | Train Loss: 0.8944 | Val Loss: 1.3912\n",
      "[Run 1] Ep 21/40 | Train Acc: 0.767 | Val Acc: 0.630 | Train Loss: 0.8580 | Val Loss: 1.2582\n",
      "[Run 1] Ep 22/40 | Train Acc: 0.778 | Val Acc: 0.450 | Train Loss: 0.8154 | Val Loss: 2.4730\n",
      "[Run 1] Ep 23/40 | Train Acc: 0.801 | Val Acc: 0.640 | Train Loss: 0.7676 | Val Loss: 1.2186\n",
      "[Run 1] Ep 24/40 | Train Acc: 0.792 | Val Acc: 0.637 | Train Loss: 0.7786 | Val Loss: 1.2234\n",
      "[Run 1] Ep 25/40 | Train Acc: 0.834 | Val Acc: 0.690 | Train Loss: 0.6748 | Val Loss: 1.0395\n",
      "[Run 1] Ep 26/40 | Train Acc: 0.863 | Val Acc: 0.688 | Train Loss: 0.6103 | Val Loss: 1.0775\n",
      "[Run 1] Ep 27/40 | Train Acc: 0.863 | Val Acc: 0.698 | Train Loss: 0.5749 | Val Loss: 1.0592\n",
      "[Run 1] Ep 28/40 | Train Acc: 0.890 | Val Acc: 0.703 | Train Loss: 0.5452 | Val Loss: 1.0193\n",
      "[Run 1] Ep 29/40 | Train Acc: 0.878 | Val Acc: 0.627 | Train Loss: 0.5261 | Val Loss: 1.2077\n",
      "[Run 1] Ep 30/40 | Train Acc: 0.891 | Val Acc: 0.642 | Train Loss: 0.5125 | Val Loss: 1.2405\n",
      "[Run 1] Ep 31/40 | Train Acc: 0.912 | Val Acc: 0.657 | Train Loss: 0.4489 | Val Loss: 1.1627\n",
      "[Run 1] Ep 32/40 | Train Acc: 0.928 | Val Acc: 0.715 | Train Loss: 0.4203 | Val Loss: 1.0072\n",
      "[Run 1] Ep 33/40 | Train Acc: 0.929 | Val Acc: 0.755 | Train Loss: 0.3808 | Val Loss: 0.8666\n",
      "[Run 1] Ep 34/40 | Train Acc: 0.951 | Val Acc: 0.708 | Train Loss: 0.3426 | Val Loss: 1.0047\n",
      "[Run 1] Ep 35/40 | Train Acc: 0.955 | Val Acc: 0.713 | Train Loss: 0.3254 | Val Loss: 1.0160\n",
      "[Run 1] Ep 36/40 | Train Acc: 0.956 | Val Acc: 0.710 | Train Loss: 0.3044 | Val Loss: 0.9995\n",
      "[Run 1] Ep 37/40 | Train Acc: 0.953 | Val Acc: 0.710 | Train Loss: 0.3010 | Val Loss: 1.0036\n",
      "[Run 1] Ep 38/40 | Train Acc: 0.957 | Val Acc: 0.735 | Train Loss: 0.2880 | Val Loss: 0.8992\n",
      "[Run 1] Ep 39/40 | Train Acc: 0.943 | Val Acc: 0.685 | Train Loss: 0.3153 | Val Loss: 1.0129\n",
      "[Run 1] Ep 40/40 | Train Acc: 0.962 | Val Acc: 0.710 | Train Loss: 0.2693 | Val Loss: 0.9575\n",
      "[Run 1] Early stopping en epoch 40.\n",
      "✅ [Run 1] Mejor Val Acc: 0.755\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▃▄▄▅▅▄▅▅▅▅▅▅▅▆▆▆▆▇▅▇▇▇▇▇▇▇▇▇██▇████▇█</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▅▄▄▅▃▃▄▅▄▃▄▂▃▂▂▂▆▂▂▁▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.755</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>5e-05</td></tr><tr><td>train_acc</td><td>0.96167</td></tr><tr><td>train_loss</td><td>0.26929</td></tr><tr><td>val_acc</td><td>0.71</td></tr><tr><td>val_loss</td><td>0.95747</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18B_run_1_opt-AdamW_lr-0.0003_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/k2jxmqin' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/k2jxmqin</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251024_192720-k2jxmqin/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Iniciando experimento 2 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251024_201807-4v34pn0o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/4v34pn0o' target=\"_blank\">resnet18B_run_2_opt-AdamW_lr-0.0001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/4v34pn0o' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/4v34pn0o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12046/2201489793.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/tmp/ipykernel_12046/2201489793.py:130: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/tmp/ipykernel_12046/2201489793.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Ep 01/40 | Train Acc: 0.074 | Val Acc: 0.145 | Train Loss: 3.5792 | Val Loss: 3.3781\n",
      "[Run 2] Ep 02/40 | Train Acc: 0.177 | Val Acc: 0.198 | Train Loss: 3.1243 | Val Loss: 2.9663\n",
      "[Run 2] Ep 03/40 | Train Acc: 0.238 | Val Acc: 0.255 | Train Loss: 2.8196 | Val Loss: 2.7934\n",
      "[Run 2] Ep 04/40 | Train Acc: 0.306 | Val Acc: 0.325 | Train Loss: 2.6023 | Val Loss: 2.5362\n",
      "[Run 2] Ep 05/40 | Train Acc: 0.338 | Val Acc: 0.328 | Train Loss: 2.4305 | Val Loss: 2.4510\n",
      "[Run 2] Ep 06/40 | Train Acc: 0.413 | Val Acc: 0.333 | Train Loss: 2.2576 | Val Loss: 2.4054\n",
      "[Run 2] Ep 07/40 | Train Acc: 0.407 | Val Acc: 0.438 | Train Loss: 2.1556 | Val Loss: 2.1357\n",
      "[Run 2] Ep 08/40 | Train Acc: 0.493 | Val Acc: 0.453 | Train Loss: 2.0092 | Val Loss: 2.0277\n",
      "[Run 2] Ep 09/40 | Train Acc: 0.502 | Val Acc: 0.415 | Train Loss: 1.8847 | Val Loss: 1.9932\n",
      "[Run 2] Ep 10/40 | Train Acc: 0.532 | Val Acc: 0.480 | Train Loss: 1.7798 | Val Loss: 1.8669\n",
      "[Run 2] Ep 11/40 | Train Acc: 0.561 | Val Acc: 0.492 | Train Loss: 1.6999 | Val Loss: 1.8927\n",
      "[Run 2] Ep 12/40 | Train Acc: 0.573 | Val Acc: 0.497 | Train Loss: 1.6344 | Val Loss: 1.7704\n",
      "[Run 2] Ep 13/40 | Train Acc: 0.588 | Val Acc: 0.430 | Train Loss: 1.5705 | Val Loss: 1.9672\n",
      "[Run 2] Ep 14/40 | Train Acc: 0.626 | Val Acc: 0.507 | Train Loss: 1.4663 | Val Loss: 1.6910\n",
      "[Run 2] Ep 15/40 | Train Acc: 0.639 | Val Acc: 0.527 | Train Loss: 1.4212 | Val Loss: 1.6722\n",
      "[Run 2] Ep 16/40 | Train Acc: 0.671 | Val Acc: 0.552 | Train Loss: 1.3227 | Val Loss: 1.6012\n",
      "[Run 2] Ep 17/40 | Train Acc: 0.700 | Val Acc: 0.578 | Train Loss: 1.2405 | Val Loss: 1.4677\n",
      "[Run 2] Ep 18/40 | Train Acc: 0.712 | Val Acc: 0.580 | Train Loss: 1.2032 | Val Loss: 1.5166\n",
      "[Run 2] Ep 19/40 | Train Acc: 0.730 | Val Acc: 0.645 | Train Loss: 1.1623 | Val Loss: 1.3421\n",
      "[Run 2] Ep 20/40 | Train Acc: 0.741 | Val Acc: 0.635 | Train Loss: 1.1095 | Val Loss: 1.3671\n",
      "[Run 2] Ep 21/40 | Train Acc: 0.755 | Val Acc: 0.637 | Train Loss: 1.0715 | Val Loss: 1.3878\n",
      "[Run 2] Ep 22/40 | Train Acc: 0.795 | Val Acc: 0.630 | Train Loss: 0.9981 | Val Loss: 1.3049\n",
      "[Run 2] Ep 23/40 | Train Acc: 0.799 | Val Acc: 0.665 | Train Loss: 0.9502 | Val Loss: 1.2904\n",
      "[Run 2] Ep 24/40 | Train Acc: 0.816 | Val Acc: 0.645 | Train Loss: 0.9409 | Val Loss: 1.2822\n",
      "[Run 2] Ep 25/40 | Train Acc: 0.818 | Val Acc: 0.627 | Train Loss: 0.8717 | Val Loss: 1.3013\n",
      "[Run 2] Ep 26/40 | Train Acc: 0.830 | Val Acc: 0.675 | Train Loss: 0.8381 | Val Loss: 1.2208\n",
      "[Run 2] Ep 27/40 | Train Acc: 0.829 | Val Acc: 0.693 | Train Loss: 0.8381 | Val Loss: 1.1746\n",
      "[Run 2] Ep 28/40 | Train Acc: 0.858 | Val Acc: 0.680 | Train Loss: 0.7685 | Val Loss: 1.1774\n",
      "[Run 2] Ep 29/40 | Train Acc: 0.865 | Val Acc: 0.685 | Train Loss: 0.7266 | Val Loss: 1.1350\n",
      "[Run 2] Ep 30/40 | Train Acc: 0.872 | Val Acc: 0.645 | Train Loss: 0.7238 | Val Loss: 1.2470\n",
      "[Run 2] Ep 31/40 | Train Acc: 0.863 | Val Acc: 0.670 | Train Loss: 0.7250 | Val Loss: 1.1820\n",
      "[Run 2] Ep 32/40 | Train Acc: 0.873 | Val Acc: 0.642 | Train Loss: 0.6888 | Val Loss: 1.1836\n",
      "[Run 2] Ep 33/40 | Train Acc: 0.913 | Val Acc: 0.665 | Train Loss: 0.5950 | Val Loss: 1.1430\n",
      "[Run 2] Ep 34/40 | Train Acc: 0.921 | Val Acc: 0.660 | Train Loss: 0.5849 | Val Loss: 1.1663\n",
      "[Run 2] Early stopping en epoch 34.\n",
      "✅ [Run 2] Mejor Val Acc: 0.693\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▃▃▃▅▅▄▅▅▆▅▆▆▆▇▇▇▇▇▇█▇▇████▇█▇██</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▅▄▄▄▃▃▃▄▃▃▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6925</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>lr</td><td>2e-05</td></tr><tr><td>train_acc</td><td>0.92083</td></tr><tr><td>train_loss</td><td>0.58494</td></tr><tr><td>val_acc</td><td>0.66</td></tr><tr><td>val_loss</td><td>1.16633</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18B_run_2_opt-AdamW_lr-0.0001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/4v34pn0o' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/4v34pn0o</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251024_201807-4v34pn0o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Iniciando experimento 3 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251024_210103-gmnnqjt4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/gmnnqjt4' target=\"_blank\">resnet18B_run_3_opt-SGD_lr-0.01_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/gmnnqjt4' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/gmnnqjt4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12046/2201489793.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/tmp/ipykernel_12046/2201489793.py:130: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/tmp/ipykernel_12046/2201489793.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Ep 01/40 | Train Acc: 0.045 | Val Acc: 0.037 | Train Loss: 3.9258 | Val Loss: 7.4180\n",
      "[Run 3] Ep 02/40 | Train Acc: 0.103 | Val Acc: 0.098 | Train Loss: 3.3763 | Val Loss: 3.3019\n",
      "[Run 3] Ep 03/40 | Train Acc: 0.137 | Val Acc: 0.138 | Train Loss: 3.1363 | Val Loss: 3.3822\n",
      "[Run 3] Ep 04/40 | Train Acc: 0.188 | Val Acc: 0.180 | Train Loss: 2.8922 | Val Loss: 3.3656\n",
      "[Run 3] Ep 05/40 | Train Acc: 0.219 | Val Acc: 0.230 | Train Loss: 2.7472 | Val Loss: 2.7777\n",
      "[Run 3] Ep 06/40 | Train Acc: 0.294 | Val Acc: 0.138 | Train Loss: 2.4362 | Val Loss: 6.4317\n",
      "[Run 3] Ep 07/40 | Train Acc: 0.323 | Val Acc: 0.195 | Train Loss: 2.2861 | Val Loss: 2.8830\n",
      "[Run 3] Ep 08/40 | Train Acc: 0.352 | Val Acc: 0.285 | Train Loss: 2.1303 | Val Loss: 2.6750\n",
      "[Run 3] Ep 09/40 | Train Acc: 0.436 | Val Acc: 0.463 | Train Loss: 1.8501 | Val Loss: 1.9552\n",
      "[Run 3] Ep 10/40 | Train Acc: 0.498 | Val Acc: 0.425 | Train Loss: 1.6636 | Val Loss: 2.0330\n",
      "[Run 3] Ep 11/40 | Train Acc: 0.519 | Val Acc: 0.347 | Train Loss: 1.5973 | Val Loss: 2.4626\n",
      "[Run 3] Ep 12/40 | Train Acc: 0.541 | Val Acc: 0.480 | Train Loss: 1.4770 | Val Loss: 1.9086\n",
      "[Run 3] Ep 13/40 | Train Acc: 0.570 | Val Acc: 0.395 | Train Loss: 1.4197 | Val Loss: 1.9913\n",
      "[Run 3] Ep 14/40 | Train Acc: 0.598 | Val Acc: 0.487 | Train Loss: 1.3266 | Val Loss: 1.7570\n",
      "[Run 3] Ep 15/40 | Train Acc: 0.586 | Val Acc: 0.470 | Train Loss: 1.3385 | Val Loss: 1.8077\n",
      "[Run 3] Ep 16/40 | Train Acc: 0.647 | Val Acc: 0.500 | Train Loss: 1.1776 | Val Loss: 1.9557\n",
      "[Run 3] Ep 17/40 | Train Acc: 0.689 | Val Acc: 0.535 | Train Loss: 1.0433 | Val Loss: 1.6354\n",
      "[Run 3] Ep 18/40 | Train Acc: 0.723 | Val Acc: 0.578 | Train Loss: 0.9418 | Val Loss: 1.4591\n",
      "[Run 3] Ep 19/40 | Train Acc: 0.754 | Val Acc: 0.547 | Train Loss: 0.8437 | Val Loss: 1.6933\n",
      "[Run 3] Ep 20/40 | Train Acc: 0.754 | Val Acc: 0.562 | Train Loss: 0.8014 | Val Loss: 1.5503\n",
      "[Run 3] Ep 21/40 | Train Acc: 0.782 | Val Acc: 0.497 | Train Loss: 0.7563 | Val Loss: 1.7412\n",
      "[Run 3] Ep 22/40 | Train Acc: 0.802 | Val Acc: 0.565 | Train Loss: 0.6925 | Val Loss: 1.4739\n",
      "[Run 3] Ep 23/40 | Train Acc: 0.802 | Val Acc: 0.600 | Train Loss: 0.7013 | Val Loss: 1.4420\n",
      "[Run 3] Ep 24/40 | Train Acc: 0.837 | Val Acc: 0.530 | Train Loss: 0.6011 | Val Loss: 1.8816\n",
      "[Run 3] Ep 25/40 | Train Acc: 0.863 | Val Acc: 0.635 | Train Loss: 0.5083 | Val Loss: 1.2296\n",
      "[Run 3] Ep 26/40 | Train Acc: 0.898 | Val Acc: 0.625 | Train Loss: 0.4219 | Val Loss: 1.3079\n",
      "[Run 3] Ep 27/40 | Train Acc: 0.885 | Val Acc: 0.635 | Train Loss: 0.4324 | Val Loss: 1.2460\n",
      "[Run 3] Ep 28/40 | Train Acc: 0.902 | Val Acc: 0.627 | Train Loss: 0.3871 | Val Loss: 1.2969\n",
      "[Run 3] Ep 29/40 | Train Acc: 0.917 | Val Acc: 0.608 | Train Loss: 0.3583 | Val Loss: 1.3338\n",
      "[Run 3] Ep 30/40 | Train Acc: 0.908 | Val Acc: 0.588 | Train Loss: 0.3696 | Val Loss: 1.5740\n",
      "[Run 3] Ep 31/40 | Train Acc: 0.917 | Val Acc: 0.630 | Train Loss: 0.3355 | Val Loss: 1.2605\n",
      "[Run 3] Ep 32/40 | Train Acc: 0.923 | Val Acc: 0.610 | Train Loss: 0.2979 | Val Loss: 1.3868\n",
      "[Run 3] Early stopping en epoch 32.\n",
      "✅ [Run 3] Mejor Val Acc: 0.635\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▃▃▂▃▄▆▆▅▆▅▆▆▆▇▇▇▇▆▇█▇█████▇██</td></tr><tr><td>val_loss</td><td>█▃▃▃▃▇▃▃▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.635</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>lr</td><td>0.0024</td></tr><tr><td>train_acc</td><td>0.92333</td></tr><tr><td>train_loss</td><td>0.2979</td></tr><tr><td>val_acc</td><td>0.61</td></tr><tr><td>val_loss</td><td>1.3868</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18B_run_3_opt-SGD_lr-0.01_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/gmnnqjt4' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/gmnnqjt4</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251024_210103-gmnnqjt4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Iniciando experimento 4 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251024_214256-r0odfpgu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/r0odfpgu' target=\"_blank\">resnet18B_run_4_opt-SGD_lr-0.005_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/r0odfpgu' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/r0odfpgu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12046/2201489793.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/tmp/ipykernel_12046/2201489793.py:130: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/tmp/ipykernel_12046/2201489793.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Ep 01/40 | Train Acc: 0.043 | Val Acc: 0.085 | Train Loss: 3.8896 | Val Loss: 3.8443\n",
      "[Run 4] Ep 02/40 | Train Acc: 0.121 | Val Acc: 0.133 | Train Loss: 3.2534 | Val Loss: 3.2584\n",
      "[Run 4] Ep 03/40 | Train Acc: 0.147 | Val Acc: 0.113 | Train Loss: 3.0007 | Val Loss: 3.7560\n",
      "[Run 4] Ep 04/40 | Train Acc: 0.207 | Val Acc: 0.117 | Train Loss: 2.7768 | Val Loss: 3.7708\n",
      "[Run 4] Ep 05/40 | Train Acc: 0.242 | Val Acc: 0.193 | Train Loss: 2.6594 | Val Loss: 3.4791\n",
      "[Run 4] Ep 06/40 | Train Acc: 0.280 | Val Acc: 0.318 | Train Loss: 2.4665 | Val Loss: 2.4036\n",
      "[Run 4] Ep 07/40 | Train Acc: 0.302 | Val Acc: 0.307 | Train Loss: 2.3101 | Val Loss: 2.4136\n",
      "[Run 4] Ep 08/40 | Train Acc: 0.384 | Val Acc: 0.158 | Train Loss: 2.1250 | Val Loss: 3.9287\n",
      "[Run 4] Ep 09/40 | Train Acc: 0.444 | Val Acc: 0.335 | Train Loss: 1.8815 | Val Loss: 2.4721\n",
      "[Run 4] Ep 10/40 | Train Acc: 0.482 | Val Acc: 0.427 | Train Loss: 1.7738 | Val Loss: 2.0257\n",
      "[Run 4] Ep 11/40 | Train Acc: 0.487 | Val Acc: 0.372 | Train Loss: 1.6880 | Val Loss: 2.3087\n",
      "[Run 4] Ep 12/40 | Train Acc: 0.522 | Val Acc: 0.443 | Train Loss: 1.5843 | Val Loss: 1.8982\n",
      "[Run 4] Ep 13/40 | Train Acc: 0.560 | Val Acc: 0.455 | Train Loss: 1.4749 | Val Loss: 1.9940\n",
      "[Run 4] Ep 14/40 | Train Acc: 0.562 | Val Acc: 0.445 | Train Loss: 1.4108 | Val Loss: 1.9228\n",
      "[Run 4] Ep 15/40 | Train Acc: 0.579 | Val Acc: 0.455 | Train Loss: 1.3641 | Val Loss: 2.1205\n",
      "[Run 4] Ep 16/40 | Train Acc: 0.606 | Val Acc: 0.512 | Train Loss: 1.2541 | Val Loss: 1.7553\n",
      "[Run 4] Ep 17/40 | Train Acc: 0.651 | Val Acc: 0.545 | Train Loss: 1.1325 | Val Loss: 1.5562\n",
      "[Run 4] Ep 18/40 | Train Acc: 0.690 | Val Acc: 0.475 | Train Loss: 1.0445 | Val Loss: 1.8295\n",
      "[Run 4] Ep 19/40 | Train Acc: 0.704 | Val Acc: 0.502 | Train Loss: 1.0008 | Val Loss: 1.6318\n",
      "[Run 4] Ep 20/40 | Train Acc: 0.723 | Val Acc: 0.520 | Train Loss: 0.9460 | Val Loss: 1.5686\n",
      "[Run 4] Ep 21/40 | Train Acc: 0.730 | Val Acc: 0.620 | Train Loss: 0.9157 | Val Loss: 1.2361\n",
      "[Run 4] Ep 22/40 | Train Acc: 0.751 | Val Acc: 0.512 | Train Loss: 0.8481 | Val Loss: 1.6118\n",
      "[Run 4] Ep 23/40 | Train Acc: 0.775 | Val Acc: 0.555 | Train Loss: 0.8123 | Val Loss: 1.5691\n",
      "[Run 4] Ep 24/40 | Train Acc: 0.768 | Val Acc: 0.550 | Train Loss: 0.7801 | Val Loss: 1.5440\n",
      "[Run 4] Ep 25/40 | Train Acc: 0.804 | Val Acc: 0.613 | Train Loss: 0.7220 | Val Loss: 1.2746\n",
      "[Run 4] Ep 26/40 | Train Acc: 0.834 | Val Acc: 0.665 | Train Loss: 0.6375 | Val Loss: 1.1820\n",
      "[Run 4] Ep 27/40 | Train Acc: 0.821 | Val Acc: 0.605 | Train Loss: 0.6504 | Val Loss: 1.2815\n",
      "[Run 4] Ep 28/40 | Train Acc: 0.845 | Val Acc: 0.650 | Train Loss: 0.5964 | Val Loss: 1.1945\n",
      "[Run 4] Ep 29/40 | Train Acc: 0.844 | Val Acc: 0.652 | Train Loss: 0.5634 | Val Loss: 1.2523\n",
      "[Run 4] Ep 30/40 | Train Acc: 0.855 | Val Acc: 0.635 | Train Loss: 0.5350 | Val Loss: 1.2943\n",
      "[Run 4] Ep 31/40 | Train Acc: 0.867 | Val Acc: 0.625 | Train Loss: 0.5146 | Val Loss: 1.1649\n",
      "[Run 4] Ep 32/40 | Train Acc: 0.890 | Val Acc: 0.662 | Train Loss: 0.4588 | Val Loss: 1.1765\n",
      "[Run 4] Ep 33/40 | Train Acc: 0.892 | Val Acc: 0.660 | Train Loss: 0.4394 | Val Loss: 1.2122\n",
      "[Run 4] Early stopping en epoch 33.\n",
      "✅ [Run 4] Mejor Val Acc: 0.665\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▂▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█▇██████</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▁▁▂▄▄▂▄▅▄▅▅▅▅▆▇▆▆▆▇▆▇▇▇█▇██████</td></tr><tr><td>val_loss</td><td>█▆██▇▄▄█▄▃▄▃▃▃▃▂▂▃▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.665</td></tr><tr><td>epoch</td><td>33</td></tr><tr><td>lr</td><td>0.0012</td></tr><tr><td>train_acc</td><td>0.89167</td></tr><tr><td>train_loss</td><td>0.43937</td></tr><tr><td>val_acc</td><td>0.66</td></tr><tr><td>val_loss</td><td>1.21223</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18B_run_4_opt-SGD_lr-0.005_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/r0odfpgu' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/r0odfpgu</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251024_214256-r0odfpgu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Iniciando experimento 5 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251024_222422-5k6n8czx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/5k6n8czx' target=\"_blank\">resnet18B_run_5_opt-AdamW_lr-0.0005_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/5k6n8czx' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/5k6n8czx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12046/2201489793.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/tmp/ipykernel_12046/2201489793.py:130: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/tmp/ipykernel_12046/2201489793.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Ep 01/40 | Train Acc: 0.079 | Val Acc: 0.120 | Train Loss: 3.5119 | Val Loss: 3.1722\n",
      "[Run 5] Ep 02/40 | Train Acc: 0.172 | Val Acc: 0.188 | Train Loss: 2.9417 | Val Loss: 3.1277\n",
      "[Run 5] Ep 03/40 | Train Acc: 0.188 | Val Acc: 0.258 | Train Loss: 2.7637 | Val Loss: 2.6846\n",
      "[Run 5] Ep 04/40 | Train Acc: 0.225 | Val Acc: 0.210 | Train Loss: 2.5865 | Val Loss: 3.4357\n",
      "[Run 5] Ep 05/40 | Train Acc: 0.292 | Val Acc: 0.275 | Train Loss: 2.4677 | Val Loss: 2.5049\n",
      "[Run 5] Ep 06/40 | Train Acc: 0.352 | Val Acc: 0.305 | Train Loss: 2.2188 | Val Loss: 2.4990\n",
      "[Run 5] Ep 07/40 | Train Acc: 0.379 | Val Acc: 0.325 | Train Loss: 2.0832 | Val Loss: 2.3268\n",
      "[Run 5] Ep 08/40 | Train Acc: 0.407 | Val Acc: 0.307 | Train Loss: 1.9726 | Val Loss: 2.4265\n",
      "[Run 5] Ep 09/40 | Train Acc: 0.469 | Val Acc: 0.375 | Train Loss: 1.7598 | Val Loss: 2.3247\n",
      "[Run 5] Ep 10/40 | Train Acc: 0.513 | Val Acc: 0.438 | Train Loss: 1.6418 | Val Loss: 1.9117\n",
      "[Run 5] Ep 11/40 | Train Acc: 0.542 | Val Acc: 0.407 | Train Loss: 1.5518 | Val Loss: 1.8636\n",
      "[Run 5] Ep 12/40 | Train Acc: 0.547 | Val Acc: 0.505 | Train Loss: 1.5093 | Val Loss: 1.6053\n",
      "[Run 5] Ep 13/40 | Train Acc: 0.562 | Val Acc: 0.490 | Train Loss: 1.4657 | Val Loss: 1.7407\n",
      "[Run 5] Ep 14/40 | Train Acc: 0.593 | Val Acc: 0.432 | Train Loss: 1.3728 | Val Loss: 2.2054\n",
      "[Run 5] Ep 15/40 | Train Acc: 0.624 | Val Acc: 0.440 | Train Loss: 1.2815 | Val Loss: 1.9946\n",
      "[Run 5] Ep 16/40 | Train Acc: 0.642 | Val Acc: 0.425 | Train Loss: 1.2240 | Val Loss: 2.1152\n",
      "[Run 5] Ep 17/40 | Train Acc: 0.637 | Val Acc: 0.608 | Train Loss: 1.2078 | Val Loss: 1.3366\n",
      "[Run 5] Ep 18/40 | Train Acc: 0.689 | Val Acc: 0.583 | Train Loss: 1.0671 | Val Loss: 1.3699\n",
      "[Run 5] Ep 19/40 | Train Acc: 0.703 | Val Acc: 0.575 | Train Loss: 1.0183 | Val Loss: 1.4409\n",
      "[Run 5] Ep 20/40 | Train Acc: 0.731 | Val Acc: 0.613 | Train Loss: 0.9428 | Val Loss: 1.3519\n",
      "[Run 5] Ep 21/40 | Train Acc: 0.736 | Val Acc: 0.500 | Train Loss: 0.9214 | Val Loss: 1.8213\n",
      "[Run 5] Ep 22/40 | Train Acc: 0.745 | Val Acc: 0.610 | Train Loss: 0.9019 | Val Loss: 1.2552\n",
      "[Run 5] Ep 23/40 | Train Acc: 0.752 | Val Acc: 0.677 | Train Loss: 0.8607 | Val Loss: 1.1246\n",
      "[Run 5] Ep 24/40 | Train Acc: 0.763 | Val Acc: 0.565 | Train Loss: 0.8255 | Val Loss: 1.4881\n",
      "[Run 5] Ep 25/40 | Train Acc: 0.819 | Val Acc: 0.623 | Train Loss: 0.7147 | Val Loss: 1.4517\n",
      "[Run 5] Ep 26/40 | Train Acc: 0.828 | Val Acc: 0.645 | Train Loss: 0.6823 | Val Loss: 1.1325\n",
      "[Run 5] Ep 27/40 | Train Acc: 0.833 | Val Acc: 0.650 | Train Loss: 0.6436 | Val Loss: 1.2035\n",
      "[Run 5] Ep 28/40 | Train Acc: 0.843 | Val Acc: 0.662 | Train Loss: 0.6274 | Val Loss: 1.1417\n",
      "[Run 5] Ep 29/40 | Train Acc: 0.842 | Val Acc: 0.608 | Train Loss: 0.6164 | Val Loss: 1.2875\n",
      "[Run 5] Ep 30/40 | Train Acc: 0.864 | Val Acc: 0.610 | Train Loss: 0.5517 | Val Loss: 1.2970\n",
      "[Run 5] Early stopping en epoch 30.\n",
      "✅ [Run 5] Mejor Val Acc: 0.677\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▂▃▃▄▃▄▅▅▆▆▅▅▅▇▇▇▇▆▇█▇▇███▇▇</td></tr><tr><td>val_loss</td><td>▇▇▆█▅▅▅▅▅▃▃▂▃▄▄▄▂▂▂▂▃▁▁▂▂▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6775</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.86417</td></tr><tr><td>train_loss</td><td>0.55174</td></tr><tr><td>val_acc</td><td>0.61</td></tr><tr><td>val_loss</td><td>1.29696</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18B_run_5_opt-AdamW_lr-0.0005_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/5k6n8czx' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB/runs/5k6n8czx</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251024_222422-5k6n8czx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===========================================\n",
    "# ENTRENAMIENTO - MODELO B (ResNet-18 Audio)\n",
    "# Dataset: data/spectrograms1/base (RAW, sin augment)\n",
    "# Imagen: 228x228\n",
    "# GPU: <= 4 GB compatible\n",
    "# ===========================================\n",
    "\n",
    "import os, random, gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Configuración y utilidades\n",
    "# -----------------------------\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Data (RAW, sin SpecAugment)\n",
    "# -----------------------------\n",
    "DATA_DIR = \"data/spectrograms1/base\"\n",
    "IMG_SIZE = (228, 228)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])   # [-1,1] coherente con modelo A\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\",   transform=transform)\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "print(\"Clases detectadas:\", num_classes)\n",
    "\n",
    "class_names = train_data.classes\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Experimentos\n",
    "# -----------------------------\n",
    "experiments = [\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 3e-4,  \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 1e-4,  \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",   \"lr\": 0.01,  \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",   \"lr\": 0.005, \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 5e-4,  \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "EPOCHS   = 40\n",
    "PATIENCE = 6\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Loop de entrenamiento multi-run\n",
    "# -----------------------------\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    print(f\"\\n===== Iniciando experimento {i} =====\")\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"esc50-modelB\",\n",
    "        name=f\"resnet18B_run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp,\n",
    "        # mode=\"offline\",   # usa esto si no querés subir a la nube\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    # DataLoaders (batch y workers según experimento)\n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # Modelo (tu función resnet18_audio)\n",
    "    # -------------------------------\n",
    "    model = resnet18_audio(num_classes=num_classes, in_channels=1, small_input=True).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if config.optimizer == \"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    # -------------------------------\n",
    "    # Entrenamiento por épocas\n",
    "    # -------------------------------\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "\n",
    "        # --------- Validación ---------\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "\n",
    "        #NUEVO\n",
    "        val_y_true, val_y_pred = [], []\n",
    "\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "                #NUEVO\n",
    "                val_y_true.extend(labels.cpu().numpy().tolist())\n",
    "                val_y_pred.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss = val_loss / max(1, len(val_loader))\n",
    "\n",
    "        # NUEVO: métricas agregadas por época (macro/weighted)\n",
    "        prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"macro\", zero_division=0\n",
    "        )\n",
    "        prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"weighted\", zero_division=0\n",
    "        )\n",
    "\n",
    "        # NUEVO: matriz de confusión (sin normalizar; puedes normalizar en la UI)\n",
    "        cm = confusion_matrix(val_y_true, val_y_pred, labels=list(range(num_classes)))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Registro de métricas\n",
    "        # Nuevas metricas registradas para la evaluacion del modelo por epocas\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1_macro\" : f1_m,\n",
    "            \"val_fi_weighted\" : f1_w,\n",
    "            \"val_precision_macro\" : prec_m,\n",
    "            \"val_recall_macro\" : rec_m,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "            \"val_confusion_matrix\" : wandb.plot.confusion_matrix(\n",
    "                y_true=val_y_true,\n",
    "                preds=val_y_pred,\n",
    "                class_names=class_names\n",
    "            )\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Ep {epoch+1:02d}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping y guardar mejor modelo\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/MODEL_B_resnet18_audio_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > PATIENCE:\n",
    "                print(f\"[Run {i}] Early stopping en epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "        # Limpieza por época\n",
    "        del imgs, labels, outputs, loss\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "\n",
    "    # Limpieza entre runs\n",
    "    wandb.finish()\n",
    "    del model, optimizer, scheduler, scaler\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2e509",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Augmented Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5965d754",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlr_scheduler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StepLR\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\_meta_registrations.py:25\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroi_align\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\_meta_registrations.py:18\u001b[0m, in \u001b[0;36mregister_meta.<locals>.wrapper\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(fn):\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[38;5;241m.\u001b[39m_has_ops():\n\u001b[0;32m     19\u001b[0m         get_meta_lib()\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchvision, op_name), overload_name), fn)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# ENTRENAMIENTO - MODELO B (ResNet-18 Audio)\n",
    "# Dataset: data/spectrograms1/augmented\n",
    "# ===========================================\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# ---- 0) Setup\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---- 1) Data (AUMENTADO en disco; no aplicamos augment extra aquí)\n",
    "DATA_DIR = \"data/spectrograms1/augmented\"\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # [-1, 1] como en A\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\",   transform=transform)\n",
    "\n",
    "# Se sobrescriben adentro del loop según batch_size del experimento\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_data,   batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "print(\"Clases:\", num_classes)\n",
    "\n",
    "# ---- 2) Tu modelo (ya definido arriba en tu notebook)\n",
    "# from resnet18_audio import resnet18_audio  # Usa esta import si lo tienes como .py\n",
    "# Si lo definiste en una celda anterior, simplemente llama resnet18_audio(...)\n",
    "# (No re-importar si está en la misma sesión de Colab)\n",
    "\n",
    "# ---- 3) Experimentos (igual estilo que A)\n",
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001,  \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001,  \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,   \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001,  \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "EPOCHS   = 40\n",
    "PATIENCE = 6\n",
    "\n",
    "# ---- 4) Loop multi-run\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    wandb.init(\n",
    "        project=\"esc50-modelB-augmented\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp,\n",
    "        # mode=\"offline\",  # <- Descomenta si no querés usar API key\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    # Loaders con batch size del experimento\n",
    "    train_loader = DataLoader(\n",
    "        train_data, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    "    )\n",
    "    val_loader   = DataLoader(\n",
    "        val_data,   batch_size=config.batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # --- Modelo B (tu ResNet-18)\n",
    "    model = resnet18_audio(num_classes=num_classes, in_channels=1, small_input=True).to(device)\n",
    "\n",
    "    # --- Criterio / Optimizador / Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "\n",
    "    # --- Entrenamiento con early stopping\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "\n",
    "        # Val\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss = val_loss / max(1, len(val_loader))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping + guardar mejor\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/resnet18_audio_AUG_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > PATIENCE:\n",
    "                print(f\"[Run {i}] Early stopping triggered at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "025edbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17970"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2a743",
   "metadata": {},
   "source": [
    "# Evaluacion de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2655c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
