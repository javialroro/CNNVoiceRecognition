{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5793bd2c",
   "metadata": {},
   "source": [
    "# Dataset Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da012a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando train: 100%|██████████| 1200/1200 [01:04<00:00, 18.71it/s]\n",
      "Procesando val: 100%|██████████| 400/400 [00:10<00:00, 36.41it/s]\n",
      "Procesando test: 100%|██████████| 400/400 [00:10<00:00, 36.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Espectrogramas generados y organizados por división.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "CSV_PATH = \"data/ESC-50-master/meta/esc50.csv\"\n",
    "AUDIO_DIR = \"data/ESC-50-master/audio\"\n",
    "OUTPUT_DIR = \"data/spectrograms1/base\"\n",
    "SR = 22050\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Divisiones basadas en folds\n",
    "TRAIN_FOLDS = [1, 2, 3]\n",
    "VAL_FOLDS   = [4]\n",
    "TEST_FOLDS  = [5]\n",
    "\n",
    "# Crear carpetas base\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split), exist_ok=True)\n",
    "\n",
    "# Leer metadatos\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "def wav_to_spectrogram(wav_path, save_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=SR)\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        S_norm = (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "        S_img = (S_norm * 255).astype(np.uint8)\n",
    "\n",
    "        img = Image.fromarray(S_img).resize(IMG_SIZE).convert(\"L\")\n",
    "        img.save(save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error procesando {wav_path}: {e}\")\n",
    "\n",
    "def process_split(split_name, folds):\n",
    "    df_split = df[df[\"fold\"].isin(folds)]\n",
    "    for _, row in tqdm(df_split.iterrows(), total=len(df_split), desc=f\"Procesando {split_name}\"):\n",
    "        file_name = row[\"filename\"]\n",
    "        label = row[\"category\"]\n",
    "\n",
    "        # Crear carpeta por clase\n",
    "        class_dir = os.path.join(OUTPUT_DIR, split_name, label)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        wav_path = os.path.join(AUDIO_DIR, file_name)\n",
    "        save_path = os.path.join(class_dir, file_name.replace(\".wav\", \".png\"))\n",
    "\n",
    "        if not os.path.exists(save_path):\n",
    "            wav_to_spectrogram(wav_path, save_path)\n",
    "\n",
    "# Generar los tres splits\n",
    "process_split(\"train\", TRAIN_FOLDS)\n",
    "process_split(\"val\", VAL_FOLDS)\n",
    "process_split(\"test\", TEST_FOLDS)\n",
    "\n",
    "print(\"✅ Espectrogramas generados y organizados por división.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6178f7",
   "metadata": {},
   "source": [
    "# Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c26731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=50, dropout=0.5):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        # --- Bloque 1 ---\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        # --- Bloque 2 ---\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        # --- Bloque 3 ---\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.pool3 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        # --- Normalización por capa (importante para tanh) ---\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # --- Capas densas ---\n",
    "        self.fc1 = nn.Linear(32 * 26 * 26, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Inicialización recomendada para tanh\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normalización ligera antes de tanh para evitar saturación\n",
    "        x = self.pool1(torch.tanh(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.tanh(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.tanh(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a0b11",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Raw Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afe49b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Normalización [-1,1] porque LeNet usa tanh\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/spectrograms1/base/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(\"data/spectrograms1/base/val\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e1870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162231-hq5ddrea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea' target=\"_blank\">run_1_opt-Adam_lr-0.001_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Epoch 1/40 | Train Acc: 0.046 | Val Acc: 0.110\n",
      "[Run 1] Epoch 2/40 | Train Acc: 0.097 | Val Acc: 0.113\n",
      "[Run 1] Epoch 3/40 | Train Acc: 0.130 | Val Acc: 0.143\n",
      "[Run 1] Epoch 4/40 | Train Acc: 0.161 | Val Acc: 0.167\n",
      "[Run 1] Epoch 5/40 | Train Acc: 0.189 | Val Acc: 0.203\n",
      "[Run 1] Epoch 6/40 | Train Acc: 0.236 | Val Acc: 0.210\n",
      "[Run 1] Epoch 7/40 | Train Acc: 0.271 | Val Acc: 0.223\n",
      "[Run 1] Epoch 8/40 | Train Acc: 0.264 | Val Acc: 0.270\n",
      "[Run 1] Epoch 9/40 | Train Acc: 0.305 | Val Acc: 0.260\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.368 | Val Acc: 0.277\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.386 | Val Acc: 0.267\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.442 | Val Acc: 0.290\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.473 | Val Acc: 0.300\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.501 | Val Acc: 0.297\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.546 | Val Acc: 0.283\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.591 | Val Acc: 0.307\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.634 | Val Acc: 0.290\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.671 | Val Acc: 0.290\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.710 | Val Acc: 0.313\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.750 | Val Acc: 0.317\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.754 | Val Acc: 0.310\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.799 | Val Acc: 0.307\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.826 | Val Acc: 0.323\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.846 | Val Acc: 0.343\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.856 | Val Acc: 0.327\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.876 | Val Acc: 0.347\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.876 | Val Acc: 0.287\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.896 | Val Acc: 0.310\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.911 | Val Acc: 0.323\n",
      "[Run 1] Epoch 30/40 | Train Acc: 0.921 | Val Acc: 0.353\n",
      "[Run 1] Epoch 31/40 | Train Acc: 0.933 | Val Acc: 0.327\n",
      "[Run 1] Epoch 32/40 | Train Acc: 0.944 | Val Acc: 0.337\n",
      "[Run 1] Epoch 33/40 | Train Acc: 0.948 | Val Acc: 0.330\n",
      "[Run 1] Epoch 34/40 | Train Acc: 0.949 | Val Acc: 0.333\n",
      "[Run 1] Epoch 35/40 | Train Acc: 0.966 | Val Acc: 0.323\n",
      "[Run 1] Epoch 36/40 | Train Acc: 0.968 | Val Acc: 0.340\n",
      "[Run 1] Epoch 37/40 | Train Acc: 0.974 | Val Acc: 0.327\n",
      "[Run 1] Epoch 38/40 | Train Acc: 0.976 | Val Acc: 0.327\n",
      "[Run 1] Epoch 39/40 | Train Acc: 0.974 | Val Acc: 0.317\n",
      "[Run 1] Epoch 40/40 | Train Acc: 0.980 | Val Acc: 0.310\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▄▄▄▆▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇█▇█▆▇▇█▇█▇▇▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▃▃▂▂▂▁▂▁▁▁▁▁▁▂▂▂▂▁▂▂▃▂▃▃▃▃▃▃▄▄▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.35333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.98</td></tr><tr><td>train_loss</td><td>0.17417</td></tr><tr><td>val_acc</td><td>0.31</td></tr><tr><td>val_loss</td><td>3.0484</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-Adam_lr-0.001_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/hq5ddrea</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162231-hq5ddrea/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162435-xrkc46ot</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot' target=\"_blank\">run_2_opt-Adam_lr-0.0005_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Epoch 1/40 | Train Acc: 0.049 | Val Acc: 0.080\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.096 | Val Acc: 0.080\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.120 | Val Acc: 0.150\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.160 | Val Acc: 0.187\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.205 | Val Acc: 0.180\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.254 | Val Acc: 0.237\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.291 | Val Acc: 0.230\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.340 | Val Acc: 0.267\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.393 | Val Acc: 0.283\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.458 | Val Acc: 0.273\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.515 | Val Acc: 0.297\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.551 | Val Acc: 0.300\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.622 | Val Acc: 0.337\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.655 | Val Acc: 0.297\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.686 | Val Acc: 0.323\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.732 | Val Acc: 0.323\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.779 | Val Acc: 0.333\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.802 | Val Acc: 0.323\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.821 | Val Acc: 0.317\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.854 | Val Acc: 0.323\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.852 | Val Acc: 0.330\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.876 | Val Acc: 0.320\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.903 | Val Acc: 0.323\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.907 | Val Acc: 0.310\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.917 | Val Acc: 0.317\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.933 | Val Acc: 0.317\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.940 | Val Acc: 0.323\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.949 | Val Acc: 0.343\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.957 | Val Acc: 0.333\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.964 | Val Acc: 0.317\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.968 | Val Acc: 0.337\n",
      "[Run 2] Epoch 32/40 | Train Acc: 0.977 | Val Acc: 0.323\n",
      "[Run 2] Epoch 33/40 | Train Acc: 0.979 | Val Acc: 0.327\n",
      "[Run 2] Epoch 34/40 | Train Acc: 0.979 | Val Acc: 0.340\n",
      "[Run 2] Epoch 35/40 | Train Acc: 0.976 | Val Acc: 0.320\n",
      "[Run 2] Epoch 36/40 | Train Acc: 0.986 | Val Acc: 0.330\n",
      "[Run 2] Epoch 37/40 | Train Acc: 0.988 | Val Acc: 0.313\n",
      "[Run 2] Epoch 38/40 | Train Acc: 0.981 | Val Acc: 0.303\n",
      "[Run 2] Epoch 39/40 | Train Acc: 0.989 | Val Acc: 0.320\n",
      "[Run 2] Epoch 40/40 | Train Acc: 0.991 | Val Acc: 0.320\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▃▄▄▅▅▆▆▆▇▇█▇▇▇█▇▇▇█▇▇▇▇▇▇██▇█▇██▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.34333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.99143</td></tr><tr><td>train_loss</td><td>0.17701</td></tr><tr><td>val_acc</td><td>0.32</td></tr><tr><td>val_loss</td><td>2.81106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-Adam_lr-0.0005_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/xrkc46ot</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162435-xrkc46ot/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162651-kpvuo89q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q' target=\"_blank\">run_3_opt-Adam_lr-0.001_bs-64</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Epoch 1/40 | Train Acc: 0.049 | Val Acc: 0.103\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.094 | Val Acc: 0.100\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.126 | Val Acc: 0.150\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.156 | Val Acc: 0.170\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.187 | Val Acc: 0.197\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.219 | Val Acc: 0.173\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.228 | Val Acc: 0.190\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.261 | Val Acc: 0.227\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.311 | Val Acc: 0.280\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.314 | Val Acc: 0.253\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.371 | Val Acc: 0.267\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.399 | Val Acc: 0.277\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.472 | Val Acc: 0.297\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.489 | Val Acc: 0.307\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.543 | Val Acc: 0.280\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.576 | Val Acc: 0.337\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.621 | Val Acc: 0.303\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.676 | Val Acc: 0.337\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.691 | Val Acc: 0.320\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.716 | Val Acc: 0.323\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.721 | Val Acc: 0.323\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.751 | Val Acc: 0.323\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.777 | Val Acc: 0.327\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.800 | Val Acc: 0.333\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.831 | Val Acc: 0.337\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.843 | Val Acc: 0.343\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.849 | Val Acc: 0.360\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.861 | Val Acc: 0.373\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.865 | Val Acc: 0.337\n",
      "[Run 3] Epoch 30/40 | Train Acc: 0.873 | Val Acc: 0.353\n",
      "[Run 3] Epoch 31/40 | Train Acc: 0.892 | Val Acc: 0.373\n",
      "[Run 3] Epoch 32/40 | Train Acc: 0.905 | Val Acc: 0.340\n",
      "[Run 3] Epoch 33/40 | Train Acc: 0.918 | Val Acc: 0.350\n",
      "[Run 3] Epoch 34/40 | Train Acc: 0.925 | Val Acc: 0.360\n",
      "[Run 3] Epoch 35/40 | Train Acc: 0.917 | Val Acc: 0.357\n",
      "[Run 3] Epoch 36/40 | Train Acc: 0.931 | Val Acc: 0.353\n",
      "[Run 3] Epoch 37/40 | Train Acc: 0.946 | Val Acc: 0.360\n",
      "[Run 3] Epoch 38/40 | Train Acc: 0.942 | Val Acc: 0.343\n",
      "[Run 3] Epoch 39/40 | Train Acc: 0.947 | Val Acc: 0.333\n",
      "[Run 3] Epoch 40/40 | Train Acc: 0.950 | Val Acc: 0.343\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▃▃▄▆▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██▇▇█▇▇██▇█▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.37333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.95</td></tr><tr><td>train_loss</td><td>0.32957</td></tr><tr><td>val_acc</td><td>0.34333</td></tr><tr><td>val_loss</td><td>2.63842</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-Adam_lr-0.001_bs-64</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/kpvuo89q</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162651-kpvuo89q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_162908-sk1okcp1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1' target=\"_blank\">run_4_opt-SGD_lr-0.01_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Epoch 1/40 | Train Acc: 0.053 | Val Acc: 0.070\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.114 | Val Acc: 0.123\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.156 | Val Acc: 0.157\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.195 | Val Acc: 0.187\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.229 | Val Acc: 0.227\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.238 | Val Acc: 0.270\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.272 | Val Acc: 0.243\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.284 | Val Acc: 0.257\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.304 | Val Acc: 0.260\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.344 | Val Acc: 0.280\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.373 | Val Acc: 0.277\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.372 | Val Acc: 0.297\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.431 | Val Acc: 0.297\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.484 | Val Acc: 0.300\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.496 | Val Acc: 0.293\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.571 | Val Acc: 0.330\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.606 | Val Acc: 0.337\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.664 | Val Acc: 0.330\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.671 | Val Acc: 0.330\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.746 | Val Acc: 0.333\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.776 | Val Acc: 0.323\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.818 | Val Acc: 0.350\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.861 | Val Acc: 0.343\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.863 | Val Acc: 0.323\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.904 | Val Acc: 0.330\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.911 | Val Acc: 0.340\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.936 | Val Acc: 0.317\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.942 | Val Acc: 0.340\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.962 | Val Acc: 0.323\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.967 | Val Acc: 0.330\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.970 | Val Acc: 0.330\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.975 | Val Acc: 0.310\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.976 | Val Acc: 0.330\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.985 | Val Acc: 0.330\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.986 | Val Acc: 0.313\n",
      "[Run 4] Epoch 36/40 | Train Acc: 0.984 | Val Acc: 0.353\n",
      "[Run 4] Epoch 37/40 | Train Acc: 0.993 | Val Acc: 0.333\n",
      "[Run 4] Epoch 38/40 | Train Acc: 0.992 | Val Acc: 0.340\n",
      "[Run 4] Epoch 39/40 | Train Acc: 0.989 | Val Acc: 0.347\n",
      "[Run 4] Epoch 40/40 | Train Acc: 0.993 | Val Acc: 0.343\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇██████████████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▄▅▆▅▆▆▆▆▇▇▇▇▇█▇▇█▇██▇▇█▇█▇▇▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▂▂▂▃▂▃▂▃▃▄▃▄▄▄▄▄▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.35333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.99286</td></tr><tr><td>train_loss</td><td>0.09715</td></tr><tr><td>val_acc</td><td>0.34333</td></tr><tr><td>val_loss</td><td>2.93547</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-SGD_lr-0.01_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/sk1okcp1</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_162908-sk1okcp1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_163129-p4f9num9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9' target=\"_blank\">run_5_opt-SGD_lr-0.001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Epoch 1/40 | Train Acc: 0.039 | Val Acc: 0.067\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.056 | Val Acc: 0.083\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.083 | Val Acc: 0.090\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.107 | Val Acc: 0.100\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.130 | Val Acc: 0.147\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.159 | Val Acc: 0.157\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.185 | Val Acc: 0.180\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.210 | Val Acc: 0.210\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.216 | Val Acc: 0.217\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.257 | Val Acc: 0.227\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.256 | Val Acc: 0.223\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.265 | Val Acc: 0.243\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.266 | Val Acc: 0.270\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.281 | Val Acc: 0.257\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.302 | Val Acc: 0.247\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.302 | Val Acc: 0.273\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.323 | Val Acc: 0.277\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.322 | Val Acc: 0.287\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.346 | Val Acc: 0.267\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.356 | Val Acc: 0.303\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.356 | Val Acc: 0.283\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.364 | Val Acc: 0.307\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.377 | Val Acc: 0.323\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.383 | Val Acc: 0.300\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.386 | Val Acc: 0.313\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.418 | Val Acc: 0.300\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.417 | Val Acc: 0.313\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.422 | Val Acc: 0.317\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.431 | Val Acc: 0.330\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.437 | Val Acc: 0.333\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.454 | Val Acc: 0.310\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.466 | Val Acc: 0.327\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.482 | Val Acc: 0.313\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.499 | Val Acc: 0.313\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.498 | Val Acc: 0.327\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.511 | Val Acc: 0.327\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.517 | Val Acc: 0.313\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.535 | Val Acc: 0.340\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.556 | Val Acc: 0.327\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.553 | Val Acc: 0.317\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▂▃▃▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇█▇▇▇▇▇██▇█▇▇██▇██▇</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.34</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>train_acc</td><td>0.55286</td></tr><tr><td>train_loss</td><td>1.79318</td></tr><tr><td>val_acc</td><td>0.31667</td></tr><tr><td>val_loss</td><td>2.46487</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet/runs/p4f9num9</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_163129-p4f9num9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Transformaciones ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/spectrograms1_split/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(\"data/spectrograms1_split/val\", transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "# === LISTA DE EXPERIMENTOS ===\n",
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 32, \"weight_decay\": 0},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 0.0001},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 64, \"weight_decay\": 0},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,  \"batch_size\": 32, \"weight_decay\": 0.0001},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001, \"batch_size\": 16, \"weight_decay\": 0},\n",
    "]\n",
    "\n",
    "# === ENTRENAR 5 RUNS ===\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    wandb.init(\n",
    "        project=\"esc50-lenet\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    # Actualizar batch size dinámicamente\n",
    "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_data, batch_size=config.batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LeNet5(num_classes=len(train_data.classes)).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    EPOCHS = 40\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1}/{EPOCHS} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f\"models/lenet_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444df42",
   "metadata": {},
   "source": [
    "## Dataset Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26467187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando TRAIN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando VAL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando TEST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset aumentado generado con SpecAugment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "BASE_DIR = \"data/spectrograms1/base\"\n",
    "AUG_DIR = \"data/spectrograms1/augmented\"\n",
    "\n",
    "# Parámetros de SpecAugment (según Park et al., 2019)\n",
    "FREQ_MASK_PARAM = 20      # ancho máximo de bandas de frecuencia a enmascarar\n",
    "TIME_MASK_PARAM = 25      # ancho máximo de regiones de tiempo a enmascarar\n",
    "NUM_FREQ_MASKS = 2        # número de máscaras de frecuencia\n",
    "NUM_TIME_MASKS = 2        # número de máscaras de tiempo\n",
    "\n",
    "# Crear carpetas base del dataset aumentado\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(AUG_DIR, split), exist_ok=True)\n",
    "\n",
    "\n",
    "# === FUNCIÓN PRINCIPAL ===\n",
    "def apply_specaugment(image_path, save_path):\n",
    "    \"\"\"Aplica SpecAugment a una imagen de espectrograma (grises).\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"L\")\n",
    "        spec = np.array(img)\n",
    "\n",
    "        # --- Frequency masking (vertical) ---\n",
    "        for _ in range(NUM_FREQ_MASKS):\n",
    "            f = random.randint(0, FREQ_MASK_PARAM)\n",
    "            if f == 0:\n",
    "                continue\n",
    "            f0 = random.randint(0, spec.shape[0] - f)\n",
    "            spec[f0:f0 + f, :] = 0  # borra bandas de frecuencia\n",
    "\n",
    "        # --- Time masking (horizontal) ---\n",
    "        for _ in range(NUM_TIME_MASKS):\n",
    "            t = random.randint(0, TIME_MASK_PARAM)\n",
    "            if t == 0:\n",
    "                continue\n",
    "            t0 = random.randint(0, spec.shape[1] - t)\n",
    "            spec[:, t0:t0 + t] = 0  # borra regiones de tiempo\n",
    "\n",
    "        aug_img = Image.fromarray(spec)\n",
    "        aug_img.save(save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error procesando {image_path}: {e}\")\n",
    "\n",
    "\n",
    "# === RECORRER TODAS LAS PARTICIONES ===\n",
    "def process_split(split_name):\n",
    "    base_split_path = os.path.join(BASE_DIR, split_name)\n",
    "    aug_split_path = os.path.join(AUG_DIR, split_name)\n",
    "\n",
    "    # recorrer las clases\n",
    "    for class_name in os.listdir(base_split_path):\n",
    "        class_base_path = os.path.join(base_split_path, class_name)\n",
    "        class_aug_path = os.path.join(aug_split_path, class_name)\n",
    "        os.makedirs(class_aug_path, exist_ok=True)\n",
    "\n",
    "        # recorrer las imágenes\n",
    "        images = [f for f in os.listdir(class_base_path) if f.endswith(\".png\")]\n",
    "\n",
    "        for img_file in tqdm(images, desc=f\"{split_name}/{class_name}\", leave=False):\n",
    "            src_path = os.path.join(class_base_path, img_file)\n",
    "            dst_path = os.path.join(class_aug_path, img_file)\n",
    "\n",
    "            # aplicar SpecAugment y guardar\n",
    "            apply_specaugment(src_path, dst_path)\n",
    "\n",
    "\n",
    "# === EJECUCIÓN ===\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"\\nProcesando {split.upper()}...\")\n",
    "    process_split(split)\n",
    "\n",
    "print(\"\\n✅ Dataset aumentado generado con SpecAugment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85f92b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] A dynamic link library (DLL) initialization routine failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchaudio\\__init__.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize extension and backend first\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa  # usort: skip\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compliance, datasets, functional, models, pipelines, transforms, utils  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchcodec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_with_torchcodec, save_with_torchcodec\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchaudio\\_extension\\__init__.py:37\u001b[0m\n\u001b[0;32m     35\u001b[0m _IS_ALIGN_AVAILABLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_TORCHAUDIO_EXT_AVAILABLE:\n\u001b[1;32m---> 37\u001b[0m     \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchaudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchaudio\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     _check_cuda_version()\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchaudio\\_extension\\utils.py:58\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_ops.py:1478\u001b[0m, in \u001b[0;36mload_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_library\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;124;03m    Loads a shared library from the given path into the current process.\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m \n\u001b[0;32m   1468\u001b[0m \u001b[38;5;124;03m    The library being loaded may run global initialization code to register\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;124;03m    custom operators with the PyTorch JIT runtime. This allows dynamically\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;124;03m    loading custom operators. For this, you should compile your operator\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;124;03m    and the static registration code into a shared library object, and then\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;124;03m    call ``torch.ops.load_library('path/to/libcustom.so')`` to load the\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;124;03m    shared object.\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m \n\u001b[0;32m   1475\u001b[0m \u001b[38;5;124;03m    After the library is loaded, it is added to the\u001b[39;00m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;124;03m    ``torch.ops.loaded_libraries`` attribute, a set that may be inspected\u001b[39;00m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;124;03m    for the paths of all libraries loaded using this function.\u001b[39;00m\n\u001b[1;32m-> 1478\u001b[0m \n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;124;03m        path (str): A path to a shared library to load.\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m     path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m   1483\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m   1484\u001b[0m         \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m   1485\u001b[0m         \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m   1486\u001b[0m         \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ctypes\\__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1114] A dynamic link library (DLL) initialization routine failed"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "CSV_PATH = \"data/ESC-50-master/meta/esc50.csv\"\n",
    "AUDIO_DIR = \"data/ESC-50-master/audio\"\n",
    "OUTPUT_DIR = \"data/spectrograms1/augmented1\"\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "N_MELS = 128\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Folds por división\n",
    "TRAIN_FOLDS = [1, 2, 3]\n",
    "VAL_FOLDS   = [4]\n",
    "TEST_FOLDS  = [5]\n",
    "\n",
    "# === TRANSFORMACIONES ===\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_mels=N_MELS\n",
    ")\n",
    "\n",
    "specaugment = torchaudio.transforms.SpecAugment(\n",
    "    freq_mask_param=15,      # enmascaramiento de frecuencia\n",
    "    time_mask_param=35,      # enmascaramiento de tiempo\n",
    "    n_freq_masks=2,\n",
    "    n_time_masks=2\n",
    ")\n",
    "\n",
    "# === FUNCIONES ===\n",
    "def save_spec_image(tensor, save_path):\n",
    "    \"\"\"Convierte un tensor de espectrograma a imagen PNG.\"\"\"\n",
    "    tensor = tensor.squeeze().numpy()\n",
    "    tensor_db = torchaudio.functional.amplitude_to_DB(\n",
    "        torch.tensor(tensor), multiplier=10, amin=1e-10, db_multiplier=0\n",
    "    ).numpy()\n",
    "    tensor_norm = (tensor_db - tensor_db.min()) / (tensor_db.max() - tensor_db.min())\n",
    "    img = (tensor_norm * 255).astype(np.uint8)\n",
    "    Image.fromarray(img).resize(IMG_SIZE).convert(\"L\").save(save_path)\n",
    "\n",
    "def process_split(df, split_name):\n",
    "    \"\"\"Procesa un subconjunto del dataset aplicando SpecAugment.\"\"\"\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Procesando {split_name}\"):\n",
    "        file_name = row[\"filename\"]\n",
    "        label = row[\"category\"]\n",
    "\n",
    "        class_dir = os.path.join(OUTPUT_DIR, split_name, label)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        wav_path = os.path.join(AUDIO_DIR, file_name)\n",
    "        save_path = os.path.join(class_dir, file_name.replace(\".wav\", \".png\"))\n",
    "\n",
    "        try:\n",
    "            # Cargar audio\n",
    "            waveform, sr = torchaudio.load(wav_path)\n",
    "            if sr != SAMPLE_RATE:\n",
    "                waveform = torchaudio.functional.resample(waveform, sr, SAMPLE_RATE)\n",
    "\n",
    "            # Crear mel-espectrograma\n",
    "            mel_spec = mel_transform(waveform)\n",
    "\n",
    "            # Aplicar SpecAugment\n",
    "            augmented_spec = specaugment(mel_spec)\n",
    "\n",
    "            # Guardar como imagen\n",
    "            save_spec_image(augmented_spec, save_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error con {wav_path}: {e}\")\n",
    "\n",
    "# === MAIN ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "splits = {\n",
    "    \"train\": df[df[\"fold\"].isin(TRAIN_FOLDS)],\n",
    "    \"val\":   df[df[\"fold\"].isin(VAL_FOLDS)],\n",
    "    \"test\":  df[df[\"fold\"].isin(TEST_FOLDS)]\n",
    "}\n",
    "\n",
    "for split_name, subset in splits.items():\n",
    "    process_split(subset, split_name)\n",
    "\n",
    "print(\"\\n✅ Dataset aumentado con SpecAugment generado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637852f",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Augmented Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4087f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/spectrograms1/augmented\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==============================\n",
    "# TRANSFORMACIONES\n",
    "# ==============================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3ad64dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181523-3ewxjhu6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6' target=\"_blank\">run_1_opt-Adam_lr-0.001_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Epoch 1/40 | Train Acc: 0.048 | Val Acc: 0.058 | Train Loss: 3.7720 | Val Loss: 3.6313\n",
      "[Run 1] Epoch 2/40 | Train Acc: 0.072 | Val Acc: 0.090 | Train Loss: 3.5444 | Val Loss: 3.5044\n",
      "[Run 1] Epoch 3/40 | Train Acc: 0.098 | Val Acc: 0.083 | Train Loss: 3.4440 | Val Loss: 3.4397\n",
      "[Run 1] Epoch 4/40 | Train Acc: 0.132 | Val Acc: 0.120 | Train Loss: 3.3288 | Val Loss: 3.3846\n",
      "[Run 1] Epoch 5/40 | Train Acc: 0.141 | Val Acc: 0.133 | Train Loss: 3.2640 | Val Loss: 3.3304\n",
      "[Run 1] Epoch 6/40 | Train Acc: 0.138 | Val Acc: 0.140 | Train Loss: 3.2181 | Val Loss: 3.2802\n",
      "[Run 1] Epoch 7/40 | Train Acc: 0.160 | Val Acc: 0.170 | Train Loss: 3.1562 | Val Loss: 3.2503\n",
      "[Run 1] Epoch 8/40 | Train Acc: 0.172 | Val Acc: 0.140 | Train Loss: 3.1305 | Val Loss: 3.2696\n",
      "[Run 1] Epoch 9/40 | Train Acc: 0.194 | Val Acc: 0.128 | Train Loss: 3.0511 | Val Loss: 3.2524\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.204 | Val Acc: 0.130 | Train Loss: 2.9838 | Val Loss: 3.2430\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.219 | Val Acc: 0.140 | Train Loss: 2.9362 | Val Loss: 3.2626\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.247 | Val Acc: 0.150 | Train Loss: 2.8694 | Val Loss: 3.2395\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.261 | Val Acc: 0.175 | Train Loss: 2.7973 | Val Loss: 3.1705\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.282 | Val Acc: 0.160 | Train Loss: 2.7306 | Val Loss: 3.1579\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.294 | Val Acc: 0.185 | Train Loss: 2.6747 | Val Loss: 3.1475\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.324 | Val Acc: 0.203 | Train Loss: 2.5764 | Val Loss: 3.1343\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.350 | Val Acc: 0.170 | Train Loss: 2.4961 | Val Loss: 3.1788\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.375 | Val Acc: 0.160 | Train Loss: 2.3998 | Val Loss: 3.1873\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.400 | Val Acc: 0.177 | Train Loss: 2.3404 | Val Loss: 3.1302\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.431 | Val Acc: 0.190 | Train Loss: 2.2514 | Val Loss: 3.1296\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.453 | Val Acc: 0.198 | Train Loss: 2.1718 | Val Loss: 3.1221\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.473 | Val Acc: 0.195 | Train Loss: 2.1216 | Val Loss: 3.1269\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.521 | Val Acc: 0.190 | Train Loss: 2.0341 | Val Loss: 3.1419\n",
      "[Run 1] Early stopping triggered at epoch 23.\n",
      "✅ [Run 1] Mejor Val Acc: 0.203\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>███████▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▂▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▃▂▄▅▅▆▅▄▄▅▅▇▆▇█▆▆▇▇██▇</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▃▃▃▃▃▃▃▂▁▁▁▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.2025</td></tr><tr><td>epoch</td><td>23</td></tr><tr><td>lr</td><td>0.00049</td></tr><tr><td>train_acc</td><td>0.52083</td></tr><tr><td>train_loss</td><td>2.03415</td></tr><tr><td>val_acc</td><td>0.19</td></tr><tr><td>val_loss</td><td>3.14192</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-Adam_lr-0.001_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/3ewxjhu6</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181523-3ewxjhu6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181631-jvqdd1fb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb' target=\"_blank\">run_2_opt-Adam_lr-0.0005_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Epoch 1/40 | Train Acc: 0.043 | Val Acc: 0.052 | Train Loss: 3.8529 | Val Loss: 3.7090\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.082 | Val Acc: 0.068 | Train Loss: 3.5996 | Val Loss: 3.5511\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.147 | Val Acc: 0.110 | Train Loss: 3.4077 | Val Loss: 3.4791\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.174 | Val Acc: 0.125 | Train Loss: 3.2858 | Val Loss: 3.4160\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.231 | Val Acc: 0.163 | Train Loss: 3.1617 | Val Loss: 3.3699\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.286 | Val Acc: 0.145 | Train Loss: 3.0103 | Val Loss: 3.3281\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.345 | Val Acc: 0.138 | Train Loss: 2.8824 | Val Loss: 3.3323\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.368 | Val Acc: 0.170 | Train Loss: 2.7625 | Val Loss: 3.2698\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.438 | Val Acc: 0.170 | Train Loss: 2.5974 | Val Loss: 3.2337\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.487 | Val Acc: 0.203 | Train Loss: 2.4682 | Val Loss: 3.2199\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.544 | Val Acc: 0.185 | Train Loss: 2.3319 | Val Loss: 3.1940\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.574 | Val Acc: 0.193 | Train Loss: 2.2301 | Val Loss: 3.1899\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.597 | Val Acc: 0.188 | Train Loss: 2.1403 | Val Loss: 3.1952\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.616 | Val Acc: 0.172 | Train Loss: 2.0400 | Val Loss: 3.1872\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.661 | Val Acc: 0.193 | Train Loss: 1.9276 | Val Loss: 3.1541\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.703 | Val Acc: 0.203 | Train Loss: 1.8124 | Val Loss: 3.1598\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.714 | Val Acc: 0.195 | Train Loss: 1.7108 | Val Loss: 3.1498\n",
      "[Run 2] Early stopping triggered at epoch 17.\n",
      "✅ [Run 2] Mejor Val Acc: 0.203\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>███████▄▄▄▄▄▄▄▄▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▃▄▄▄▅▆▆▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▂▄▄▆▅▅▆▆█▇█▇▇███</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.2025</td></tr><tr><td>epoch</td><td>17</td></tr><tr><td>lr</td><td>0.00024</td></tr><tr><td>train_acc</td><td>0.71417</td></tr><tr><td>train_loss</td><td>1.71079</td></tr><tr><td>val_acc</td><td>0.195</td></tr><tr><td>val_loss</td><td>3.14979</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-Adam_lr-0.0005_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/jvqdd1fb</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181631-jvqdd1fb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181724-qbtr0d4y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y' target=\"_blank\">run_3_opt-Adam_lr-0.001_bs-64</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Epoch 1/40 | Train Acc: 0.043 | Val Acc: 0.058 | Train Loss: 3.8034 | Val Loss: 3.6058\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.091 | Val Acc: 0.092 | Train Loss: 3.5447 | Val Loss: 3.4712\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.136 | Val Acc: 0.102 | Train Loss: 3.4030 | Val Loss: 3.3887\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.169 | Val Acc: 0.135 | Train Loss: 3.2755 | Val Loss: 3.3231\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.218 | Val Acc: 0.133 | Train Loss: 3.1499 | Val Loss: 3.2539\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.241 | Val Acc: 0.147 | Train Loss: 3.0370 | Val Loss: 3.2316\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.282 | Val Acc: 0.158 | Train Loss: 2.8991 | Val Loss: 3.1809\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.324 | Val Acc: 0.165 | Train Loss: 2.7669 | Val Loss: 3.1441\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.366 | Val Acc: 0.163 | Train Loss: 2.6337 | Val Loss: 3.1664\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.425 | Val Acc: 0.172 | Train Loss: 2.4882 | Val Loss: 3.1387\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.478 | Val Acc: 0.165 | Train Loss: 2.3758 | Val Loss: 3.1374\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.510 | Val Acc: 0.155 | Train Loss: 2.2650 | Val Loss: 3.1412\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.550 | Val Acc: 0.168 | Train Loss: 2.1278 | Val Loss: 3.1063\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.568 | Val Acc: 0.165 | Train Loss: 2.0408 | Val Loss: 3.1384\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.632 | Val Acc: 0.163 | Train Loss: 1.9175 | Val Loss: 3.1161\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.664 | Val Acc: 0.170 | Train Loss: 1.7933 | Val Loss: 3.1537\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.702 | Val Acc: 0.170 | Train Loss: 1.6758 | Val Loss: 3.1255\n",
      "[Run 3] Early stopping triggered at epoch 17.\n",
      "✅ [Run 3] Mejor Val Acc: 0.172\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>███████▄▄▄▄▄▄▄▄▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▅▄▄▃▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▆▆▆▇█▇██▇██▇██</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▃▂▂▂▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.1725</td></tr><tr><td>epoch</td><td>17</td></tr><tr><td>lr</td><td>0.00049</td></tr><tr><td>train_acc</td><td>0.70167</td></tr><tr><td>train_loss</td><td>1.67584</td></tr><tr><td>val_acc</td><td>0.17</td></tr><tr><td>val_loss</td><td>3.12547</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-Adam_lr-0.001_bs-64</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/qbtr0d4y</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181724-qbtr0d4y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181818-j3lr4kiq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq' target=\"_blank\">run_4_opt-SGD_lr-0.01_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Epoch 1/40 | Train Acc: 0.030 | Val Acc: 0.055 | Train Loss: 3.8714 | Val Loss: 3.7322\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.069 | Val Acc: 0.107 | Train Loss: 3.6054 | Val Loss: 3.4959\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.114 | Val Acc: 0.138 | Train Loss: 3.4025 | Val Loss: 3.4217\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.163 | Val Acc: 0.147 | Train Loss: 3.2395 | Val Loss: 3.3113\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.180 | Val Acc: 0.138 | Train Loss: 3.1176 | Val Loss: 3.2709\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.217 | Val Acc: 0.125 | Train Loss: 2.9857 | Val Loss: 3.3042\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.239 | Val Acc: 0.175 | Train Loss: 2.9135 | Val Loss: 3.1644\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.273 | Val Acc: 0.177 | Train Loss: 2.7594 | Val Loss: 3.1090\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.338 | Val Acc: 0.168 | Train Loss: 2.5928 | Val Loss: 3.1228\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.374 | Val Acc: 0.190 | Train Loss: 2.4608 | Val Loss: 3.0803\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.407 | Val Acc: 0.198 | Train Loss: 2.3363 | Val Loss: 3.0756\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.458 | Val Acc: 0.168 | Train Loss: 2.1976 | Val Loss: 3.0809\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.497 | Val Acc: 0.177 | Train Loss: 2.0757 | Val Loss: 3.0507\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.540 | Val Acc: 0.188 | Train Loss: 1.9183 | Val Loss: 3.0512\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.574 | Val Acc: 0.172 | Train Loss: 1.8057 | Val Loss: 3.1272\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.612 | Val Acc: 0.182 | Train Loss: 1.6817 | Val Loss: 3.0522\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.668 | Val Acc: 0.203 | Train Loss: 1.5133 | Val Loss: 3.0164\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.738 | Val Acc: 0.182 | Train Loss: 1.3499 | Val Loss: 3.0610\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.757 | Val Acc: 0.175 | Train Loss: 1.2552 | Val Loss: 3.0540\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.783 | Val Acc: 0.193 | Train Loss: 1.1626 | Val Loss: 3.0529\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.812 | Val Acc: 0.198 | Train Loss: 1.0500 | Val Loss: 3.0404\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.836 | Val Acc: 0.203 | Train Loss: 0.9570 | Val Loss: 3.0874\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.836 | Val Acc: 0.203 | Train Loss: 0.9112 | Val Loss: 3.1102\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.871 | Val Acc: 0.175 | Train Loss: 0.8196 | Val Loss: 3.1616\n",
      "[Run 4] Early stopping triggered at epoch 24.\n",
      "✅ [Run 4] Mejor Val Acc: 0.203\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▅▅▄▇▇▆▇█▆▇▇▇▇█▇▇████▇</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▄▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.2025</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>lr</td><td>0.00343</td></tr><tr><td>train_acc</td><td>0.87083</td></tr><tr><td>train_loss</td><td>0.81957</td></tr><tr><td>val_acc</td><td>0.175</td></tr><tr><td>val_loss</td><td>3.1616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-SGD_lr-0.01_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/j3lr4kiq</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181818-j3lr4kiq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251018_181930-6zc8df1r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r' target=\"_blank\">run_5_opt-SGD_lr-0.001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Epoch 1/40 | Train Acc: 0.030 | Val Acc: 0.033 | Train Loss: 3.8964 | Val Loss: 3.8509\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.052 | Val Acc: 0.065 | Train Loss: 3.7887 | Val Loss: 3.7278\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.077 | Val Acc: 0.070 | Train Loss: 3.6700 | Val Loss: 3.6275\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.102 | Val Acc: 0.098 | Train Loss: 3.5662 | Val Loss: 3.5627\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.113 | Val Acc: 0.102 | Train Loss: 3.4968 | Val Loss: 3.5199\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.136 | Val Acc: 0.100 | Train Loss: 3.4331 | Val Loss: 3.4835\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.162 | Val Acc: 0.128 | Train Loss: 3.3715 | Val Loss: 3.4573\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.168 | Val Acc: 0.135 | Train Loss: 3.3202 | Val Loss: 3.4273\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.192 | Val Acc: 0.140 | Train Loss: 3.2668 | Val Loss: 3.4107\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.212 | Val Acc: 0.145 | Train Loss: 3.2205 | Val Loss: 3.3904\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.199 | Val Acc: 0.147 | Train Loss: 3.1988 | Val Loss: 3.3770\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.233 | Val Acc: 0.142 | Train Loss: 3.1552 | Val Loss: 3.3622\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.244 | Val Acc: 0.163 | Train Loss: 3.1179 | Val Loss: 3.3390\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.240 | Val Acc: 0.158 | Train Loss: 3.0899 | Val Loss: 3.3280\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.259 | Val Acc: 0.165 | Train Loss: 3.0391 | Val Loss: 3.3157\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.277 | Val Acc: 0.165 | Train Loss: 3.0109 | Val Loss: 3.3039\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.292 | Val Acc: 0.168 | Train Loss: 2.9642 | Val Loss: 3.2855\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.309 | Val Acc: 0.170 | Train Loss: 2.9411 | Val Loss: 3.2824\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.304 | Val Acc: 0.165 | Train Loss: 2.9185 | Val Loss: 3.2721\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.307 | Val Acc: 0.163 | Train Loss: 2.8912 | Val Loss: 3.2679\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.318 | Val Acc: 0.163 | Train Loss: 2.8666 | Val Loss: 3.2556\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.323 | Val Acc: 0.158 | Train Loss: 2.8452 | Val Loss: 3.2533\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.330 | Val Acc: 0.158 | Train Loss: 2.8209 | Val Loss: 3.2512\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.334 | Val Acc: 0.170 | Train Loss: 2.7976 | Val Loss: 3.2268\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.344 | Val Acc: 0.163 | Train Loss: 2.7624 | Val Loss: 3.2317\n",
      "[Run 5] Early stopping triggered at epoch 25.\n",
      "✅ [Run 5] Mejor Val Acc: 0.170\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▃▄▅▄▆▆▆▇▇▇█▇███████▇▇██</td></tr><tr><td>val_loss</td><td>█▇▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.17</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>lr</td><td>0.00034</td></tr><tr><td>train_acc</td><td>0.34417</td></tr><tr><td>train_loss</td><td>2.76239</td></tr><tr><td>val_acc</td><td>0.1625</td></tr><tr><td>val_loss</td><td>3.23165</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented/runs/6zc8df1r</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251018_181930-6zc8df1r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,  \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001, \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# CICLO DE ENTRENAMIENTO (IGUAL AL DATASET 1)\n",
    "# ==============================\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    wandb.init(\n",
    "        project=\"esc50-lenet-augmented\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_data, batch_size=config.batch_size)\n",
    "\n",
    "    model = LeNet5(num_classes=len(train_data.classes)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "\n",
    "    EPOCHS = 40\n",
    "    best_val_acc = 0.0\n",
    "    patience = 6\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # === VALIDACIÓN ===\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # === Early stopping ===\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/lenet5_aug_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > patience:\n",
    "                print(f\"[Run {i}] Early stopping triggered at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f633eb",
   "metadata": {},
   "source": [
    "# Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca37970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Type, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utilidades de convolución\n",
    "# -------------------------\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"Conv 3×3 con padding=1, sin bias (BN lo compensa).\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"Conv 1×1 para proyección en atajos (ajustar canales/stride).\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Bloque residual \"básico\"\n",
    "# -------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Estructura:\n",
    "        Conv3x3 → BN → ReLU → Conv3x3 → BN → (Suma con atajo) → ReLU\n",
    "    Donde el atajo (identity) puede incluir una proyección 1×1 si cambia\n",
    "    la resolución (stride > 1) o el número de canales.\n",
    "    \"\"\"\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1   = norm_layer(planes)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2   = norm_layer(planes)\n",
    "\n",
    "        self.downsample = downsample  # Proyección para el atajo, si aplica\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x  # Atajo\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Alinear dimensiones del atajo si cambió stride o # de canales\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# -----------\n",
    "# ResNet base\n",
    "# -----------\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Constructor general de ResNet con BasicBlock y configuración [2,2,2,2].\n",
    "    Parámetros clave:\n",
    "        - small_input=True: conv1=3×3 s=1 y sin MaxPool (mejor para 64–224 px).\n",
    "        - small_input=False: conv1=7×7 s=2 + MaxPool (clásico de ResNet).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[BasicBlock],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 50,\n",
    "        in_channels: int = 1,\n",
    "        small_input: bool = True,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "\n",
    "        # Capa inicial: variante \"small_input\" recomendada para espectrogramas\n",
    "        if small_input:\n",
    "            # Preserva más detalle inicial (sin MaxPool temprano)\n",
    "            self.conv1   = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.maxpool = nn.Identity()\n",
    "        else:\n",
    "            # Estilo ResNet clásico para entradas grandes\n",
    "            self.conv1   = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.bn1  = norm_layer(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Stages: [64, 128, 256, 512] con [2, 2, 2, 2] bloques\n",
    "        self.layer1 = self._make_layer(block,  64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        # Cabeza de clasificación\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Global Average Pooling\n",
    "        self.fc      = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Inicialización recomendada para ReLU/BN\n",
    "        self._init_weights()\n",
    "\n",
    "    def _make_layer(self, block: Type[BasicBlock], planes: int, blocks: int, stride: int = 1) -> nn.Sequential:\n",
    "        \"\"\"\n",
    "        Crea un stage con 'blocks' bloques. El primer bloque puede hacer downsample\n",
    "        (stride=2) para reducir resolución y duplicar canales.\n",
    "        \"\"\"\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "\n",
    "        # Si cambia resolución o # de canales, proyectamos el atajo (1×1)\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _init_weights(self) -> None:\n",
    "        \"\"\"Inicialización Kaiming para conv; constantes para BN; normal para FC.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Entrada → conv1 → BN → ReLU → (posible MaxPool/Identity)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Stages residuales\n",
    "        x = self.layer1(x)  # 64\n",
    "        x = self.layer2(x)  # 128\n",
    "        x = self.layer3(x)  # 256\n",
    "        x = self.layer4(x)  # 512\n",
    "\n",
    "        # Cabeza\n",
    "        x = self.avgpool(x)           # (B, 512, 1, 1)\n",
    "        x = torch.flatten(x, 1)       # (B, 512)\n",
    "        x = self.fc(x)                # (B, num_classes)\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Fábrica de ResNet-18\n",
    "# -------------------------\n",
    "def resnet18_audio(num_classes: int = 50, in_channels: int = 1, small_input: bool = True) -> ResNet:\n",
    "    \"\"\"\n",
    "    Retorna una ResNet-18 lista para espectrogramas:\n",
    "        - num_classes: # de clases del dataset (ESC-50 → 50)\n",
    "        - in_channels: 1 para grises; 3 si usas RGB (replicar canal)\n",
    "        - small_input: True recomendado para ~128–224 px\n",
    "    \"\"\"\n",
    "    return ResNet(\n",
    "        block=BasicBlock,\n",
    "        layers=[2, 2, 2, 2],\n",
    "        num_classes=num_classes,\n",
    "        in_channels=in_channels,\n",
    "        small_input=small_input,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf849e1",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Raw Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Clases detectadas: 50\n",
      "\n",
      "===== Iniciando experimento 1 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_121513-sk1icg39</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB2/runs/sk1icg39' target=\"_blank\">resnet18B_run_1_opt-AdamW_lr-0.0003_bs-8</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB2/runs/sk1icg39' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB2/runs/sk1icg39</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15696/528800939.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_15696/528800939.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/tmp/ipykernel_15696/528800939.py:162: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Ep 01/40 | Train Acc: 0.074 | Val Acc: 0.083 | Train Loss: 3.5868 | Val Loss: 3.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15696/528800939.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/tmp/ipykernel_15696/528800939.py:162: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Ep 02/40 | Train Acc: 0.147 | Val Acc: 0.145 | Train Loss: 3.0707 | Val Loss: 3.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15696/528800939.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 137\u001b[39m\n\u001b[32m    134\u001b[39m     loss = criterion(outputs, labels)\n\u001b[32m    136\u001b[39m scaler.scale(loss).backward()\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m scaler.update()\n\u001b[32m    140\u001b[39m _, preds = torch.max(outputs, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/torch/amp/grad_scaler.py:462\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    456\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m, (\n\u001b[32m    459\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/torch/amp/grad_scaler.py:356\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    350\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m     **kwargs: Any,\n\u001b[32m    354\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    355\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf_per_device\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    357\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/torch/amp/grad_scaler.py:356\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    350\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m     **kwargs: Any,\n\u001b[32m    354\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    355\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    357\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x78ff85296330>> (for post_run_cell), with arguments args (<ExecutionResult object at 790032def650, execution_count=3 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 790032dedfd0, raw_cell=\"# ===========================================\n",
      "# EN..\" transformed_cell=\"# ===========================================\n",
      "# EN..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/home/javialroro/TEC/2025%20II/IA/CNNVoiceRecognition/source.ipynb#X22sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "Connection lost",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionResetError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/wandb/sdk/wandb_init.py:595\u001b[39m, in \u001b[36m_WandbInit._post_run_cell_hook\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    592\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    594\u001b[39m \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33mresuming backend\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/wandb/sdk/interface/interface.py:818\u001b[39m, in \u001b[36mInterfaceBase.publish_resume\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    816\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    817\u001b[39m     resume = pb.ResumeRequest()\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/wandb/sdk/interface/interface_shared.py:296\u001b[39m, in \u001b[36mInterfaceShared._publish_resume\u001b[39m\u001b[34m(self, resume)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb.ResumeRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    295\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m._make_request(resume=resume)\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/wandb/sdk/interface/interface_sock.py:43\u001b[39m, in \u001b[36mInterfaceSock._publish\u001b[39m\u001b[34m(self, record, local)\u001b[39m\n\u001b[32m     41\u001b[39m request = spb.ServerRequest()\n\u001b[32m     42\u001b[39m request.record_publish.CopyFrom(record)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_asyncer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[39m, in \u001b[36mAsyncioManager.run\u001b[39m\u001b[34m(self, fn)\u001b[39m\n\u001b[32m    133\u001b[39m future = \u001b[38;5;28mself\u001b[39m._schedule(fn, daemon=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent.futures.CancelledError:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[39m, in \u001b[36mAsyncioManager._wrap\u001b[39m\u001b[34m(self, fn, daemon, name)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task := asyncio.current_task()):\n\u001b[32m    217\u001b[39m         task.set_name(name)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[39m, in \u001b[36mServiceClient.publish\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_server_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[39m, in \u001b[36mServiceClient._send_server_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     61\u001b[39m data = request.SerializeToString()\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m._writer.write(data)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._writer.drain()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/asyncio/streams.py:386\u001b[39m, in \u001b[36mStreamWriter.drain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing():\n\u001b[32m    376\u001b[39m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[32m    377\u001b[39m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol._drain_helper()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.13/asyncio/streams.py:166\u001b[39m, in \u001b[36mFlowControlMixin._drain_helper\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_drain_helper\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection_lost:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionResetError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mConnection lost\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._paused:\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mConnectionResetError\u001b[39m: Connection lost"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# ENTRENAMIENTO - MODELO B (ResNet-18 Audio)\n",
    "# Dataset: data/spectrograms1/base (RAW, sin augment)\n",
    "# Imagen: 228x228\n",
    "# GPU: <= 4 GB compatible\n",
    "# ===========================================\n",
    "\n",
    "import os, random, gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Configuración y utilidades\n",
    "# -----------------------------\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Data (RAW)\n",
    "# -----------------------------\n",
    "DATA_DIR = \"data/spectrograms1/base\"\n",
    "IMG_SIZE = (228, 228)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # [-1,1]\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\",   transform=transform)\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "class_names = train_data.classes\n",
    "print(\"Clases detectadas:\", num_classes)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Experimentos\n",
    "# -----------------------------\n",
    "experiments = [\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 3e-4,  \"batch_size\": 8, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 1e-4,  \"batch_size\": 8, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",   \"lr\": 0.01,  \"batch_size\": 8, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",   \"lr\": 0.005, \"batch_size\": 8, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 5e-4,  \"batch_size\": 12, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "EPOCHS   = 40\n",
    "PATIENCE = 6\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Loop multi-run\n",
    "# -----------------------------\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    print(f\"\\n===== Iniciando experimento {i} =====\")\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"esc50-modelB\",\n",
    "        name=f\"resnet18B_run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp,\n",
    "        # mode=\"offline\",\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # Modelo (ResNet-18 personalizada)\n",
    "    # -------------------------------\n",
    "    model = resnet18_audio(num_classes=num_classes, in_channels=1, small_input=True).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if config.optimizer == \"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "    scaler = GradScaler('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    # -------------------------------\n",
    "    # Entrenamiento por épocas\n",
    "    # -------------------------------\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            # Limpieza batch\n",
    "            del imgs, labels, outputs, loss, preds\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "\n",
    "        # --------- Validación ---------\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        val_y_true, val_y_pred = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs = imgs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item()\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "                val_y_true.extend(labels.cpu().tolist())\n",
    "                val_y_pred.extend(preds.cpu().tolist())\n",
    "\n",
    "                del imgs, labels, outputs, preds, loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss = val_loss / max(1, len(val_loader))\n",
    "\n",
    "        # --- Métricas adicionales\n",
    "        prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"macro\", zero_division=0\n",
    "        )\n",
    "        prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"weighted\", zero_division=0\n",
    "        )\n",
    "\n",
    "        scheduler.step()\n",
    "        gc.collect()\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1_macro\": f1_m,\n",
    "            \"val_f1_weighted\": f1_w,\n",
    "            \"val_precision_macro\": prec_m,\n",
    "            \"val_recall_macro\": rec_m,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "            \"val_confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                y_true=val_y_true,\n",
    "                preds=val_y_pred,\n",
    "                class_names=class_names\n",
    "            )\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Ep {epoch+1:02d}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # --- Early stopping y guardado\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/MODEL_B_resnet18_audio_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > PATIENCE:\n",
    "                print(f\"[Run {i}] Early stopping en epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "\n",
    "    wandb.finish()\n",
    "    del model, optimizer, scheduler, scaler\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2e509",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Augmented Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5965d754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javialroro/miniconda3/envs/ml/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/javialroro/miniconda3/envs/ml/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Clases: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjavialroro\u001b[0m (\u001b[33mjavialroro-tecnologico-de-costa-rica\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_124130-vx6l8e6e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/vx6l8e6e' target=\"_blank\">run_1_opt-Adam_lr-0.001_bs-8</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/vx6l8e6e' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/vx6l8e6e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Epoch 01/40 | Train Acc: 0.028 | Val Acc: 0.062 | Train Loss: 3.9371 | Val Loss: 3.7019\n",
      "[Run 1] Epoch 02/40 | Train Acc: 0.052 | Val Acc: 0.065 | Train Loss: 3.6587 | Val Loss: 3.5678\n",
      "[Run 1] Epoch 02/40 | Train Acc: 0.052 | Val Acc: 0.065 | Train Loss: 3.6587 | Val Loss: 3.5678\n",
      "[Run 1] Epoch 03/40 | Train Acc: 0.059 | Val Acc: 0.095 | Train Loss: 3.5390 | Val Loss: 3.6986\n",
      "[Run 1] Epoch 03/40 | Train Acc: 0.059 | Val Acc: 0.095 | Train Loss: 3.5390 | Val Loss: 3.6986\n",
      "[Run 1] Epoch 04/40 | Train Acc: 0.114 | Val Acc: 0.125 | Train Loss: 3.2836 | Val Loss: 3.1744\n",
      "[Run 1] Epoch 04/40 | Train Acc: 0.114 | Val Acc: 0.125 | Train Loss: 3.2836 | Val Loss: 3.1744\n",
      "[Run 1] Epoch 05/40 | Train Acc: 0.128 | Val Acc: 0.188 | Train Loss: 3.1629 | Val Loss: 2.9689\n",
      "[Run 1] Epoch 05/40 | Train Acc: 0.128 | Val Acc: 0.188 | Train Loss: 3.1629 | Val Loss: 2.9689\n",
      "[Run 1] Epoch 06/40 | Train Acc: 0.149 | Val Acc: 0.087 | Train Loss: 2.9977 | Val Loss: 4.6198\n",
      "[Run 1] Epoch 06/40 | Train Acc: 0.149 | Val Acc: 0.087 | Train Loss: 2.9977 | Val Loss: 4.6198\n",
      "[Run 1] Epoch 07/40 | Train Acc: 0.159 | Val Acc: 0.198 | Train Loss: 2.9176 | Val Loss: 2.9035\n",
      "[Run 1] Epoch 07/40 | Train Acc: 0.159 | Val Acc: 0.198 | Train Loss: 2.9176 | Val Loss: 2.9035\n",
      "[Run 1] Epoch 08/40 | Train Acc: 0.192 | Val Acc: 0.242 | Train Loss: 2.8454 | Val Loss: 2.8034\n",
      "[Run 1] Epoch 08/40 | Train Acc: 0.192 | Val Acc: 0.242 | Train Loss: 2.8454 | Val Loss: 2.8034\n",
      "[Run 1] Epoch 09/40 | Train Acc: 0.223 | Val Acc: 0.263 | Train Loss: 2.6965 | Val Loss: 2.6547\n",
      "[Run 1] Epoch 09/40 | Train Acc: 0.223 | Val Acc: 0.263 | Train Loss: 2.6965 | Val Loss: 2.6547\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.259 | Val Acc: 0.312 | Train Loss: 2.5843 | Val Loss: 2.4316\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.259 | Val Acc: 0.312 | Train Loss: 2.5843 | Val Loss: 2.4316\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.278 | Val Acc: 0.323 | Train Loss: 2.5161 | Val Loss: 2.4470\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.278 | Val Acc: 0.323 | Train Loss: 2.5161 | Val Loss: 2.4470\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.314 | Val Acc: 0.278 | Train Loss: 2.3134 | Val Loss: 2.4421\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.314 | Val Acc: 0.278 | Train Loss: 2.3134 | Val Loss: 2.4421\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.333 | Val Acc: 0.290 | Train Loss: 2.3123 | Val Loss: 2.3562\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.333 | Val Acc: 0.290 | Train Loss: 2.3123 | Val Loss: 2.3562\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.329 | Val Acc: 0.370 | Train Loss: 2.2095 | Val Loss: 2.1918\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.329 | Val Acc: 0.370 | Train Loss: 2.2095 | Val Loss: 2.1918\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.371 | Val Acc: 0.250 | Train Loss: 2.0918 | Val Loss: 3.4596\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.371 | Val Acc: 0.250 | Train Loss: 2.0918 | Val Loss: 3.4596\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.372 | Val Acc: 0.357 | Train Loss: 2.0553 | Val Loss: 2.5266\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.372 | Val Acc: 0.357 | Train Loss: 2.0553 | Val Loss: 2.5266\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.452 | Val Acc: 0.250 | Train Loss: 1.8779 | Val Loss: 2.9011\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.452 | Val Acc: 0.250 | Train Loss: 1.8779 | Val Loss: 2.9011\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.465 | Val Acc: 0.398 | Train Loss: 1.7674 | Val Loss: 2.0458\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.465 | Val Acc: 0.398 | Train Loss: 1.7674 | Val Loss: 2.0458\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.468 | Val Acc: 0.492 | Train Loss: 1.7097 | Val Loss: 1.7265\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.468 | Val Acc: 0.492 | Train Loss: 1.7097 | Val Loss: 1.7265\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.490 | Val Acc: 0.403 | Train Loss: 1.6468 | Val Loss: 2.0795\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.490 | Val Acc: 0.403 | Train Loss: 1.6468 | Val Loss: 2.0795\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.518 | Val Acc: 0.443 | Train Loss: 1.5951 | Val Loss: 1.8512\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.518 | Val Acc: 0.443 | Train Loss: 1.5951 | Val Loss: 1.8512\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.535 | Val Acc: 0.475 | Train Loss: 1.5320 | Val Loss: 1.7528\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.535 | Val Acc: 0.475 | Train Loss: 1.5320 | Val Loss: 1.7528\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.553 | Val Acc: 0.448 | Train Loss: 1.4703 | Val Loss: 1.7990\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.553 | Val Acc: 0.448 | Train Loss: 1.4703 | Val Loss: 1.7990\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.593 | Val Acc: 0.485 | Train Loss: 1.4058 | Val Loss: 1.6817\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.593 | Val Acc: 0.485 | Train Loss: 1.4058 | Val Loss: 1.6817\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.623 | Val Acc: 0.525 | Train Loss: 1.2568 | Val Loss: 1.7353\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.623 | Val Acc: 0.525 | Train Loss: 1.2568 | Val Loss: 1.7353\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.646 | Val Acc: 0.520 | Train Loss: 1.1870 | Val Loss: 1.5795\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.646 | Val Acc: 0.520 | Train Loss: 1.1870 | Val Loss: 1.5795\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.666 | Val Acc: 0.540 | Train Loss: 1.0975 | Val Loss: 1.5546\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.666 | Val Acc: 0.540 | Train Loss: 1.0975 | Val Loss: 1.5546\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.692 | Val Acc: 0.515 | Train Loss: 1.0489 | Val Loss: 1.5603\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.692 | Val Acc: 0.515 | Train Loss: 1.0489 | Val Loss: 1.5603\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.691 | Val Acc: 0.560 | Train Loss: 1.0516 | Val Loss: 1.4767\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.691 | Val Acc: 0.560 | Train Loss: 1.0516 | Val Loss: 1.4767\n",
      "[Run 1] Epoch 30/40 | Train Acc: 0.705 | Val Acc: 0.505 | Train Loss: 0.9799 | Val Loss: 1.5722\n",
      "[Run 1] Epoch 30/40 | Train Acc: 0.705 | Val Acc: 0.505 | Train Loss: 0.9799 | Val Loss: 1.5722\n",
      "[Run 1] Epoch 31/40 | Train Acc: 0.737 | Val Acc: 0.532 | Train Loss: 0.9117 | Val Loss: 1.6251\n",
      "[Run 1] Epoch 31/40 | Train Acc: 0.737 | Val Acc: 0.532 | Train Loss: 0.9117 | Val Loss: 1.6251\n",
      "[Run 1] Epoch 32/40 | Train Acc: 0.746 | Val Acc: 0.487 | Train Loss: 0.8565 | Val Loss: 1.7569\n",
      "[Run 1] Epoch 32/40 | Train Acc: 0.746 | Val Acc: 0.487 | Train Loss: 0.8565 | Val Loss: 1.7569\n",
      "[Run 1] Epoch 33/40 | Train Acc: 0.802 | Val Acc: 0.557 | Train Loss: 0.7377 | Val Loss: 1.3800\n",
      "[Run 1] Epoch 33/40 | Train Acc: 0.802 | Val Acc: 0.557 | Train Loss: 0.7377 | Val Loss: 1.3800\n",
      "[Run 1] Epoch 34/40 | Train Acc: 0.813 | Val Acc: 0.605 | Train Loss: 0.6909 | Val Loss: 1.3365\n",
      "[Run 1] Epoch 34/40 | Train Acc: 0.813 | Val Acc: 0.605 | Train Loss: 0.6909 | Val Loss: 1.3365\n",
      "[Run 1] Epoch 35/40 | Train Acc: 0.836 | Val Acc: 0.600 | Train Loss: 0.6527 | Val Loss: 1.3606\n",
      "[Run 1] Epoch 35/40 | Train Acc: 0.836 | Val Acc: 0.600 | Train Loss: 0.6527 | Val Loss: 1.3606\n",
      "[Run 1] Epoch 36/40 | Train Acc: 0.838 | Val Acc: 0.510 | Train Loss: 0.6393 | Val Loss: 1.6568\n",
      "[Run 1] Epoch 36/40 | Train Acc: 0.838 | Val Acc: 0.510 | Train Loss: 0.6393 | Val Loss: 1.6568\n",
      "[Run 1] Epoch 37/40 | Train Acc: 0.841 | Val Acc: 0.613 | Train Loss: 0.6007 | Val Loss: 1.3336\n",
      "[Run 1] Epoch 37/40 | Train Acc: 0.841 | Val Acc: 0.613 | Train Loss: 0.6007 | Val Loss: 1.3336\n",
      "[Run 1] Epoch 38/40 | Train Acc: 0.859 | Val Acc: 0.515 | Train Loss: 0.5464 | Val Loss: 1.5264\n",
      "[Run 1] Epoch 38/40 | Train Acc: 0.859 | Val Acc: 0.515 | Train Loss: 0.5464 | Val Loss: 1.5264\n",
      "[Run 1] Epoch 39/40 | Train Acc: 0.859 | Val Acc: 0.550 | Train Loss: 0.5712 | Val Loss: 1.5111\n",
      "[Run 1] Epoch 39/40 | Train Acc: 0.859 | Val Acc: 0.550 | Train Loss: 0.5712 | Val Loss: 1.5111\n",
      "[Run 1] Epoch 40/40 | Train Acc: 0.891 | Val Acc: 0.588 | Train Loss: 0.4625 | Val Loss: 1.4529\n",
      "✅ [Run 1] Mejor Val Acc: 0.613\n",
      "[Run 1] Epoch 40/40 | Train Acc: 0.891 | Val Acc: 0.588 | Train Loss: 0.4625 | Val Loss: 1.4529\n",
      "✅ [Run 1] Mejor Val Acc: 0.613\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▂▃▁▃▃▄▄▄▄▄▅▃▅▃▅▆▅▆▆▆▆▇▇▇▇▇▇▇▆▇██▇█▇▇█</td></tr><tr><td>val_f1_macro</td><td>▁▁▁▂▂▁▃▃▄▄▄▄▄▅▃▅▃▅▆▅▆▆▆▆▇▇▇▇▇▇▇▆▇██▇█▇▇▇</td></tr><tr><td>val_f1_weighted</td><td>▁▁▁▂▂▁▃▃▄▄▄▄▄▅▃▅▃▅▆▅▆▆▆▆▇▇▇▇▇▇▇▆▇██▇█▇▇▇</td></tr><tr><td>val_loss</td><td>▆▆▆▅▄█▄▄▄▃▃▃▃▃▆▄▄▃▂▃▂▂▂▂▂▂▁▁▁▂▂▂▁▁▁▂▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▁▂▂▂▃▂▄▄▅▄▄▅▄▅▄▆▆▆▆▆▆▇▇▇▇▇██▇▇▇▇█▇█▇██</td></tr><tr><td>val_recall_macro</td><td>▁▁▁▂▃▁▃▃▄▄▄▄▄▅▃▅▃▅▆▅▆▆▆▆▇▇▇▇▇▇▇▆▇██▇█▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6125</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.89083</td></tr><tr><td>train_loss</td><td>0.46251</td></tr><tr><td>val_acc</td><td>0.5875</td></tr><tr><td>val_f1_macro</td><td>0.55876</td></tr><tr><td>val_f1_weighted</td><td>0.55876</td></tr><tr><td>val_loss</td><td>1.45288</td></tr><tr><td>val_precision_macro</td><td>0.61456</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-Adam_lr-0.001_bs-8</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/vx6l8e6e' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/vx6l8e6e</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_124130-vx6l8e6e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_132022-x58mqrbm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/x58mqrbm' target=\"_blank\">run_2_opt-Adam_lr-0.0005_bs-8</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/x58mqrbm' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/x58mqrbm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Epoch 01/40 | Train Acc: 0.057 | Val Acc: 0.060 | Train Loss: 3.7364 | Val Loss: 3.7073\n",
      "[Run 2] Epoch 02/40 | Train Acc: 0.084 | Val Acc: 0.090 | Train Loss: 3.3562 | Val Loss: 3.4327\n",
      "[Run 2] Epoch 02/40 | Train Acc: 0.084 | Val Acc: 0.090 | Train Loss: 3.3562 | Val Loss: 3.4327\n",
      "[Run 2] Epoch 03/40 | Train Acc: 0.111 | Val Acc: 0.152 | Train Loss: 3.2064 | Val Loss: 3.1589\n",
      "[Run 2] Epoch 03/40 | Train Acc: 0.111 | Val Acc: 0.152 | Train Loss: 3.2064 | Val Loss: 3.1589\n",
      "[Run 2] Epoch 04/40 | Train Acc: 0.147 | Val Acc: 0.205 | Train Loss: 3.0393 | Val Loss: 2.8981\n",
      "[Run 2] Epoch 04/40 | Train Acc: 0.147 | Val Acc: 0.205 | Train Loss: 3.0393 | Val Loss: 2.8981\n",
      "[Run 2] Epoch 05/40 | Train Acc: 0.145 | Val Acc: 0.182 | Train Loss: 2.9506 | Val Loss: 3.0472\n",
      "[Run 2] Epoch 05/40 | Train Acc: 0.145 | Val Acc: 0.182 | Train Loss: 2.9506 | Val Loss: 3.0472\n",
      "[Run 2] Epoch 06/40 | Train Acc: 0.227 | Val Acc: 0.302 | Train Loss: 2.7572 | Val Loss: 2.6592\n",
      "[Run 2] Epoch 06/40 | Train Acc: 0.227 | Val Acc: 0.302 | Train Loss: 2.7572 | Val Loss: 2.6592\n",
      "[Run 2] Epoch 07/40 | Train Acc: 0.247 | Val Acc: 0.295 | Train Loss: 2.6283 | Val Loss: 2.5033\n",
      "[Run 2] Epoch 07/40 | Train Acc: 0.247 | Val Acc: 0.295 | Train Loss: 2.6283 | Val Loss: 2.5033\n",
      "[Run 2] Epoch 08/40 | Train Acc: 0.286 | Val Acc: 0.217 | Train Loss: 2.4979 | Val Loss: 2.8006\n",
      "[Run 2] Epoch 08/40 | Train Acc: 0.286 | Val Acc: 0.217 | Train Loss: 2.4979 | Val Loss: 2.8006\n",
      "[Run 2] Epoch 09/40 | Train Acc: 0.310 | Val Acc: 0.347 | Train Loss: 2.3209 | Val Loss: 2.2354\n",
      "[Run 2] Epoch 09/40 | Train Acc: 0.310 | Val Acc: 0.347 | Train Loss: 2.3209 | Val Loss: 2.2354\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.334 | Val Acc: 0.398 | Train Loss: 2.2498 | Val Loss: 2.1357\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.334 | Val Acc: 0.398 | Train Loss: 2.2498 | Val Loss: 2.1357\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.375 | Val Acc: 0.380 | Train Loss: 2.1132 | Val Loss: 2.1397\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.375 | Val Acc: 0.380 | Train Loss: 2.1132 | Val Loss: 2.1397\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.390 | Val Acc: 0.338 | Train Loss: 2.1025 | Val Loss: 2.3779\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.390 | Val Acc: 0.338 | Train Loss: 2.1025 | Val Loss: 2.3779\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.405 | Val Acc: 0.355 | Train Loss: 1.9691 | Val Loss: 2.2254\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.405 | Val Acc: 0.355 | Train Loss: 1.9691 | Val Loss: 2.2254\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.395 | Val Acc: 0.400 | Train Loss: 1.9904 | Val Loss: 2.0466\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.395 | Val Acc: 0.400 | Train Loss: 1.9904 | Val Loss: 2.0466\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.439 | Val Acc: 0.395 | Train Loss: 1.8581 | Val Loss: 2.2147\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.439 | Val Acc: 0.395 | Train Loss: 1.8581 | Val Loss: 2.2147\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.466 | Val Acc: 0.443 | Train Loss: 1.8039 | Val Loss: 1.9718\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.466 | Val Acc: 0.443 | Train Loss: 1.8039 | Val Loss: 1.9718\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.493 | Val Acc: 0.458 | Train Loss: 1.6285 | Val Loss: 1.9257\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.493 | Val Acc: 0.458 | Train Loss: 1.6285 | Val Loss: 1.9257\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.525 | Val Acc: 0.482 | Train Loss: 1.5869 | Val Loss: 1.8082\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.525 | Val Acc: 0.482 | Train Loss: 1.5869 | Val Loss: 1.8082\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.532 | Val Acc: 0.430 | Train Loss: 1.5767 | Val Loss: 1.9489\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.532 | Val Acc: 0.430 | Train Loss: 1.5767 | Val Loss: 1.9489\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.568 | Val Acc: 0.517 | Train Loss: 1.4269 | Val Loss: 1.7752\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.568 | Val Acc: 0.517 | Train Loss: 1.4269 | Val Loss: 1.7752\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.567 | Val Acc: 0.455 | Train Loss: 1.4461 | Val Loss: 1.9663\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.567 | Val Acc: 0.455 | Train Loss: 1.4461 | Val Loss: 1.9663\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.598 | Val Acc: 0.477 | Train Loss: 1.3198 | Val Loss: 1.7585\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.598 | Val Acc: 0.477 | Train Loss: 1.3198 | Val Loss: 1.7585\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.601 | Val Acc: 0.522 | Train Loss: 1.2991 | Val Loss: 1.7107\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.601 | Val Acc: 0.522 | Train Loss: 1.2991 | Val Loss: 1.7107\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.631 | Val Acc: 0.573 | Train Loss: 1.2533 | Val Loss: 1.5624\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.631 | Val Acc: 0.573 | Train Loss: 1.2533 | Val Loss: 1.5624\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.656 | Val Acc: 0.552 | Train Loss: 1.1943 | Val Loss: 1.5512\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.656 | Val Acc: 0.552 | Train Loss: 1.1943 | Val Loss: 1.5512\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.690 | Val Acc: 0.527 | Train Loss: 1.0865 | Val Loss: 1.6282\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.690 | Val Acc: 0.527 | Train Loss: 1.0865 | Val Loss: 1.6282\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.682 | Val Acc: 0.552 | Train Loss: 1.0407 | Val Loss: 1.5878\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.682 | Val Acc: 0.552 | Train Loss: 1.0407 | Val Loss: 1.5878\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.713 | Val Acc: 0.555 | Train Loss: 1.0006 | Val Loss: 1.6150\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.713 | Val Acc: 0.555 | Train Loss: 1.0006 | Val Loss: 1.6150\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.734 | Val Acc: 0.570 | Train Loss: 0.9243 | Val Loss: 1.5095\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.734 | Val Acc: 0.570 | Train Loss: 0.9243 | Val Loss: 1.5095\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.750 | Val Acc: 0.475 | Train Loss: 0.8718 | Val Loss: 1.8375\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.750 | Val Acc: 0.475 | Train Loss: 0.8718 | Val Loss: 1.8375\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.729 | Val Acc: 0.545 | Train Loss: 0.9299 | Val Loss: 1.5824\n",
      "[Run 2] Early stopping triggered at epoch 31.\n",
      "✅ [Run 2] Mejor Val Acc: 0.573\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.729 | Val Acc: 0.545 | Train Loss: 0.9299 | Val Loss: 1.5824\n",
      "[Run 2] Early stopping triggered at epoch 31.\n",
      "✅ [Run 2] Mejor Val Acc: 0.573\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▅▄▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▄▄▃▅▆▅▅▅▆▆▆▆▇▆▇▆▇▇██▇███▇█</td></tr><tr><td>val_f1_macro</td><td>▁▁▂▃▃▄▄▃▅▅▅▅▅▆▅▆▆▇▆▇▆▇▇██▇███▇█</td></tr><tr><td>val_f1_weighted</td><td>▁▁▂▃▃▄▄▃▅▅▅▅▅▆▅▆▆▇▆▇▆▇▇██▇███▇█</td></tr><tr><td>val_loss</td><td>█▇▆▅▆▅▄▅▃▃▃▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▂▃▃▄▄▃▅▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇█▇█▇█</td></tr><tr><td>val_recall_macro</td><td>▁▁▂▃▃▄▄▃▅▆▅▅▅▆▆▆▆▇▆▇▆▇▇██▇███▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.5725</td></tr><tr><td>epoch</td><td>31</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.72917</td></tr><tr><td>train_loss</td><td>0.92986</td></tr><tr><td>val_acc</td><td>0.545</td></tr><tr><td>val_f1_macro</td><td>0.53383</td></tr><tr><td>val_f1_weighted</td><td>0.53383</td></tr><tr><td>val_loss</td><td>1.58241</td></tr><tr><td>val_precision_macro</td><td>0.62073</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-Adam_lr-0.0005_bs-8</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/x58mqrbm' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/x58mqrbm</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a><br>Synced 5 W&B file(s), 31 media file(s), 62 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_132022-x58mqrbm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_134934-g0tr9k06</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/g0tr9k06' target=\"_blank\">run_3_opt-Adam_lr-0.001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/g0tr9k06' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/g0tr9k06</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Epoch 01/40 | Train Acc: 0.037 | Val Acc: 0.040 | Train Loss: 3.8082 | Val Loss: 3.8550\n",
      "[Run 3] Epoch 02/40 | Train Acc: 0.077 | Val Acc: 0.080 | Train Loss: 3.4639 | Val Loss: 3.2861\n",
      "[Run 3] Epoch 02/40 | Train Acc: 0.077 | Val Acc: 0.080 | Train Loss: 3.4639 | Val Loss: 3.2861\n",
      "[Run 3] Epoch 03/40 | Train Acc: 0.111 | Val Acc: 0.090 | Train Loss: 3.2120 | Val Loss: 3.2970\n",
      "[Run 3] Epoch 03/40 | Train Acc: 0.111 | Val Acc: 0.090 | Train Loss: 3.2120 | Val Loss: 3.2970\n",
      "[Run 3] Epoch 04/40 | Train Acc: 0.159 | Val Acc: 0.168 | Train Loss: 2.9609 | Val Loss: 2.8582\n",
      "[Run 3] Epoch 04/40 | Train Acc: 0.159 | Val Acc: 0.168 | Train Loss: 2.9609 | Val Loss: 2.8582\n",
      "[Run 3] Epoch 05/40 | Train Acc: 0.218 | Val Acc: 0.228 | Train Loss: 2.7222 | Val Loss: 2.7622\n",
      "[Run 3] Epoch 05/40 | Train Acc: 0.218 | Val Acc: 0.228 | Train Loss: 2.7222 | Val Loss: 2.7622\n",
      "[Run 3] Epoch 06/40 | Train Acc: 0.255 | Val Acc: 0.320 | Train Loss: 2.5501 | Val Loss: 2.4695\n",
      "[Run 3] Epoch 06/40 | Train Acc: 0.255 | Val Acc: 0.320 | Train Loss: 2.5501 | Val Loss: 2.4695\n",
      "[Run 3] Epoch 07/40 | Train Acc: 0.315 | Val Acc: 0.352 | Train Loss: 2.3456 | Val Loss: 2.4830\n",
      "[Run 3] Epoch 07/40 | Train Acc: 0.315 | Val Acc: 0.352 | Train Loss: 2.3456 | Val Loss: 2.4830\n",
      "[Run 3] Epoch 08/40 | Train Acc: 0.331 | Val Acc: 0.323 | Train Loss: 2.3270 | Val Loss: 2.2868\n",
      "[Run 3] Epoch 08/40 | Train Acc: 0.331 | Val Acc: 0.323 | Train Loss: 2.3270 | Val Loss: 2.2868\n",
      "[Run 3] Epoch 09/40 | Train Acc: 0.394 | Val Acc: 0.268 | Train Loss: 2.0510 | Val Loss: 2.5865\n",
      "[Run 3] Epoch 09/40 | Train Acc: 0.394 | Val Acc: 0.268 | Train Loss: 2.0510 | Val Loss: 2.5865\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.402 | Val Acc: 0.278 | Train Loss: 1.9586 | Val Loss: 2.7120\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.402 | Val Acc: 0.278 | Train Loss: 1.9586 | Val Loss: 2.7120\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.443 | Val Acc: 0.323 | Train Loss: 1.8411 | Val Loss: 2.5708\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.443 | Val Acc: 0.323 | Train Loss: 1.8411 | Val Loss: 2.5708\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.470 | Val Acc: 0.378 | Train Loss: 1.7646 | Val Loss: 2.1311\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.470 | Val Acc: 0.378 | Train Loss: 1.7646 | Val Loss: 2.1311\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.485 | Val Acc: 0.370 | Train Loss: 1.6602 | Val Loss: 2.1597\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.485 | Val Acc: 0.370 | Train Loss: 1.6602 | Val Loss: 2.1597\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.499 | Val Acc: 0.372 | Train Loss: 1.6041 | Val Loss: 2.2521\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.499 | Val Acc: 0.372 | Train Loss: 1.6041 | Val Loss: 2.2521\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.527 | Val Acc: 0.372 | Train Loss: 1.5445 | Val Loss: 2.1446\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.527 | Val Acc: 0.372 | Train Loss: 1.5445 | Val Loss: 2.1446\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.532 | Val Acc: 0.333 | Train Loss: 1.5123 | Val Loss: 2.4156\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.532 | Val Acc: 0.333 | Train Loss: 1.5123 | Val Loss: 2.4156\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.594 | Val Acc: 0.507 | Train Loss: 1.3623 | Val Loss: 1.6454\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.594 | Val Acc: 0.507 | Train Loss: 1.3623 | Val Loss: 1.6454\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.593 | Val Acc: 0.398 | Train Loss: 1.3235 | Val Loss: 2.2316\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.593 | Val Acc: 0.398 | Train Loss: 1.3235 | Val Loss: 2.2316\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.620 | Val Acc: 0.430 | Train Loss: 1.2335 | Val Loss: 1.9023\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.620 | Val Acc: 0.430 | Train Loss: 1.2335 | Val Loss: 1.9023\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.633 | Val Acc: 0.500 | Train Loss: 1.2446 | Val Loss: 1.6839\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.633 | Val Acc: 0.500 | Train Loss: 1.2446 | Val Loss: 1.6839\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.647 | Val Acc: 0.547 | Train Loss: 1.1229 | Val Loss: 1.5366\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.647 | Val Acc: 0.547 | Train Loss: 1.1229 | Val Loss: 1.5366\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.663 | Val Acc: 0.532 | Train Loss: 1.0921 | Val Loss: 1.5345\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.663 | Val Acc: 0.532 | Train Loss: 1.0921 | Val Loss: 1.5345\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.719 | Val Acc: 0.453 | Train Loss: 1.0108 | Val Loss: 1.8609\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.719 | Val Acc: 0.453 | Train Loss: 1.0108 | Val Loss: 1.8609\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.689 | Val Acc: 0.438 | Train Loss: 0.9977 | Val Loss: 1.8792\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.689 | Val Acc: 0.438 | Train Loss: 0.9977 | Val Loss: 1.8792\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.748 | Val Acc: 0.515 | Train Loss: 0.8795 | Val Loss: 1.6302\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.748 | Val Acc: 0.515 | Train Loss: 0.8795 | Val Loss: 1.6302\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.777 | Val Acc: 0.545 | Train Loss: 0.7779 | Val Loss: 1.3980\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.777 | Val Acc: 0.545 | Train Loss: 0.7779 | Val Loss: 1.3980\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.796 | Val Acc: 0.547 | Train Loss: 0.7367 | Val Loss: 1.4535\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.796 | Val Acc: 0.547 | Train Loss: 0.7367 | Val Loss: 1.4535\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.813 | Val Acc: 0.590 | Train Loss: 0.6790 | Val Loss: 1.3610\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.813 | Val Acc: 0.590 | Train Loss: 0.6790 | Val Loss: 1.3610\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.808 | Val Acc: 0.477 | Train Loss: 0.6856 | Val Loss: 1.9058\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.808 | Val Acc: 0.477 | Train Loss: 0.6856 | Val Loss: 1.9058\n",
      "[Run 3] Epoch 30/40 | Train Acc: 0.802 | Val Acc: 0.590 | Train Loss: 0.6669 | Val Loss: 1.4305\n",
      "[Run 3] Epoch 30/40 | Train Acc: 0.802 | Val Acc: 0.590 | Train Loss: 0.6669 | Val Loss: 1.4305\n",
      "[Run 3] Epoch 31/40 | Train Acc: 0.823 | Val Acc: 0.608 | Train Loss: 0.6307 | Val Loss: 1.3938\n",
      "[Run 3] Epoch 31/40 | Train Acc: 0.823 | Val Acc: 0.608 | Train Loss: 0.6307 | Val Loss: 1.3938\n",
      "[Run 3] Epoch 32/40 | Train Acc: 0.840 | Val Acc: 0.552 | Train Loss: 0.5856 | Val Loss: 1.5072\n",
      "[Run 3] Epoch 32/40 | Train Acc: 0.840 | Val Acc: 0.552 | Train Loss: 0.5856 | Val Loss: 1.5072\n",
      "[Run 3] Epoch 33/40 | Train Acc: 0.865 | Val Acc: 0.590 | Train Loss: 0.5388 | Val Loss: 1.3528\n",
      "[Run 3] Epoch 33/40 | Train Acc: 0.865 | Val Acc: 0.590 | Train Loss: 0.5388 | Val Loss: 1.3528\n",
      "[Run 3] Epoch 34/40 | Train Acc: 0.893 | Val Acc: 0.552 | Train Loss: 0.4515 | Val Loss: 1.4852\n",
      "[Run 3] Epoch 34/40 | Train Acc: 0.893 | Val Acc: 0.552 | Train Loss: 0.4515 | Val Loss: 1.4852\n",
      "[Run 3] Epoch 35/40 | Train Acc: 0.908 | Val Acc: 0.583 | Train Loss: 0.3971 | Val Loss: 1.4419\n",
      "[Run 3] Epoch 35/40 | Train Acc: 0.908 | Val Acc: 0.583 | Train Loss: 0.3971 | Val Loss: 1.4419\n",
      "[Run 3] Epoch 36/40 | Train Acc: 0.922 | Val Acc: 0.593 | Train Loss: 0.3638 | Val Loss: 1.3408\n",
      "[Run 3] Epoch 36/40 | Train Acc: 0.922 | Val Acc: 0.593 | Train Loss: 0.3638 | Val Loss: 1.3408\n",
      "[Run 3] Epoch 37/40 | Train Acc: 0.914 | Val Acc: 0.620 | Train Loss: 0.3837 | Val Loss: 1.2451\n",
      "[Run 3] Epoch 37/40 | Train Acc: 0.914 | Val Acc: 0.620 | Train Loss: 0.3837 | Val Loss: 1.2451\n",
      "[Run 3] Epoch 38/40 | Train Acc: 0.919 | Val Acc: 0.590 | Train Loss: 0.3597 | Val Loss: 1.4065\n",
      "[Run 3] Epoch 38/40 | Train Acc: 0.919 | Val Acc: 0.590 | Train Loss: 0.3597 | Val Loss: 1.4065\n",
      "[Run 3] Epoch 39/40 | Train Acc: 0.934 | Val Acc: 0.588 | Train Loss: 0.3454 | Val Loss: 1.4321\n",
      "[Run 3] Epoch 39/40 | Train Acc: 0.934 | Val Acc: 0.588 | Train Loss: 0.3454 | Val Loss: 1.4321\n",
      "[Run 3] Epoch 40/40 | Train Acc: 0.941 | Val Acc: 0.573 | Train Loss: 0.3014 | Val Loss: 1.5629\n",
      "✅ [Run 3] Mejor Val Acc: 0.620\n",
      "[Run 3] Epoch 40/40 | Train Acc: 0.941 | Val Acc: 0.573 | Train Loss: 0.3014 | Val Loss: 1.5629\n",
      "✅ [Run 3] Mejor Val Acc: 0.620\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▄▅▄▄▄▄▅▅▅▅▅▇▅▆▇▇▇▆▆▇▇▇█▆██▇█▇█████▇</td></tr><tr><td>val_f1_macro</td><td>▁▁▁▂▃▄▄▄▃▄▄▅▅▅▅▄▇▅▆▆▇▇▆▅▇▇▇█▆██▇█▇█████▇</td></tr><tr><td>val_f1_weighted</td><td>▁▁▁▂▃▄▄▄▃▄▄▅▅▅▅▄▇▅▆▆▇▇▆▅▇▇▇█▆██▇█▇█████▇</td></tr><tr><td>val_loss</td><td>█▆▇▅▅▄▄▄▅▅▅▃▃▄▃▄▂▄▃▂▂▂▃▃▂▁▂▁▃▁▁▂▁▂▂▁▁▁▂▂</td></tr><tr><td>val_precision_macro</td><td>▁▁▁▂▃▄▅▄▄▄▅▅▅▆▅▆▇▆▆▇▇▇▇▆▇▇▇▇▇██▇▇██▇███▇</td></tr><tr><td>val_recall_macro</td><td>▁▁▂▃▃▄▅▄▄▄▄▅▅▅▅▅▇▅▆▇▇▇▆▆▇▇▇█▆██▇█▇█████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.62</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.94083</td></tr><tr><td>train_loss</td><td>0.3014</td></tr><tr><td>val_acc</td><td>0.5725</td></tr><tr><td>val_f1_macro</td><td>0.55551</td></tr><tr><td>val_f1_weighted</td><td>0.55551</td></tr><tr><td>val_loss</td><td>1.56287</td></tr><tr><td>val_precision_macro</td><td>0.62847</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-Adam_lr-0.001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/g0tr9k06' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/g0tr9k06</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_134934-g0tr9k06/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_142658-yocrcvcv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/yocrcvcv' target=\"_blank\">run_4_opt-SGD_lr-0.01_bs-8</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/yocrcvcv' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/yocrcvcv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Epoch 01/40 | Train Acc: 0.022 | Val Acc: 0.030 | Train Loss: 4.0767 | Val Loss: 3.9781\n",
      "[Run 4] Epoch 02/40 | Train Acc: 0.056 | Val Acc: 0.075 | Train Loss: 3.6328 | Val Loss: 4.0524\n",
      "[Run 4] Epoch 02/40 | Train Acc: 0.056 | Val Acc: 0.075 | Train Loss: 3.6328 | Val Loss: 4.0524\n",
      "[Run 4] Epoch 03/40 | Train Acc: 0.112 | Val Acc: 0.083 | Train Loss: 3.3671 | Val Loss: 4.7000\n",
      "[Run 4] Epoch 03/40 | Train Acc: 0.112 | Val Acc: 0.083 | Train Loss: 3.3671 | Val Loss: 4.7000\n",
      "[Run 4] Epoch 04/40 | Train Acc: 0.144 | Val Acc: 0.177 | Train Loss: 3.1378 | Val Loss: 2.8800\n",
      "[Run 4] Epoch 04/40 | Train Acc: 0.144 | Val Acc: 0.177 | Train Loss: 3.1378 | Val Loss: 2.8800\n",
      "[Run 4] Epoch 05/40 | Train Acc: 0.183 | Val Acc: 0.145 | Train Loss: 2.9245 | Val Loss: 3.5701\n",
      "[Run 4] Epoch 05/40 | Train Acc: 0.183 | Val Acc: 0.145 | Train Loss: 2.9245 | Val Loss: 3.5701\n",
      "[Run 4] Epoch 06/40 | Train Acc: 0.228 | Val Acc: 0.250 | Train Loss: 2.7629 | Val Loss: 2.7424\n",
      "[Run 4] Epoch 06/40 | Train Acc: 0.228 | Val Acc: 0.250 | Train Loss: 2.7629 | Val Loss: 2.7424\n",
      "[Run 4] Epoch 07/40 | Train Acc: 0.243 | Val Acc: 0.265 | Train Loss: 2.5859 | Val Loss: 2.6886\n",
      "[Run 4] Epoch 07/40 | Train Acc: 0.243 | Val Acc: 0.265 | Train Loss: 2.5859 | Val Loss: 2.6886\n",
      "[Run 4] Epoch 08/40 | Train Acc: 0.280 | Val Acc: 0.185 | Train Loss: 2.4662 | Val Loss: 2.7917\n",
      "[Run 4] Epoch 08/40 | Train Acc: 0.280 | Val Acc: 0.185 | Train Loss: 2.4662 | Val Loss: 2.7917\n",
      "[Run 4] Epoch 09/40 | Train Acc: 0.366 | Val Acc: 0.270 | Train Loss: 2.1606 | Val Loss: 2.5631\n",
      "[Run 4] Epoch 09/40 | Train Acc: 0.366 | Val Acc: 0.270 | Train Loss: 2.1606 | Val Loss: 2.5631\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.372 | Val Acc: 0.378 | Train Loss: 2.1083 | Val Loss: 2.2025\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.372 | Val Acc: 0.378 | Train Loss: 2.1083 | Val Loss: 2.2025\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.397 | Val Acc: 0.407 | Train Loss: 1.9819 | Val Loss: 2.0591\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.397 | Val Acc: 0.407 | Train Loss: 1.9819 | Val Loss: 2.0591\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.422 | Val Acc: 0.403 | Train Loss: 1.8883 | Val Loss: 2.5384\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.422 | Val Acc: 0.403 | Train Loss: 1.8883 | Val Loss: 2.5384\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.459 | Val Acc: 0.362 | Train Loss: 1.7679 | Val Loss: 2.2926\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.459 | Val Acc: 0.362 | Train Loss: 1.7679 | Val Loss: 2.2926\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.483 | Val Acc: 0.415 | Train Loss: 1.6775 | Val Loss: 2.0218\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.483 | Val Acc: 0.415 | Train Loss: 1.6775 | Val Loss: 2.0218\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.520 | Val Acc: 0.425 | Train Loss: 1.5931 | Val Loss: 2.0788\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.520 | Val Acc: 0.425 | Train Loss: 1.5931 | Val Loss: 2.0788\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.518 | Val Acc: 0.407 | Train Loss: 1.5234 | Val Loss: 2.0426\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.518 | Val Acc: 0.407 | Train Loss: 1.5234 | Val Loss: 2.0426\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.615 | Val Acc: 0.500 | Train Loss: 1.2427 | Val Loss: 1.8014\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.615 | Val Acc: 0.500 | Train Loss: 1.2427 | Val Loss: 1.8014\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.635 | Val Acc: 0.532 | Train Loss: 1.1709 | Val Loss: 1.6984\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.635 | Val Acc: 0.532 | Train Loss: 1.1709 | Val Loss: 1.6984\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.658 | Val Acc: 0.507 | Train Loss: 1.1210 | Val Loss: 1.7347\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.658 | Val Acc: 0.507 | Train Loss: 1.1210 | Val Loss: 1.7347\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.708 | Val Acc: 0.417 | Train Loss: 1.0026 | Val Loss: 2.3159\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.708 | Val Acc: 0.417 | Train Loss: 1.0026 | Val Loss: 2.3159\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.714 | Val Acc: 0.530 | Train Loss: 0.9364 | Val Loss: 1.7611\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.714 | Val Acc: 0.530 | Train Loss: 0.9364 | Val Loss: 1.7611\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.730 | Val Acc: 0.487 | Train Loss: 0.8995 | Val Loss: 1.7653\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.730 | Val Acc: 0.487 | Train Loss: 0.8995 | Val Loss: 1.7653\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.758 | Val Acc: 0.472 | Train Loss: 0.8080 | Val Loss: 2.0114\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.758 | Val Acc: 0.472 | Train Loss: 0.8080 | Val Loss: 2.0114\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.777 | Val Acc: 0.468 | Train Loss: 0.7889 | Val Loss: 2.1356\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.777 | Val Acc: 0.468 | Train Loss: 0.7889 | Val Loss: 2.1356\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.829 | Val Acc: 0.598 | Train Loss: 0.5846 | Val Loss: 1.4778\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.829 | Val Acc: 0.598 | Train Loss: 0.5846 | Val Loss: 1.4778\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.866 | Val Acc: 0.585 | Train Loss: 0.5119 | Val Loss: 1.5050\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.866 | Val Acc: 0.585 | Train Loss: 0.5119 | Val Loss: 1.5050\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.886 | Val Acc: 0.568 | Train Loss: 0.4599 | Val Loss: 1.5780\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.886 | Val Acc: 0.568 | Train Loss: 0.4599 | Val Loss: 1.5780\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.905 | Val Acc: 0.632 | Train Loss: 0.3988 | Val Loss: 1.3623\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.905 | Val Acc: 0.632 | Train Loss: 0.3988 | Val Loss: 1.3623\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.904 | Val Acc: 0.625 | Train Loss: 0.4166 | Val Loss: 1.4061\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.904 | Val Acc: 0.625 | Train Loss: 0.4166 | Val Loss: 1.4061\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.912 | Val Acc: 0.547 | Train Loss: 0.3617 | Val Loss: 1.8117\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.912 | Val Acc: 0.547 | Train Loss: 0.3617 | Val Loss: 1.8117\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.930 | Val Acc: 0.588 | Train Loss: 0.3152 | Val Loss: 1.4938\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.930 | Val Acc: 0.588 | Train Loss: 0.3152 | Val Loss: 1.4938\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.933 | Val Acc: 0.580 | Train Loss: 0.3090 | Val Loss: 1.6151\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.933 | Val Acc: 0.580 | Train Loss: 0.3090 | Val Loss: 1.6151\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.955 | Val Acc: 0.598 | Train Loss: 0.2444 | Val Loss: 1.4321\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.955 | Val Acc: 0.598 | Train Loss: 0.2444 | Val Loss: 1.4321\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.973 | Val Acc: 0.627 | Train Loss: 0.1740 | Val Loss: 1.3579\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.973 | Val Acc: 0.627 | Train Loss: 0.1740 | Val Loss: 1.3579\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.978 | Val Acc: 0.630 | Train Loss: 0.1784 | Val Loss: 1.5290\n",
      "[Run 4] Early stopping triggered at epoch 35.\n",
      "✅ [Run 4] Mejor Val Acc: 0.632\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.978 | Val Acc: 0.630 | Train Loss: 0.1784 | Val Loss: 1.5290\n",
      "[Run 4] Early stopping triggered at epoch 35.\n",
      "✅ [Run 4] Mejor Val Acc: 0.632\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▃▂▄▄▃▄▅▅▅▅▅▆▅▆▇▇▆▇▆▆▆█▇▇██▇▇▇███</td></tr><tr><td>val_f1_macro</td><td>▁▁▁▂▂▃▃▃▄▅▅▅▅▅▅▅▆▇▆▅▇▆▆▆█▇▇██▇▇▇███</td></tr><tr><td>val_f1_weighted</td><td>▁▁▁▂▂▃▃▃▄▅▅▅▅▅▅▅▆▇▆▅▇▆▆▆█▇▇██▇▇▇███</td></tr><tr><td>val_loss</td><td>▆▇█▄▆▄▄▄▄▃▂▃▃▂▃▂▂▂▂▃▂▂▂▃▁▁▁▁▁▂▁▂▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▁▂▂▃▃▃▄▅▆▆▅▅▆▆▇▇▆▆▇▆▆▆█▇▇██▇▇▇██▇</td></tr><tr><td>val_recall_macro</td><td>▁▂▂▃▂▄▄▃▄▅▅▅▅▅▆▅▆▇▇▆▇▆▆▆█▇▇██▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6325</td></tr><tr><td>epoch</td><td>35</td></tr><tr><td>lr</td><td>0.0024</td></tr><tr><td>train_acc</td><td>0.97833</td></tr><tr><td>train_loss</td><td>0.17839</td></tr><tr><td>val_acc</td><td>0.63</td></tr><tr><td>val_f1_macro</td><td>0.61419</td></tr><tr><td>val_f1_weighted</td><td>0.61419</td></tr><tr><td>val_loss</td><td>1.52899</td></tr><tr><td>val_precision_macro</td><td>0.64456</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-SGD_lr-0.01_bs-8</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/yocrcvcv' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/yocrcvcv</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a><br>Synced 5 W&B file(s), 35 media file(s), 70 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_142658-yocrcvcv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_145937-kgvla8k7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/kgvla8k7' target=\"_blank\">run_5_opt-SGD_lr-0.001_bs-8</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/kgvla8k7' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/kgvla8k7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Epoch 01/40 | Train Acc: 0.025 | Val Acc: 0.060 | Train Loss: 3.9136 | Val Loss: 3.7168\n",
      "[Run 5] Epoch 02/40 | Train Acc: 0.042 | Val Acc: 0.055 | Train Loss: 3.6964 | Val Loss: 3.5477\n",
      "[Run 5] Epoch 02/40 | Train Acc: 0.042 | Val Acc: 0.055 | Train Loss: 3.6964 | Val Loss: 3.5477\n",
      "[Run 5] Epoch 03/40 | Train Acc: 0.061 | Val Acc: 0.072 | Train Loss: 3.5663 | Val Loss: 3.4538\n",
      "[Run 5] Epoch 03/40 | Train Acc: 0.061 | Val Acc: 0.072 | Train Loss: 3.5663 | Val Loss: 3.4538\n",
      "[Run 5] Epoch 04/40 | Train Acc: 0.090 | Val Acc: 0.102 | Train Loss: 3.3985 | Val Loss: 3.2162\n",
      "[Run 5] Epoch 04/40 | Train Acc: 0.090 | Val Acc: 0.102 | Train Loss: 3.3985 | Val Loss: 3.2162\n",
      "[Run 5] Epoch 05/40 | Train Acc: 0.118 | Val Acc: 0.138 | Train Loss: 3.2274 | Val Loss: 3.2526\n",
      "[Run 5] Epoch 05/40 | Train Acc: 0.118 | Val Acc: 0.138 | Train Loss: 3.2274 | Val Loss: 3.2526\n",
      "[Run 5] Epoch 06/40 | Train Acc: 0.142 | Val Acc: 0.160 | Train Loss: 3.0723 | Val Loss: 3.1945\n",
      "[Run 5] Epoch 06/40 | Train Acc: 0.142 | Val Acc: 0.160 | Train Loss: 3.0723 | Val Loss: 3.1945\n",
      "[Run 5] Epoch 07/40 | Train Acc: 0.169 | Val Acc: 0.125 | Train Loss: 2.9561 | Val Loss: 3.4166\n",
      "[Run 5] Epoch 07/40 | Train Acc: 0.169 | Val Acc: 0.125 | Train Loss: 2.9561 | Val Loss: 3.4166\n",
      "[Run 5] Epoch 08/40 | Train Acc: 0.187 | Val Acc: 0.170 | Train Loss: 2.8557 | Val Loss: 3.1217\n",
      "[Run 5] Epoch 08/40 | Train Acc: 0.187 | Val Acc: 0.170 | Train Loss: 2.8557 | Val Loss: 3.1217\n",
      "[Run 5] Epoch 09/40 | Train Acc: 0.231 | Val Acc: 0.253 | Train Loss: 2.6860 | Val Loss: 2.6634\n",
      "[Run 5] Epoch 09/40 | Train Acc: 0.231 | Val Acc: 0.253 | Train Loss: 2.6860 | Val Loss: 2.6634\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.247 | Val Acc: 0.263 | Train Loss: 2.6462 | Val Loss: 2.6292\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.247 | Val Acc: 0.263 | Train Loss: 2.6462 | Val Loss: 2.6292\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.272 | Val Acc: 0.273 | Train Loss: 2.5480 | Val Loss: 2.5913\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.272 | Val Acc: 0.273 | Train Loss: 2.5480 | Val Loss: 2.5913\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.293 | Val Acc: 0.278 | Train Loss: 2.4894 | Val Loss: 2.5560\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.293 | Val Acc: 0.278 | Train Loss: 2.4894 | Val Loss: 2.5560\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.310 | Val Acc: 0.258 | Train Loss: 2.4087 | Val Loss: 2.5285\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.310 | Val Acc: 0.258 | Train Loss: 2.4087 | Val Loss: 2.5285\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.312 | Val Acc: 0.312 | Train Loss: 2.3283 | Val Loss: 2.4915\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.312 | Val Acc: 0.312 | Train Loss: 2.3283 | Val Loss: 2.4915\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.330 | Val Acc: 0.328 | Train Loss: 2.2923 | Val Loss: 2.3926\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.330 | Val Acc: 0.328 | Train Loss: 2.2923 | Val Loss: 2.3926\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.346 | Val Acc: 0.228 | Train Loss: 2.2058 | Val Loss: 2.8615\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.346 | Val Acc: 0.228 | Train Loss: 2.2058 | Val Loss: 2.8615\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.389 | Val Acc: 0.407 | Train Loss: 2.1050 | Val Loss: 2.2162\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.389 | Val Acc: 0.407 | Train Loss: 2.1050 | Val Loss: 2.2162\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.413 | Val Acc: 0.320 | Train Loss: 2.0529 | Val Loss: 2.3413\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.413 | Val Acc: 0.320 | Train Loss: 2.0529 | Val Loss: 2.3413\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.429 | Val Acc: 0.357 | Train Loss: 1.9867 | Val Loss: 2.2600\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.429 | Val Acc: 0.357 | Train Loss: 1.9867 | Val Loss: 2.2600\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.422 | Val Acc: 0.360 | Train Loss: 1.9664 | Val Loss: 2.4245\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.422 | Val Acc: 0.360 | Train Loss: 1.9664 | Val Loss: 2.4245\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.448 | Val Acc: 0.422 | Train Loss: 1.9025 | Val Loss: 2.0285\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.448 | Val Acc: 0.422 | Train Loss: 1.9025 | Val Loss: 2.0285\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.464 | Val Acc: 0.375 | Train Loss: 1.8706 | Val Loss: 2.2227\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.464 | Val Acc: 0.375 | Train Loss: 1.8706 | Val Loss: 2.2227\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.438 | Val Acc: 0.427 | Train Loss: 1.8298 | Val Loss: 1.9948\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.438 | Val Acc: 0.427 | Train Loss: 1.8298 | Val Loss: 1.9948\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.485 | Val Acc: 0.427 | Train Loss: 1.7889 | Val Loss: 1.9478\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.485 | Val Acc: 0.427 | Train Loss: 1.7889 | Val Loss: 1.9478\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.501 | Val Acc: 0.448 | Train Loss: 1.7448 | Val Loss: 1.9631\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.501 | Val Acc: 0.448 | Train Loss: 1.7448 | Val Loss: 1.9631\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.518 | Val Acc: 0.475 | Train Loss: 1.6664 | Val Loss: 1.9550\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.518 | Val Acc: 0.475 | Train Loss: 1.6664 | Val Loss: 1.9550\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.530 | Val Acc: 0.487 | Train Loss: 1.6505 | Val Loss: 1.8646\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.530 | Val Acc: 0.487 | Train Loss: 1.6505 | Val Loss: 1.8646\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.533 | Val Acc: 0.487 | Train Loss: 1.6001 | Val Loss: 1.7842\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.533 | Val Acc: 0.487 | Train Loss: 1.6001 | Val Loss: 1.7842\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.542 | Val Acc: 0.427 | Train Loss: 1.5773 | Val Loss: 1.9734\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.542 | Val Acc: 0.427 | Train Loss: 1.5773 | Val Loss: 1.9734\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.548 | Val Acc: 0.468 | Train Loss: 1.5459 | Val Loss: 1.8589\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.548 | Val Acc: 0.468 | Train Loss: 1.5459 | Val Loss: 1.8589\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.549 | Val Acc: 0.443 | Train Loss: 1.5186 | Val Loss: 1.8761\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.549 | Val Acc: 0.443 | Train Loss: 1.5186 | Val Loss: 1.8761\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.572 | Val Acc: 0.468 | Train Loss: 1.4892 | Val Loss: 1.8209\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.572 | Val Acc: 0.468 | Train Loss: 1.4892 | Val Loss: 1.8209\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.599 | Val Acc: 0.497 | Train Loss: 1.4254 | Val Loss: 1.8233\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.599 | Val Acc: 0.497 | Train Loss: 1.4254 | Val Loss: 1.8233\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.605 | Val Acc: 0.482 | Train Loss: 1.3956 | Val Loss: 1.7269\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.605 | Val Acc: 0.482 | Train Loss: 1.3956 | Val Loss: 1.7269\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.596 | Val Acc: 0.512 | Train Loss: 1.4095 | Val Loss: 1.6855\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.596 | Val Acc: 0.512 | Train Loss: 1.4095 | Val Loss: 1.6855\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.623 | Val Acc: 0.510 | Train Loss: 1.3452 | Val Loss: 1.6772\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.623 | Val Acc: 0.510 | Train Loss: 1.3452 | Val Loss: 1.6772\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.637 | Val Acc: 0.480 | Train Loss: 1.3183 | Val Loss: 1.7318\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.637 | Val Acc: 0.480 | Train Loss: 1.3183 | Val Loss: 1.7318\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.625 | Val Acc: 0.485 | Train Loss: 1.3377 | Val Loss: 1.8042\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.625 | Val Acc: 0.485 | Train Loss: 1.3377 | Val Loss: 1.8042\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.632 | Val Acc: 0.475 | Train Loss: 1.3039 | Val Loss: 1.7827\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.632 | Val Acc: 0.475 | Train Loss: 1.3039 | Val Loss: 1.7827\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.649 | Val Acc: 0.490 | Train Loss: 1.2828 | Val Loss: 1.7889\n",
      "✅ [Run 5] Mejor Val Acc: 0.512\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.649 | Val Acc: 0.490 | Train Loss: 1.2828 | Val Loss: 1.7889\n",
      "✅ [Run 5] Mejor Val Acc: 0.512\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▂▂▃▂▃▄▄▄▄▄▅▅▄▆▅▆▆▇▆▇▇▇▇██▇▇▇▇██████▇█</td></tr><tr><td>val_f1_macro</td><td>▁▁▁▂▂▂▂▂▃▄▄▄▄▅▅▄▆▅▅▅▆▅▇▇▇▇█▇▇▇▇▇██████▇▇</td></tr><tr><td>val_f1_weighted</td><td>▁▁▁▂▂▂▂▂▃▄▄▄▄▅▅▄▆▅▅▅▆▅▇▇▇▇█▇▇▇▇▇██████▇▇</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▆▇▆▄▄▄▄▄▄▃▅▃▃▃▄▂▃▂▂▂▂▂▁▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▁▂▃▃▂▂▄▄▄▄▄▅▆▅▇▆▆▅▇▅▇▇▇█▇▇▇▇▇▇██████▇█</td></tr><tr><td>val_recall_macro</td><td>▁▁▁▂▂▃▂▃▄▄▄▄▄▅▅▄▆▅▆▆▇▆▇▇▇▇██▇▇▇▇██████▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.5125</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.64917</td></tr><tr><td>train_loss</td><td>1.28283</td></tr><tr><td>val_acc</td><td>0.49</td></tr><tr><td>val_f1_macro</td><td>0.45799</td></tr><tr><td>val_f1_weighted</td><td>0.45799</td></tr><tr><td>val_loss</td><td>1.78888</td></tr><tr><td>val_precision_macro</td><td>0.53778</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.001_bs-8</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/kgvla8k7' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/kgvla8k7</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_145937-kgvla8k7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===========================================\n",
    "# ENTRENAMIENTO - MODELO B (ResNet-18 Audio)\n",
    "# Dataset: data/spectrograms1/augmented\n",
    "# Optimizado para GPUs pequeñas (≤ 4 GB)\n",
    "# ===========================================\n",
    "\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# ---- 0) Setup\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---- 1) Data\n",
    "DATA_DIR = \"data/spectrograms1/augmented\"\n",
    "IMG_SIZE = (224, 224)   \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\",   transform=transform)\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "class_names = train_data.classes\n",
    "print(\"Clases:\", num_classes)\n",
    "\n",
    "# ---- 2) Experimentos\n",
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001,  \"batch_size\": 8,  \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 8,  \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001,  \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,   \"batch_size\": 8,  \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001,  \"batch_size\": 8,  \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "EPOCHS   = 40\n",
    "PATIENCE = 6\n",
    "\n",
    "# ---- 3) Loop multi-run\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    # Cerrar cualquier run previo de W&B para evitar duplicados\n",
    "    if wandb.run is not None:\n",
    "        wandb.finish()\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"esc50-resnet18-augmented\",  # ← Nombre único del proyecto\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp,\n",
    "        reinit=True  # Permite reinicialización si hay conflictos\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_data, batch_size=config.batch_size, shuffle=True, num_workers=2, pin_memory=True\n",
    "    )\n",
    "    val_loader   = DataLoader(\n",
    "        val_data,   batch_size=config.batch_size, shuffle=False, num_workers=2, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # --- Modelo B (tu ResNet-18)\n",
    "    model = resnet18_audio(num_classes=num_classes, in_channels=1, small_input=True).to(device)\n",
    "\n",
    "    # --- Criterio / Optimizador / Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "    scaler = GradScaler('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    # ---- Entrenamiento\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "\n",
    "        # ---- Validación\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        val_y_true, val_y_pred = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                \n",
    "                val_y_true.extend(labels.cpu().tolist())\n",
    "                val_y_pred.extend(preds.cpu().tolist())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss = val_loss / max(1, len(val_loader))\n",
    "\n",
    "        # --- Métricas adicionales\n",
    "        prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"macro\", zero_division=0\n",
    "        )\n",
    "        prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"weighted\", zero_division=0\n",
    "        )\n",
    "\n",
    "        scheduler.step()\n",
    "        torch.cuda.empty_cache()  # Liberar VRAM\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1_macro\": f1_m,\n",
    "            \"val_f1_weighted\": f1_w,\n",
    "            \"val_precision_macro\": prec_m,\n",
    "            \"val_recall_macro\": rec_m,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "            \"val_confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                y_true=val_y_true,\n",
    "                preds=val_y_pred,\n",
    "                class_names=class_names\n",
    "            )\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # ---- Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/resnet18_audio_AUG_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > PATIENCE:\n",
    "                print(f\"[Run {i}] Early stopping triggered at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2a743",
   "metadata": {},
   "source": [
    "# Evaluacion de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2655c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
