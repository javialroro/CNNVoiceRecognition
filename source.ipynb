{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5793bd2c",
   "metadata": {},
   "source": [
    "# Dataset Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da012a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de muestras: 2000\n",
      "Categorías únicas: 50\n",
      "\n",
      "Distribución por categoría:\n",
      "category\n",
      "airplane            40\n",
      "breathing           40\n",
      "brushing_teeth      40\n",
      "can_opening         40\n",
      "car_horn            40\n",
      "cat                 40\n",
      "chainsaw            40\n",
      "chirping_birds      40\n",
      "church_bells        40\n",
      "clapping            40\n",
      "clock_alarm         40\n",
      "clock_tick          40\n",
      "coughing            40\n",
      "cow                 40\n",
      "crackling_fire      40\n",
      "crickets            40\n",
      "crow                40\n",
      "crying_baby         40\n",
      "dog                 40\n",
      "door_wood_creaks    40\n",
      "door_wood_knock     40\n",
      "drinking_sipping    40\n",
      "engine              40\n",
      "fireworks           40\n",
      "footsteps           40\n",
      "frog                40\n",
      "glass_breaking      40\n",
      "hand_saw            40\n",
      "helicopter          40\n",
      "hen                 40\n",
      "insects             40\n",
      "keyboard_typing     40\n",
      "laughing            40\n",
      "mouse_click         40\n",
      "pig                 40\n",
      "pouring_water       40\n",
      "rain                40\n",
      "rooster             40\n",
      "sea_waves           40\n",
      "sheep               40\n",
      "siren               40\n",
      "sneezing            40\n",
      "snoring             40\n",
      "thunderstorm        40\n",
      "toilet_flush        40\n",
      "train               40\n",
      "vacuum_cleaner      40\n",
      "washing_machine     40\n",
      "water_drops         40\n",
      "wind                40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Tamaños de splits ===\n",
      "Train: 1400 (70.0%)\n",
      "Val:   300 (15.0%)\n",
      "Test:  300 (15.0%)\n",
      "\n",
      "=== Verificación de estratificación ===\n",
      "Train categorías: 50\n",
      "Val categorías: 50\n",
      "Test categorías: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando train: 100%|██████████| 1400/1400 [00:16<00:00, 86.86it/s]\n",
      "Procesando val: 100%|██████████| 300/300 [00:03<00:00, 84.22it/s]\n",
      "Procesando test: 100%|██████████| 300/300 [00:03<00:00, 82.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Espectrogramas generados con split estratificado.\n",
      "✅ Todas las categorías están representadas en cada conjunto.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "CSV_PATH = \"data/ESC-50-master/meta/esc50.csv\"\n",
    "AUDIO_DIR = \"data/ESC-50-master/audio\"\n",
    "OUTPUT_DIR = \"data/spectrograms2/base\"\n",
    "SR = 22050\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Proporciones para split estratificado\n",
    "TRAIN_RATIO = 0.70  # 70% entrenamiento\n",
    "VAL_RATIO = 0.15    # 15% validación\n",
    "TEST_RATIO = 0.15   # 15% test\n",
    "\n",
    "# Crear carpetas base\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split), exist_ok=True)\n",
    "\n",
    "# Leer metadatos\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "def wav_to_spectrogram(wav_path, save_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=SR)\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        S_norm = (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "        S_img = (S_norm * 255).astype(np.uint8)\n",
    "\n",
    "        img = Image.fromarray(S_img).resize(IMG_SIZE).convert(\"L\")\n",
    "        img.save(save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error procesando {wav_path}: {e}\")\n",
    "\n",
    "def process_split(df_split, split_name):\n",
    "    for _, row in tqdm(df_split.iterrows(), total=len(df_split), desc=f\"Procesando {split_name}\"):\n",
    "        file_name = row[\"filename\"]\n",
    "        label = row[\"category\"]\n",
    "\n",
    "        # Crear carpeta por clase\n",
    "        class_dir = os.path.join(OUTPUT_DIR, split_name, label)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        wav_path = os.path.join(AUDIO_DIR, file_name)\n",
    "        save_path = os.path.join(class_dir, file_name.replace(\".wav\", \".png\"))\n",
    "\n",
    "        if not os.path.exists(save_path):\n",
    "            wav_to_spectrogram(wav_path, save_path)\n",
    "\n",
    "# === SPLIT ESTRATIFICADO ===\n",
    "print(f\"Total de muestras: {len(df)}\")\n",
    "print(f\"Categorías únicas: {df['category'].nunique()}\")\n",
    "print(f\"\\nDistribución por categoría:\")\n",
    "print(df['category'].value_counts().sort_index())\n",
    "\n",
    "# Primera división: train vs (val+test)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=(VAL_RATIO + TEST_RATIO),\n",
    "    stratify=df['category'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Segunda división: val vs test\n",
    "val_ratio_adjusted = VAL_RATIO / (VAL_RATIO + TEST_RATIO)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=(1 - val_ratio_adjusted),\n",
    "    stratify=temp_df['category'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Tamaños de splits ===\")\n",
    "print(f\"Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n=== Verificación de estratificación ===\")\n",
    "print(\"Train categorías:\", train_df['category'].nunique())\n",
    "print(\"Val categorías:\", val_df['category'].nunique())\n",
    "print(\"Test categorías:\", test_df['category'].nunique())\n",
    "\n",
    "# Generar los tres splits\n",
    "process_split(train_df, \"train\")\n",
    "process_split(val_df, \"val\")\n",
    "process_split(test_df, \"test\")\n",
    "\n",
    "print(\"\\n✅ Espectrogramas generados con split estratificado.\")\n",
    "print(\"✅ Todas las categorías están representadas en cada conjunto.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6178f7",
   "metadata": {},
   "source": [
    "# Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c26731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=50, dropout=0.4):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        # --- Bloque 1: Más filtros para capturar características complejas ---\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # --- Bloque 2: Mayor capacidad ---\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # --- Bloque 3: Profundidad adicional ---\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Dropout espacial\n",
    "        self.drop_conv = nn.Dropout2d(0.3)\n",
    "\n",
    "        # ✅ CALCULAR DIMENSIONES DINÁMICAMENTE\n",
    "        self._to_linear = None\n",
    "        self._get_conv_output_size((1, 224, 224))\n",
    "\n",
    "        # --- Capas densas con regularización fuerte ---\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Dropout más agresivo\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.dropout2 = nn.Dropout(p=0.4)\n",
    "\n",
    "        # Inicialización Xavier para tanh\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _get_conv_output_size(self, shape):\n",
    "        \"\"\"Calcula automáticamente el tamaño de salida de las capas conv.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *shape)\n",
    "            x = self.pool1(torch.tanh(self.bn1(self.conv1(dummy_input))))\n",
    "            x = self.pool2(torch.tanh(self.bn2(self.conv2(x))))\n",
    "            x = self.pool3(torch.tanh(self.bn3(self.conv3(x))))\n",
    "            self._to_linear = x.view(1, -1).shape[1]\n",
    "            print(f\"✅ Tamaño calculado para FC: {self._to_linear}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bloques convolucionales\n",
    "        x = self.pool1(torch.tanh(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.tanh(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.tanh(self.bn3(self.conv3(x))))\n",
    "        x = self.drop_conv(x)\n",
    "        \n",
    "        # Aplanar\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Capas densas con dropout fuerte\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a0b11",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Raw Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0e1870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javialroro/miniconda3/envs/ml/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/javialroro/miniconda3/envs/ml/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjavialroro\u001b[0m (\u001b[33mjavialroro-tecnologico-de-costa-rica\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjavialroro\u001b[0m (\u001b[33mjavialroro-tecnologico-de-costa-rica\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_182739-rll8rxjk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/rll8rxjk' target=\"_blank\">run_1_opt-SGD_lr-0.001_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/rll8rxjk' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/rll8rxjk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamaño calculado para FC: 43264\n",
      "[Run 1] Epoch 1/40 | Train Acc: 0.044 | Val Acc: 0.073 | Train Loss: 4.1785 | Val Loss: 3.4956\n",
      "[Run 1] Epoch 1/40 | Train Acc: 0.044 | Val Acc: 0.073 | Train Loss: 4.1785 | Val Loss: 3.4956\n",
      "[Run 1] Epoch 2/40 | Train Acc: 0.071 | Val Acc: 0.147 | Train Loss: 3.8950 | Val Loss: 3.3310\n",
      "[Run 1] Epoch 2/40 | Train Acc: 0.071 | Val Acc: 0.147 | Train Loss: 3.8950 | Val Loss: 3.3310\n",
      "[Run 1] Epoch 3/40 | Train Acc: 0.096 | Val Acc: 0.147 | Train Loss: 3.6854 | Val Loss: 3.3073\n",
      "[Run 1] Epoch 3/40 | Train Acc: 0.096 | Val Acc: 0.147 | Train Loss: 3.6854 | Val Loss: 3.3073\n",
      "[Run 1] Epoch 4/40 | Train Acc: 0.106 | Val Acc: 0.220 | Train Loss: 3.6071 | Val Loss: 3.1705\n",
      "[Run 1] Epoch 4/40 | Train Acc: 0.106 | Val Acc: 0.220 | Train Loss: 3.6071 | Val Loss: 3.1705\n",
      "[Run 1] Epoch 5/40 | Train Acc: 0.137 | Val Acc: 0.183 | Train Loss: 3.4642 | Val Loss: 3.2047\n",
      "[Run 1] Epoch 5/40 | Train Acc: 0.137 | Val Acc: 0.183 | Train Loss: 3.4642 | Val Loss: 3.2047\n",
      "[Run 1] Epoch 6/40 | Train Acc: 0.146 | Val Acc: 0.207 | Train Loss: 3.4177 | Val Loss: 3.0688\n",
      "[Run 1] Epoch 6/40 | Train Acc: 0.146 | Val Acc: 0.207 | Train Loss: 3.4177 | Val Loss: 3.0688\n",
      "[Run 1] Epoch 7/40 | Train Acc: 0.162 | Val Acc: 0.280 | Train Loss: 3.2878 | Val Loss: 2.9980\n",
      "[Run 1] Epoch 7/40 | Train Acc: 0.162 | Val Acc: 0.280 | Train Loss: 3.2878 | Val Loss: 2.9980\n",
      "[Run 1] Epoch 8/40 | Train Acc: 0.172 | Val Acc: 0.247 | Train Loss: 3.2186 | Val Loss: 2.9679\n",
      "[Run 1] Epoch 8/40 | Train Acc: 0.172 | Val Acc: 0.247 | Train Loss: 3.2186 | Val Loss: 2.9679\n",
      "[Run 1] Epoch 9/40 | Train Acc: 0.174 | Val Acc: 0.267 | Train Loss: 3.1252 | Val Loss: 2.8846\n",
      "[Run 1] Epoch 9/40 | Train Acc: 0.174 | Val Acc: 0.267 | Train Loss: 3.1252 | Val Loss: 2.8846\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.232 | Val Acc: 0.273 | Train Loss: 2.9475 | Val Loss: 2.8624\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.232 | Val Acc: 0.273 | Train Loss: 2.9475 | Val Loss: 2.8624\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.279 | Val Acc: 0.320 | Train Loss: 2.7884 | Val Loss: 2.8284\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.279 | Val Acc: 0.320 | Train Loss: 2.7884 | Val Loss: 2.8284\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.264 | Val Acc: 0.303 | Train Loss: 2.7594 | Val Loss: 2.8534\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.264 | Val Acc: 0.303 | Train Loss: 2.7594 | Val Loss: 2.8534\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.306 | Val Acc: 0.330 | Train Loss: 2.6901 | Val Loss: 2.7326\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.306 | Val Acc: 0.330 | Train Loss: 2.6901 | Val Loss: 2.7326\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.341 | Val Acc: 0.357 | Train Loss: 2.5711 | Val Loss: 2.7006\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.341 | Val Acc: 0.357 | Train Loss: 2.5711 | Val Loss: 2.7006\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.363 | Val Acc: 0.353 | Train Loss: 2.4879 | Val Loss: 2.6941\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.363 | Val Acc: 0.353 | Train Loss: 2.4879 | Val Loss: 2.6941\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.392 | Val Acc: 0.357 | Train Loss: 2.3914 | Val Loss: 2.6354\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.392 | Val Acc: 0.357 | Train Loss: 2.3914 | Val Loss: 2.6354\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.444 | Val Acc: 0.360 | Train Loss: 2.2438 | Val Loss: 2.5960\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.444 | Val Acc: 0.360 | Train Loss: 2.2438 | Val Loss: 2.5960\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.462 | Val Acc: 0.363 | Train Loss: 2.1821 | Val Loss: 2.6100\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.462 | Val Acc: 0.363 | Train Loss: 2.1821 | Val Loss: 2.6100\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.486 | Val Acc: 0.360 | Train Loss: 2.0918 | Val Loss: 2.6874\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.486 | Val Acc: 0.360 | Train Loss: 2.0918 | Val Loss: 2.6874\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.526 | Val Acc: 0.413 | Train Loss: 2.0312 | Val Loss: 2.5547\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.526 | Val Acc: 0.413 | Train Loss: 2.0312 | Val Loss: 2.5547\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.521 | Val Acc: 0.347 | Train Loss: 1.9945 | Val Loss: 2.6796\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.521 | Val Acc: 0.347 | Train Loss: 1.9945 | Val Loss: 2.6796\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.536 | Val Acc: 0.410 | Train Loss: 1.9231 | Val Loss: 2.5486\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.536 | Val Acc: 0.410 | Train Loss: 1.9231 | Val Loss: 2.5486\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.579 | Val Acc: 0.390 | Train Loss: 1.8626 | Val Loss: 2.5238\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.579 | Val Acc: 0.390 | Train Loss: 1.8626 | Val Loss: 2.5238\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.606 | Val Acc: 0.400 | Train Loss: 1.7755 | Val Loss: 2.4887\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.606 | Val Acc: 0.400 | Train Loss: 1.7755 | Val Loss: 2.4887\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.626 | Val Acc: 0.400 | Train Loss: 1.7183 | Val Loss: 2.5401\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.626 | Val Acc: 0.400 | Train Loss: 1.7183 | Val Loss: 2.5401\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.644 | Val Acc: 0.420 | Train Loss: 1.6622 | Val Loss: 2.4676\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.644 | Val Acc: 0.420 | Train Loss: 1.6622 | Val Loss: 2.4676\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.653 | Val Acc: 0.413 | Train Loss: 1.6319 | Val Loss: 2.4646\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.653 | Val Acc: 0.413 | Train Loss: 1.6319 | Val Loss: 2.4646\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.669 | Val Acc: 0.420 | Train Loss: 1.6086 | Val Loss: 2.4802\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.669 | Val Acc: 0.420 | Train Loss: 1.6086 | Val Loss: 2.4802\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.679 | Val Acc: 0.413 | Train Loss: 1.5033 | Val Loss: 2.5259\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.679 | Val Acc: 0.413 | Train Loss: 1.5033 | Val Loss: 2.5259\n",
      "[Run 1] Epoch 30/40 | Train Acc: 0.694 | Val Acc: 0.413 | Train Loss: 1.5138 | Val Loss: 2.4417\n",
      "[Run 1] Epoch 30/40 | Train Acc: 0.694 | Val Acc: 0.413 | Train Loss: 1.5138 | Val Loss: 2.4417\n",
      "[Run 1] Epoch 31/40 | Train Acc: 0.701 | Val Acc: 0.447 | Train Loss: 1.4909 | Val Loss: 2.4144\n",
      "[Run 1] Epoch 31/40 | Train Acc: 0.701 | Val Acc: 0.447 | Train Loss: 1.4909 | Val Loss: 2.4144\n",
      "[Run 1] Epoch 32/40 | Train Acc: 0.724 | Val Acc: 0.443 | Train Loss: 1.4327 | Val Loss: 2.4630\n",
      "[Run 1] Epoch 32/40 | Train Acc: 0.724 | Val Acc: 0.443 | Train Loss: 1.4327 | Val Loss: 2.4630\n",
      "[Run 1] Epoch 33/40 | Train Acc: 0.763 | Val Acc: 0.400 | Train Loss: 1.3732 | Val Loss: 2.4086\n",
      "[Run 1] Epoch 33/40 | Train Acc: 0.763 | Val Acc: 0.400 | Train Loss: 1.3732 | Val Loss: 2.4086\n",
      "[Run 1] Epoch 34/40 | Train Acc: 0.732 | Val Acc: 0.437 | Train Loss: 1.4010 | Val Loss: 2.4150\n",
      "[Run 1] Epoch 34/40 | Train Acc: 0.732 | Val Acc: 0.437 | Train Loss: 1.4010 | Val Loss: 2.4150\n",
      "[Run 1] Epoch 35/40 | Train Acc: 0.740 | Val Acc: 0.450 | Train Loss: 1.3664 | Val Loss: 2.3985\n",
      "[Run 1] Epoch 35/40 | Train Acc: 0.740 | Val Acc: 0.450 | Train Loss: 1.3664 | Val Loss: 2.3985\n",
      "[Run 1] Epoch 36/40 | Train Acc: 0.765 | Val Acc: 0.460 | Train Loss: 1.3118 | Val Loss: 2.3802\n",
      "[Run 1] Epoch 36/40 | Train Acc: 0.765 | Val Acc: 0.460 | Train Loss: 1.3118 | Val Loss: 2.3802\n",
      "[Run 1] Epoch 37/40 | Train Acc: 0.784 | Val Acc: 0.443 | Train Loss: 1.2941 | Val Loss: 2.4052\n",
      "[Run 1] Epoch 37/40 | Train Acc: 0.784 | Val Acc: 0.443 | Train Loss: 1.2941 | Val Loss: 2.4052\n",
      "[Run 1] Epoch 38/40 | Train Acc: 0.771 | Val Acc: 0.463 | Train Loss: 1.2817 | Val Loss: 2.3762\n",
      "[Run 1] Epoch 38/40 | Train Acc: 0.771 | Val Acc: 0.463 | Train Loss: 1.2817 | Val Loss: 2.3762\n",
      "[Run 1] Epoch 39/40 | Train Acc: 0.764 | Val Acc: 0.440 | Train Loss: 1.3053 | Val Loss: 2.3679\n",
      "[Run 1] Epoch 39/40 | Train Acc: 0.764 | Val Acc: 0.440 | Train Loss: 1.3053 | Val Loss: 2.3679\n",
      "[Run 1] Epoch 40/40 | Train Acc: 0.791 | Val Acc: 0.447 | Train Loss: 1.2428 | Val Loss: 2.3822\n",
      "✅ [Run 1] Mejor Val Acc: 0.463\n",
      "[Run 1] Epoch 40/40 | Train Acc: 0.791 | Val Acc: 0.447 | Train Loss: 1.2428 | Val Loss: 2.3822\n",
      "✅ [Run 1] Mejor Val Acc: 0.463\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇█▇██████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▄▃▃▅▄▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██▇███████</td></tr><tr><td>val_f1_macro</td><td>▁▂▂▃▂▃▄▄▄▄▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██▇███████</td></tr><tr><td>val_f1_weighted</td><td>▁▂▂▃▂▃▄▄▄▄▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██▇███████</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▃▃▂▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▃▂▃▃▄▅▄▄▄▆▅▆▆▅▅▆▆▆▆▇▇▇▇▇▇█▇▇▇██▇███████</td></tr><tr><td>val_recall_macro</td><td>▁▂▂▄▃▃▅▄▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.46333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.79071</td></tr><tr><td>train_loss</td><td>1.24278</td></tr><tr><td>val_acc</td><td>0.44667</td></tr><tr><td>val_f1_macro</td><td>0.41307</td></tr><tr><td>val_f1_weighted</td><td>0.41307</td></tr><tr><td>val_loss</td><td>2.38216</td></tr><tr><td>val_precision_macro</td><td>0.45397</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-SGD_lr-0.001_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/rll8rxjk' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/rll8rxjk</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_182739-rll8rxjk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_183306-lwe0iubj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/lwe0iubj' target=\"_blank\">run_2_opt-SGD_lr-0.0005_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/lwe0iubj' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/lwe0iubj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamaño calculado para FC: 43264\n",
      "[Run 2] Epoch 1/40 | Train Acc: 0.041 | Val Acc: 0.103 | Train Loss: 4.1617 | Val Loss: 3.4721\n",
      "[Run 2] Epoch 1/40 | Train Acc: 0.041 | Val Acc: 0.103 | Train Loss: 4.1617 | Val Loss: 3.4721\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.081 | Val Acc: 0.140 | Train Loss: 3.8083 | Val Loss: 3.2910\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.081 | Val Acc: 0.140 | Train Loss: 3.8083 | Val Loss: 3.2910\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.095 | Val Acc: 0.197 | Train Loss: 3.6987 | Val Loss: 3.1789\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.095 | Val Acc: 0.197 | Train Loss: 3.6987 | Val Loss: 3.1789\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.134 | Val Acc: 0.223 | Train Loss: 3.5026 | Val Loss: 3.1260\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.134 | Val Acc: 0.223 | Train Loss: 3.5026 | Val Loss: 3.1260\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.148 | Val Acc: 0.243 | Train Loss: 3.4111 | Val Loss: 3.0268\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.148 | Val Acc: 0.243 | Train Loss: 3.4111 | Val Loss: 3.0268\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.161 | Val Acc: 0.233 | Train Loss: 3.3034 | Val Loss: 2.9953\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.161 | Val Acc: 0.233 | Train Loss: 3.3034 | Val Loss: 2.9953\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.193 | Val Acc: 0.247 | Train Loss: 3.1651 | Val Loss: 2.9404\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.193 | Val Acc: 0.247 | Train Loss: 3.1651 | Val Loss: 2.9404\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.206 | Val Acc: 0.253 | Train Loss: 3.1187 | Val Loss: 2.9486\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.206 | Val Acc: 0.253 | Train Loss: 3.1187 | Val Loss: 2.9486\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.228 | Val Acc: 0.287 | Train Loss: 2.9522 | Val Loss: 2.8310\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.228 | Val Acc: 0.287 | Train Loss: 2.9522 | Val Loss: 2.8310\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.238 | Val Acc: 0.277 | Train Loss: 2.8937 | Val Loss: 2.8045\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.238 | Val Acc: 0.277 | Train Loss: 2.8937 | Val Loss: 2.8045\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.279 | Val Acc: 0.300 | Train Loss: 2.7916 | Val Loss: 2.7620\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.279 | Val Acc: 0.300 | Train Loss: 2.7916 | Val Loss: 2.7620\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.302 | Val Acc: 0.320 | Train Loss: 2.7170 | Val Loss: 2.7078\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.302 | Val Acc: 0.320 | Train Loss: 2.7170 | Val Loss: 2.7078\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.323 | Val Acc: 0.313 | Train Loss: 2.6125 | Val Loss: 2.6776\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.323 | Val Acc: 0.313 | Train Loss: 2.6125 | Val Loss: 2.6776\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.353 | Val Acc: 0.330 | Train Loss: 2.5596 | Val Loss: 2.6407\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.353 | Val Acc: 0.330 | Train Loss: 2.5596 | Val Loss: 2.6407\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.371 | Val Acc: 0.337 | Train Loss: 2.4768 | Val Loss: 2.6188\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.371 | Val Acc: 0.337 | Train Loss: 2.4768 | Val Loss: 2.6188\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.386 | Val Acc: 0.373 | Train Loss: 2.4338 | Val Loss: 2.5569\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.386 | Val Acc: 0.373 | Train Loss: 2.4338 | Val Loss: 2.5569\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.397 | Val Acc: 0.397 | Train Loss: 2.3565 | Val Loss: 2.5511\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.397 | Val Acc: 0.397 | Train Loss: 2.3565 | Val Loss: 2.5511\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.449 | Val Acc: 0.350 | Train Loss: 2.2615 | Val Loss: 2.5528\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.449 | Val Acc: 0.350 | Train Loss: 2.2615 | Val Loss: 2.5528\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.455 | Val Acc: 0.390 | Train Loss: 2.2265 | Val Loss: 2.5237\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.455 | Val Acc: 0.390 | Train Loss: 2.2265 | Val Loss: 2.5237\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.476 | Val Acc: 0.390 | Train Loss: 2.1536 | Val Loss: 2.5036\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.476 | Val Acc: 0.390 | Train Loss: 2.1536 | Val Loss: 2.5036\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.488 | Val Acc: 0.393 | Train Loss: 2.1048 | Val Loss: 2.4872\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.488 | Val Acc: 0.393 | Train Loss: 2.1048 | Val Loss: 2.4872\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.508 | Val Acc: 0.423 | Train Loss: 2.0517 | Val Loss: 2.4571\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.508 | Val Acc: 0.423 | Train Loss: 2.0517 | Val Loss: 2.4571\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.533 | Val Acc: 0.427 | Train Loss: 1.9897 | Val Loss: 2.4871\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.533 | Val Acc: 0.427 | Train Loss: 1.9897 | Val Loss: 2.4871\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.535 | Val Acc: 0.420 | Train Loss: 1.9615 | Val Loss: 2.4220\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.535 | Val Acc: 0.420 | Train Loss: 1.9615 | Val Loss: 2.4220\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.561 | Val Acc: 0.453 | Train Loss: 1.8980 | Val Loss: 2.3902\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.561 | Val Acc: 0.453 | Train Loss: 1.8980 | Val Loss: 2.3902\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.586 | Val Acc: 0.443 | Train Loss: 1.8520 | Val Loss: 2.4086\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.586 | Val Acc: 0.443 | Train Loss: 1.8520 | Val Loss: 2.4086\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.613 | Val Acc: 0.440 | Train Loss: 1.7950 | Val Loss: 2.3757\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.613 | Val Acc: 0.440 | Train Loss: 1.7950 | Val Loss: 2.3757\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.608 | Val Acc: 0.423 | Train Loss: 1.7747 | Val Loss: 2.4010\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.608 | Val Acc: 0.423 | Train Loss: 1.7747 | Val Loss: 2.4010\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.658 | Val Acc: 0.443 | Train Loss: 1.6729 | Val Loss: 2.3541\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.658 | Val Acc: 0.443 | Train Loss: 1.6729 | Val Loss: 2.3541\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.629 | Val Acc: 0.430 | Train Loss: 1.7279 | Val Loss: 2.3602\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.629 | Val Acc: 0.430 | Train Loss: 1.7279 | Val Loss: 2.3602\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.641 | Val Acc: 0.417 | Train Loss: 1.7032 | Val Loss: 2.3623\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.641 | Val Acc: 0.417 | Train Loss: 1.7032 | Val Loss: 2.3623\n",
      "[Run 2] Epoch 32/40 | Train Acc: 0.668 | Val Acc: 0.440 | Train Loss: 1.6424 | Val Loss: 2.3793\n",
      "[Run 2] Early stopping triggered at epoch 32.\n",
      "✅ [Run 2] Mejor Val Acc: 0.453\n",
      "[Run 2] Epoch 32/40 | Train Acc: 0.668 | Val Acc: 0.440 | Train Loss: 1.6424 | Val Loss: 2.3793\n",
      "[Run 2] Early stopping triggered at epoch 32.\n",
      "✅ [Run 2] Mejor Val Acc: 0.453\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▃▄▄▄▄▅▄▅▅▅▆▆▆▇▆▇▇▇▇▇▇███▇██▇█</td></tr><tr><td>val_f1_macro</td><td>▁▂▂▃▃▃▄▄▄▄▄▅▅▅▆▆▇▆▇▇▇▇█▇███▇██▇█</td></tr><tr><td>val_f1_weighted</td><td>▁▂▂▃▃▃▄▄▄▄▄▅▅▅▆▆▇▆▇▇▇▇█▇███▇██▇█</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▂▃▃▃▃▄▄▄▄▅▄▅▅▆▇▅▆▇▆▇▇▇█▇█▇▇▇▇█</td></tr><tr><td>val_recall_macro</td><td>▁▂▃▃▄▄▄▄▅▄▅▅▅▆▆▆▇▆▇▇▇▇▇▇███▇██▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.45333</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>lr</td><td>0.00012</td></tr><tr><td>train_acc</td><td>0.66786</td></tr><tr><td>train_loss</td><td>1.64244</td></tr><tr><td>val_acc</td><td>0.44</td></tr><tr><td>val_f1_macro</td><td>0.41345</td></tr><tr><td>val_f1_weighted</td><td>0.41345</td></tr><tr><td>val_loss</td><td>2.3793</td></tr><tr><td>val_precision_macro</td><td>0.47</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-SGD_lr-0.0005_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/lwe0iubj' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/lwe0iubj</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified</a><br>Synced 5 W&B file(s), 32 media file(s), 64 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_183306-lwe0iubj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_183754-rizsp1so</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/rizsp1so' target=\"_blank\">run_3_opt-SGD_lr-0.001_bs-64</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/rizsp1so' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/rizsp1so</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamaño calculado para FC: 43264\n",
      "[Run 3] Epoch 1/40 | Train Acc: 0.040 | Val Acc: 0.060 | Train Loss: 4.2723 | Val Loss: 3.5778\n",
      "[Run 3] Epoch 1/40 | Train Acc: 0.040 | Val Acc: 0.060 | Train Loss: 4.2723 | Val Loss: 3.5778\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.078 | Val Acc: 0.123 | Train Loss: 3.8235 | Val Loss: 3.3593\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.078 | Val Acc: 0.123 | Train Loss: 3.8235 | Val Loss: 3.3593\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.101 | Val Acc: 0.140 | Train Loss: 3.6025 | Val Loss: 3.2522\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.101 | Val Acc: 0.140 | Train Loss: 3.6025 | Val Loss: 3.2522\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.116 | Val Acc: 0.180 | Train Loss: 3.5556 | Val Loss: 3.1247\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.116 | Val Acc: 0.180 | Train Loss: 3.5556 | Val Loss: 3.1247\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.150 | Val Acc: 0.217 | Train Loss: 3.3424 | Val Loss: 3.0691\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.150 | Val Acc: 0.217 | Train Loss: 3.3424 | Val Loss: 3.0691\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.162 | Val Acc: 0.193 | Train Loss: 3.2504 | Val Loss: 2.9939\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.162 | Val Acc: 0.193 | Train Loss: 3.2504 | Val Loss: 2.9939\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.189 | Val Acc: 0.217 | Train Loss: 3.1683 | Val Loss: 2.9632\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.189 | Val Acc: 0.217 | Train Loss: 3.1683 | Val Loss: 2.9632\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.195 | Val Acc: 0.240 | Train Loss: 3.1147 | Val Loss: 2.9662\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.195 | Val Acc: 0.240 | Train Loss: 3.1147 | Val Loss: 2.9662\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.231 | Val Acc: 0.280 | Train Loss: 2.9449 | Val Loss: 2.8163\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.231 | Val Acc: 0.280 | Train Loss: 2.9449 | Val Loss: 2.8163\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.271 | Val Acc: 0.270 | Train Loss: 2.8493 | Val Loss: 2.8743\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.271 | Val Acc: 0.270 | Train Loss: 2.8493 | Val Loss: 2.8743\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.293 | Val Acc: 0.293 | Train Loss: 2.7583 | Val Loss: 2.7622\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.293 | Val Acc: 0.293 | Train Loss: 2.7583 | Val Loss: 2.7622\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.321 | Val Acc: 0.297 | Train Loss: 2.6666 | Val Loss: 2.7366\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.321 | Val Acc: 0.297 | Train Loss: 2.6666 | Val Loss: 2.7366\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.334 | Val Acc: 0.330 | Train Loss: 2.6259 | Val Loss: 2.6598\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.334 | Val Acc: 0.330 | Train Loss: 2.6259 | Val Loss: 2.6598\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.371 | Val Acc: 0.300 | Train Loss: 2.4812 | Val Loss: 2.6486\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.371 | Val Acc: 0.300 | Train Loss: 2.4812 | Val Loss: 2.6486\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.395 | Val Acc: 0.300 | Train Loss: 2.4390 | Val Loss: 2.6798\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.395 | Val Acc: 0.300 | Train Loss: 2.4390 | Val Loss: 2.6798\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.409 | Val Acc: 0.337 | Train Loss: 2.3354 | Val Loss: 2.5870\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.409 | Val Acc: 0.337 | Train Loss: 2.3354 | Val Loss: 2.5870\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.422 | Val Acc: 0.387 | Train Loss: 2.3220 | Val Loss: 2.4985\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.422 | Val Acc: 0.387 | Train Loss: 2.3220 | Val Loss: 2.4985\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.447 | Val Acc: 0.383 | Train Loss: 2.1692 | Val Loss: 2.5074\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.447 | Val Acc: 0.383 | Train Loss: 2.1692 | Val Loss: 2.5074\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.473 | Val Acc: 0.367 | Train Loss: 2.1656 | Val Loss: 2.5170\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.473 | Val Acc: 0.367 | Train Loss: 2.1656 | Val Loss: 2.5170\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.491 | Val Acc: 0.370 | Train Loss: 2.1069 | Val Loss: 2.4568\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.491 | Val Acc: 0.370 | Train Loss: 2.1069 | Val Loss: 2.4568\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.506 | Val Acc: 0.383 | Train Loss: 2.0450 | Val Loss: 2.4419\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.506 | Val Acc: 0.383 | Train Loss: 2.0450 | Val Loss: 2.4419\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.526 | Val Acc: 0.417 | Train Loss: 1.9972 | Val Loss: 2.4025\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.526 | Val Acc: 0.417 | Train Loss: 1.9972 | Val Loss: 2.4025\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.561 | Val Acc: 0.410 | Train Loss: 1.9173 | Val Loss: 2.4226\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.561 | Val Acc: 0.410 | Train Loss: 1.9173 | Val Loss: 2.4226\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.561 | Val Acc: 0.417 | Train Loss: 1.9013 | Val Loss: 2.4080\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.561 | Val Acc: 0.417 | Train Loss: 1.9013 | Val Loss: 2.4080\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.572 | Val Acc: 0.403 | Train Loss: 1.8687 | Val Loss: 2.4412\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.572 | Val Acc: 0.403 | Train Loss: 1.8687 | Val Loss: 2.4412\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.588 | Val Acc: 0.423 | Train Loss: 1.8124 | Val Loss: 2.3783\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.588 | Val Acc: 0.423 | Train Loss: 1.8124 | Val Loss: 2.3783\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.596 | Val Acc: 0.433 | Train Loss: 1.7938 | Val Loss: 2.3444\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.596 | Val Acc: 0.433 | Train Loss: 1.7938 | Val Loss: 2.3444\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.654 | Val Acc: 0.413 | Train Loss: 1.7038 | Val Loss: 2.3853\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.654 | Val Acc: 0.413 | Train Loss: 1.7038 | Val Loss: 2.3853\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.622 | Val Acc: 0.423 | Train Loss: 1.7261 | Val Loss: 2.3438\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.622 | Val Acc: 0.423 | Train Loss: 1.7261 | Val Loss: 2.3438\n",
      "[Run 3] Epoch 30/40 | Train Acc: 0.623 | Val Acc: 0.450 | Train Loss: 1.7079 | Val Loss: 2.3307\n",
      "[Run 3] Epoch 30/40 | Train Acc: 0.623 | Val Acc: 0.450 | Train Loss: 1.7079 | Val Loss: 2.3307\n",
      "[Run 3] Epoch 31/40 | Train Acc: 0.653 | Val Acc: 0.397 | Train Loss: 1.6713 | Val Loss: 2.3825\n",
      "[Run 3] Epoch 31/40 | Train Acc: 0.653 | Val Acc: 0.397 | Train Loss: 1.6713 | Val Loss: 2.3825\n",
      "[Run 3] Epoch 32/40 | Train Acc: 0.655 | Val Acc: 0.420 | Train Loss: 1.6344 | Val Loss: 2.3680\n",
      "[Run 3] Epoch 32/40 | Train Acc: 0.655 | Val Acc: 0.420 | Train Loss: 1.6344 | Val Loss: 2.3680\n",
      "[Run 3] Epoch 33/40 | Train Acc: 0.696 | Val Acc: 0.430 | Train Loss: 1.5683 | Val Loss: 2.4269\n",
      "[Run 3] Epoch 33/40 | Train Acc: 0.696 | Val Acc: 0.430 | Train Loss: 1.5683 | Val Loss: 2.4269\n",
      "[Run 3] Epoch 34/40 | Train Acc: 0.674 | Val Acc: 0.437 | Train Loss: 1.5649 | Val Loss: 2.3137\n",
      "[Run 3] Epoch 34/40 | Train Acc: 0.674 | Val Acc: 0.437 | Train Loss: 1.5649 | Val Loss: 2.3137\n",
      "[Run 3] Epoch 35/40 | Train Acc: 0.678 | Val Acc: 0.457 | Train Loss: 1.5544 | Val Loss: 2.2990\n",
      "[Run 3] Epoch 35/40 | Train Acc: 0.678 | Val Acc: 0.457 | Train Loss: 1.5544 | Val Loss: 2.2990\n",
      "[Run 3] Epoch 36/40 | Train Acc: 0.691 | Val Acc: 0.427 | Train Loss: 1.5630 | Val Loss: 2.3076\n",
      "[Run 3] Epoch 36/40 | Train Acc: 0.691 | Val Acc: 0.427 | Train Loss: 1.5630 | Val Loss: 2.3076\n",
      "[Run 3] Epoch 37/40 | Train Acc: 0.704 | Val Acc: 0.447 | Train Loss: 1.5224 | Val Loss: 2.2978\n",
      "[Run 3] Epoch 37/40 | Train Acc: 0.704 | Val Acc: 0.447 | Train Loss: 1.5224 | Val Loss: 2.2978\n",
      "[Run 3] Epoch 38/40 | Train Acc: 0.693 | Val Acc: 0.447 | Train Loss: 1.5131 | Val Loss: 2.2734\n",
      "[Run 3] Epoch 38/40 | Train Acc: 0.693 | Val Acc: 0.447 | Train Loss: 1.5131 | Val Loss: 2.2734\n",
      "[Run 3] Epoch 39/40 | Train Acc: 0.709 | Val Acc: 0.437 | Train Loss: 1.4637 | Val Loss: 2.3184\n",
      "[Run 3] Epoch 39/40 | Train Acc: 0.709 | Val Acc: 0.437 | Train Loss: 1.4637 | Val Loss: 2.3184\n",
      "[Run 3] Epoch 40/40 | Train Acc: 0.741 | Val Acc: 0.467 | Train Loss: 1.4433 | Val Loss: 2.2626\n",
      "✅ [Run 3] Mejor Val Acc: 0.467\n",
      "[Run 3] Epoch 40/40 | Train Acc: 0.741 | Val Acc: 0.467 | Train Loss: 1.4433 | Val Loss: 2.2626\n",
      "✅ [Run 3] Mejor Val Acc: 0.467\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█▇▇█████</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▃▄▃▄▄▅▅▅▅▆▅▅▆▇▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇██▇█</td></tr><tr><td>val_f1_macro</td><td>▁▂▂▃▃▃▃▄▅▄▅▅▆▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇████</td></tr><tr><td>val_f1_weighted</td><td>▁▂▂▃▃▃▃▄▅▄▅▅▆▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇████</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▂▂▃▄▃▄▄▅▅▅▅▆▅▅▆▆▇▇▆▇▇█▇▇▇▇▇▇█▇█▇███████</td></tr><tr><td>val_recall_macro</td><td>▁▂▂▃▄▃▄▄▅▅▅▅▆▅▅▆▇▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇██▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.46667</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.74071</td></tr><tr><td>train_loss</td><td>1.44332</td></tr><tr><td>val_acc</td><td>0.46667</td></tr><tr><td>val_f1_macro</td><td>0.4382</td></tr><tr><td>val_f1_weighted</td><td>0.4382</td></tr><tr><td>val_loss</td><td>2.2626</td></tr><tr><td>val_precision_macro</td><td>0.4449</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-SGD_lr-0.001_bs-64</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/rizsp1so' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/rizsp1so</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_183754-rizsp1so/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_184401-aotfbcpf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/aotfbcpf' target=\"_blank\">run_4_opt-SGD_lr-0.01_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/aotfbcpf' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/aotfbcpf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamaño calculado para FC: 43264\n",
      "[Run 4] Epoch 1/40 | Train Acc: 0.046 | Val Acc: 0.077 | Train Loss: 4.2342 | Val Loss: 3.6647\n",
      "[Run 4] Epoch 1/40 | Train Acc: 0.046 | Val Acc: 0.077 | Train Loss: 4.2342 | Val Loss: 3.6647\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.064 | Val Acc: 0.087 | Train Loss: 3.9872 | Val Loss: 3.5392\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.064 | Val Acc: 0.087 | Train Loss: 3.9872 | Val Loss: 3.5392\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.074 | Val Acc: 0.087 | Train Loss: 3.8291 | Val Loss: 3.5265\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.074 | Val Acc: 0.087 | Train Loss: 3.8291 | Val Loss: 3.5265\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.105 | Val Acc: 0.147 | Train Loss: 3.6944 | Val Loss: 3.4429\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.105 | Val Acc: 0.147 | Train Loss: 3.6944 | Val Loss: 3.4429\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.101 | Val Acc: 0.153 | Train Loss: 3.5926 | Val Loss: 3.3097\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.101 | Val Acc: 0.153 | Train Loss: 3.5926 | Val Loss: 3.3097\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.119 | Val Acc: 0.207 | Train Loss: 3.4622 | Val Loss: 3.3040\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.119 | Val Acc: 0.207 | Train Loss: 3.4622 | Val Loss: 3.3040\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.144 | Val Acc: 0.153 | Train Loss: 3.3896 | Val Loss: 3.3171\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.144 | Val Acc: 0.153 | Train Loss: 3.3896 | Val Loss: 3.3171\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.146 | Val Acc: 0.167 | Train Loss: 3.3372 | Val Loss: 3.0938\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.146 | Val Acc: 0.167 | Train Loss: 3.3372 | Val Loss: 3.0938\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.177 | Val Acc: 0.220 | Train Loss: 3.1665 | Val Loss: 3.0794\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.177 | Val Acc: 0.220 | Train Loss: 3.1665 | Val Loss: 3.0794\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.204 | Val Acc: 0.227 | Train Loss: 3.0043 | Val Loss: 2.9623\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.204 | Val Acc: 0.227 | Train Loss: 3.0043 | Val Loss: 2.9623\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.211 | Val Acc: 0.250 | Train Loss: 2.9716 | Val Loss: 2.9507\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.211 | Val Acc: 0.250 | Train Loss: 2.9716 | Val Loss: 2.9507\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.240 | Val Acc: 0.250 | Train Loss: 2.8426 | Val Loss: 3.0354\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.240 | Val Acc: 0.250 | Train Loss: 2.8426 | Val Loss: 3.0354\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.263 | Val Acc: 0.293 | Train Loss: 2.7858 | Val Loss: 2.8763\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.263 | Val Acc: 0.293 | Train Loss: 2.7858 | Val Loss: 2.8763\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.266 | Val Acc: 0.267 | Train Loss: 2.7238 | Val Loss: 2.9070\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.266 | Val Acc: 0.267 | Train Loss: 2.7238 | Val Loss: 2.9070\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.287 | Val Acc: 0.250 | Train Loss: 2.6642 | Val Loss: 2.9213\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.287 | Val Acc: 0.250 | Train Loss: 2.6642 | Val Loss: 2.9213\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.283 | Val Acc: 0.317 | Train Loss: 2.6249 | Val Loss: 2.7255\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.283 | Val Acc: 0.317 | Train Loss: 2.6249 | Val Loss: 2.7255\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.326 | Val Acc: 0.343 | Train Loss: 2.5133 | Val Loss: 2.5909\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.326 | Val Acc: 0.343 | Train Loss: 2.5133 | Val Loss: 2.5909\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.357 | Val Acc: 0.343 | Train Loss: 2.4249 | Val Loss: 2.6583\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.357 | Val Acc: 0.343 | Train Loss: 2.4249 | Val Loss: 2.6583\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.379 | Val Acc: 0.363 | Train Loss: 2.3847 | Val Loss: 2.6221\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.379 | Val Acc: 0.363 | Train Loss: 2.3847 | Val Loss: 2.6221\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.368 | Val Acc: 0.277 | Train Loss: 2.3815 | Val Loss: 3.3048\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.368 | Val Acc: 0.277 | Train Loss: 2.3815 | Val Loss: 3.3048\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.386 | Val Acc: 0.363 | Train Loss: 2.2918 | Val Loss: 2.5839\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.386 | Val Acc: 0.363 | Train Loss: 2.2918 | Val Loss: 2.5839\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.414 | Val Acc: 0.343 | Train Loss: 2.1909 | Val Loss: 2.6742\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.414 | Val Acc: 0.343 | Train Loss: 2.1909 | Val Loss: 2.6742\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.429 | Val Acc: 0.383 | Train Loss: 2.1679 | Val Loss: 2.5526\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.429 | Val Acc: 0.383 | Train Loss: 2.1679 | Val Loss: 2.5526\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.442 | Val Acc: 0.373 | Train Loss: 2.1349 | Val Loss: 2.6033\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.442 | Val Acc: 0.373 | Train Loss: 2.1349 | Val Loss: 2.6033\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.445 | Val Acc: 0.380 | Train Loss: 2.0828 | Val Loss: 2.5922\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.445 | Val Acc: 0.380 | Train Loss: 2.0828 | Val Loss: 2.5922\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.501 | Val Acc: 0.423 | Train Loss: 2.0094 | Val Loss: 2.4945\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.501 | Val Acc: 0.423 | Train Loss: 2.0094 | Val Loss: 2.4945\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.499 | Val Acc: 0.417 | Train Loss: 1.9474 | Val Loss: 2.5063\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.499 | Val Acc: 0.417 | Train Loss: 1.9474 | Val Loss: 2.5063\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.505 | Val Acc: 0.407 | Train Loss: 1.9599 | Val Loss: 2.5294\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.505 | Val Acc: 0.407 | Train Loss: 1.9599 | Val Loss: 2.5294\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.524 | Val Acc: 0.390 | Train Loss: 1.8810 | Val Loss: 2.5806\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.524 | Val Acc: 0.390 | Train Loss: 1.8810 | Val Loss: 2.5806\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.554 | Val Acc: 0.427 | Train Loss: 1.8313 | Val Loss: 2.4235\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.554 | Val Acc: 0.427 | Train Loss: 1.8313 | Val Loss: 2.4235\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.558 | Val Acc: 0.440 | Train Loss: 1.7787 | Val Loss: 2.4459\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.558 | Val Acc: 0.440 | Train Loss: 1.7787 | Val Loss: 2.4459\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.564 | Val Acc: 0.433 | Train Loss: 1.7640 | Val Loss: 2.4363\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.564 | Val Acc: 0.433 | Train Loss: 1.7640 | Val Loss: 2.4363\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.601 | Val Acc: 0.430 | Train Loss: 1.6747 | Val Loss: 2.4504\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.601 | Val Acc: 0.430 | Train Loss: 1.6747 | Val Loss: 2.4504\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.600 | Val Acc: 0.450 | Train Loss: 1.7058 | Val Loss: 2.3965\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.600 | Val Acc: 0.450 | Train Loss: 1.7058 | Val Loss: 2.3965\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.614 | Val Acc: 0.443 | Train Loss: 1.6246 | Val Loss: 2.3812\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.614 | Val Acc: 0.443 | Train Loss: 1.6246 | Val Loss: 2.3812\n",
      "[Run 4] Epoch 36/40 | Train Acc: 0.626 | Val Acc: 0.437 | Train Loss: 1.6059 | Val Loss: 2.4501\n",
      "[Run 4] Epoch 36/40 | Train Acc: 0.626 | Val Acc: 0.437 | Train Loss: 1.6059 | Val Loss: 2.4501\n",
      "[Run 4] Epoch 37/40 | Train Acc: 0.634 | Val Acc: 0.427 | Train Loss: 1.5728 | Val Loss: 2.4735\n",
      "[Run 4] Epoch 37/40 | Train Acc: 0.634 | Val Acc: 0.427 | Train Loss: 1.5728 | Val Loss: 2.4735\n",
      "[Run 4] Epoch 38/40 | Train Acc: 0.644 | Val Acc: 0.480 | Train Loss: 1.5401 | Val Loss: 2.3443\n",
      "[Run 4] Epoch 38/40 | Train Acc: 0.644 | Val Acc: 0.480 | Train Loss: 1.5401 | Val Loss: 2.3443\n",
      "[Run 4] Epoch 39/40 | Train Acc: 0.635 | Val Acc: 0.450 | Train Loss: 1.5559 | Val Loss: 2.4265\n",
      "[Run 4] Epoch 39/40 | Train Acc: 0.635 | Val Acc: 0.450 | Train Loss: 1.5559 | Val Loss: 2.4265\n",
      "[Run 4] Epoch 40/40 | Train Acc: 0.674 | Val Acc: 0.447 | Train Loss: 1.4903 | Val Loss: 2.3858\n",
      "✅ [Run 4] Mejor Val Acc: 0.480\n",
      "[Run 4] Epoch 40/40 | Train Acc: 0.674 | Val Acc: 0.447 | Train Loss: 1.4903 | Val Loss: 2.3858\n",
      "✅ [Run 4] Mejor Val Acc: 0.480\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▂▂▃▂▃▃▄▄▄▅▄▄▅▆▆▆▄▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>val_f1_macro</td><td>▁▁▁▂▂▃▂▃▃▃▄▄▄▄▄▅▅▆▆▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>val_f1_weighted</td><td>▁▁▁▂▂▃▂▃▃▃▄▄▄▄▄▅▅▆▆▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>val_loss</td><td>█▇▇▇▆▆▆▅▅▄▄▅▄▄▄▃▂▃▂▆▂▃▂▂▂▂▂▂▂▁▂▁▂▁▁▂▂▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▁▂▃▃▃▃▃▄▄▄▅▄▄▆▅▆▆▅▆▆▇▇▇▇▇▇▇▇█▇▇███▇██▇</td></tr><tr><td>val_recall_macro</td><td>▁▁▁▂▂▃▂▃▃▄▄▄▅▄▄▅▆▆▆▄▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.48</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00168</td></tr><tr><td>train_acc</td><td>0.67357</td></tr><tr><td>train_loss</td><td>1.49028</td></tr><tr><td>val_acc</td><td>0.44667</td></tr><tr><td>val_f1_macro</td><td>0.42516</td></tr><tr><td>val_f1_weighted</td><td>0.42516</td></tr><tr><td>val_loss</td><td>2.38583</td></tr><tr><td>val_precision_macro</td><td>0.4353</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-SGD_lr-0.01_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/aotfbcpf' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/aotfbcpf</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_184401-aotfbcpf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_185029-1402nej8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/1402nej8' target=\"_blank\">run_5_opt-SGD_lr-0.001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/1402nej8' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/1402nej8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamaño calculado para FC: 43264\n",
      "[Run 5] Epoch 1/40 | Train Acc: 0.046 | Val Acc: 0.067 | Train Loss: 4.1701 | Val Loss: 3.5367\n",
      "[Run 5] Epoch 1/40 | Train Acc: 0.046 | Val Acc: 0.067 | Train Loss: 4.1701 | Val Loss: 3.5367\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.061 | Val Acc: 0.140 | Train Loss: 3.9072 | Val Loss: 3.4141\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.061 | Val Acc: 0.140 | Train Loss: 3.9072 | Val Loss: 3.4141\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.090 | Val Acc: 0.133 | Train Loss: 3.7757 | Val Loss: 3.3805\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.090 | Val Acc: 0.133 | Train Loss: 3.7757 | Val Loss: 3.3805\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.104 | Val Acc: 0.160 | Train Loss: 3.6490 | Val Loss: 3.2587\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.104 | Val Acc: 0.160 | Train Loss: 3.6490 | Val Loss: 3.2587\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.119 | Val Acc: 0.193 | Train Loss: 3.5322 | Val Loss: 3.1783\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.119 | Val Acc: 0.193 | Train Loss: 3.5322 | Val Loss: 3.1783\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.131 | Val Acc: 0.190 | Train Loss: 3.4843 | Val Loss: 3.1221\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.131 | Val Acc: 0.190 | Train Loss: 3.4843 | Val Loss: 3.1221\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.141 | Val Acc: 0.243 | Train Loss: 3.4025 | Val Loss: 2.9842\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.141 | Val Acc: 0.243 | Train Loss: 3.4025 | Val Loss: 2.9842\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.161 | Val Acc: 0.250 | Train Loss: 3.2819 | Val Loss: 2.9953\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.161 | Val Acc: 0.250 | Train Loss: 3.2819 | Val Loss: 2.9953\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.184 | Val Acc: 0.250 | Train Loss: 3.1578 | Val Loss: 2.9122\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.184 | Val Acc: 0.250 | Train Loss: 3.1578 | Val Loss: 2.9122\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.224 | Val Acc: 0.310 | Train Loss: 2.9493 | Val Loss: 2.7512\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.224 | Val Acc: 0.310 | Train Loss: 2.9493 | Val Loss: 2.7512\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.256 | Val Acc: 0.207 | Train Loss: 2.8855 | Val Loss: 3.0678\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.256 | Val Acc: 0.207 | Train Loss: 2.8855 | Val Loss: 3.0678\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.260 | Val Acc: 0.327 | Train Loss: 2.8249 | Val Loss: 2.6706\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.260 | Val Acc: 0.327 | Train Loss: 2.8249 | Val Loss: 2.6706\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.284 | Val Acc: 0.330 | Train Loss: 2.7351 | Val Loss: 2.7007\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.284 | Val Acc: 0.330 | Train Loss: 2.7351 | Val Loss: 2.7007\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.336 | Val Acc: 0.350 | Train Loss: 2.5860 | Val Loss: 2.6094\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.336 | Val Acc: 0.350 | Train Loss: 2.5860 | Val Loss: 2.6094\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.362 | Val Acc: 0.340 | Train Loss: 2.4953 | Val Loss: 2.6968\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.362 | Val Acc: 0.340 | Train Loss: 2.4953 | Val Loss: 2.6968\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.366 | Val Acc: 0.350 | Train Loss: 2.4155 | Val Loss: 2.6895\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.366 | Val Acc: 0.350 | Train Loss: 2.4155 | Val Loss: 2.6895\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.429 | Val Acc: 0.387 | Train Loss: 2.2638 | Val Loss: 2.4767\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.429 | Val Acc: 0.387 | Train Loss: 2.2638 | Val Loss: 2.4767\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.476 | Val Acc: 0.383 | Train Loss: 2.1427 | Val Loss: 2.5617\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.476 | Val Acc: 0.383 | Train Loss: 2.1427 | Val Loss: 2.5617\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.478 | Val Acc: 0.393 | Train Loss: 2.1275 | Val Loss: 2.4971\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.478 | Val Acc: 0.393 | Train Loss: 2.1275 | Val Loss: 2.4971\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.480 | Val Acc: 0.413 | Train Loss: 2.0740 | Val Loss: 2.4639\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.480 | Val Acc: 0.413 | Train Loss: 2.0740 | Val Loss: 2.4639\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.509 | Val Acc: 0.387 | Train Loss: 1.9562 | Val Loss: 2.4321\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.509 | Val Acc: 0.387 | Train Loss: 1.9562 | Val Loss: 2.4321\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.537 | Val Acc: 0.410 | Train Loss: 1.9005 | Val Loss: 2.4916\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.537 | Val Acc: 0.410 | Train Loss: 1.9005 | Val Loss: 2.4916\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.577 | Val Acc: 0.393 | Train Loss: 1.8194 | Val Loss: 2.5310\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.577 | Val Acc: 0.393 | Train Loss: 1.8194 | Val Loss: 2.5310\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.592 | Val Acc: 0.397 | Train Loss: 1.7663 | Val Loss: 2.5058\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.592 | Val Acc: 0.397 | Train Loss: 1.7663 | Val Loss: 2.5058\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.617 | Val Acc: 0.410 | Train Loss: 1.6906 | Val Loss: 2.4320\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.617 | Val Acc: 0.410 | Train Loss: 1.6906 | Val Loss: 2.4320\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.642 | Val Acc: 0.427 | Train Loss: 1.6492 | Val Loss: 2.3891\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.642 | Val Acc: 0.427 | Train Loss: 1.6492 | Val Loss: 2.3891\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.659 | Val Acc: 0.453 | Train Loss: 1.5819 | Val Loss: 2.3519\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.659 | Val Acc: 0.453 | Train Loss: 1.5819 | Val Loss: 2.3519\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.667 | Val Acc: 0.433 | Train Loss: 1.5546 | Val Loss: 2.3722\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.667 | Val Acc: 0.433 | Train Loss: 1.5546 | Val Loss: 2.3722\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.687 | Val Acc: 0.437 | Train Loss: 1.4867 | Val Loss: 2.3507\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.687 | Val Acc: 0.437 | Train Loss: 1.4867 | Val Loss: 2.3507\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.684 | Val Acc: 0.450 | Train Loss: 1.4833 | Val Loss: 2.3239\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.684 | Val Acc: 0.450 | Train Loss: 1.4833 | Val Loss: 2.3239\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.721 | Val Acc: 0.427 | Train Loss: 1.3998 | Val Loss: 2.3516\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.721 | Val Acc: 0.427 | Train Loss: 1.3998 | Val Loss: 2.3516\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.711 | Val Acc: 0.443 | Train Loss: 1.4078 | Val Loss: 2.3048\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.711 | Val Acc: 0.443 | Train Loss: 1.4078 | Val Loss: 2.3048\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.741 | Val Acc: 0.480 | Train Loss: 1.3304 | Val Loss: 2.2778\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.741 | Val Acc: 0.480 | Train Loss: 1.3304 | Val Loss: 2.2778\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.767 | Val Acc: 0.440 | Train Loss: 1.2979 | Val Loss: 2.3525\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.767 | Val Acc: 0.440 | Train Loss: 1.2979 | Val Loss: 2.3525\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.772 | Val Acc: 0.463 | Train Loss: 1.2636 | Val Loss: 2.3137\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.772 | Val Acc: 0.463 | Train Loss: 1.2636 | Val Loss: 2.3137\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.774 | Val Acc: 0.473 | Train Loss: 1.2444 | Val Loss: 2.3110\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.774 | Val Acc: 0.473 | Train Loss: 1.2444 | Val Loss: 2.3110\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.771 | Val Acc: 0.473 | Train Loss: 1.2274 | Val Loss: 2.3993\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.771 | Val Acc: 0.473 | Train Loss: 1.2274 | Val Loss: 2.3993\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.786 | Val Acc: 0.487 | Train Loss: 1.2118 | Val Loss: 2.2726\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.786 | Val Acc: 0.487 | Train Loss: 1.2118 | Val Loss: 2.2726\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.820 | Val Acc: 0.467 | Train Loss: 1.1567 | Val Loss: 2.2857\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.820 | Val Acc: 0.467 | Train Loss: 1.1567 | Val Loss: 2.2857\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.820 | Val Acc: 0.453 | Train Loss: 1.1504 | Val Loss: 2.2959\n",
      "✅ [Run 5] Mejor Val Acc: 0.487\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.820 | Val Acc: 0.453 | Train Loss: 1.1504 | Val Loss: 2.2959\n",
      "✅ [Run 5] Mejor Val Acc: 0.487\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███████</td></tr><tr><td>train_loss</td><td>█▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▃▃▃▄▄▄▅▃▅▅▆▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇█▇█████▇</td></tr><tr><td>val_f1_macro</td><td>▁▂▂▂▃▃▄▄▄▅▃▅▅▆▅▅▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇█▇██████</td></tr><tr><td>val_f1_weighted</td><td>▁▂▂▂▃▃▄▄▄▅▃▅▅▆▅▅▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇█▇██████</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▆▅▅▅▄▅▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▃▂▃▃▄▅▄▅▆▄▆▅▆▆▆▇▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>val_recall_macro</td><td>▁▂▂▃▃▃▄▄▄▅▃▅▅▆▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇█▇█████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.48667</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.82</td></tr><tr><td>train_loss</td><td>1.1504</td></tr><tr><td>val_acc</td><td>0.45333</td></tr><tr><td>val_f1_macro</td><td>0.43001</td></tr><tr><td>val_f1_weighted</td><td>0.43001</td></tr><tr><td>val_loss</td><td>2.29591</td></tr><tr><td>val_precision_macro</td><td>0.45356</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/1402nej8' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified/runs/1402nej8</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet_stratified</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_185029-1402nej8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# ==============================\n",
    "# CONFIGURACIÓN\n",
    "# ==============================\n",
    "DATA_DIR = \"data/spectrograms2/base\"\n",
    "IMG_SIZE = (224, 224)\n",
    "EPOCHS = 40\n",
    "PATIENCE = 6\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==============================\n",
    "# TRANSFORMACIONES\n",
    "# ==============================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\", transform=transform)\n",
    "\n",
    "class_names = train_data.classes\n",
    "\n",
    "# ==============================\n",
    "# EXPERIMENTOS\n",
    "# ==============================\n",
    "experiments = [\n",
    "    {\"optimizer\": \"SGD\", \"lr\": 0.001, \"batch_size\": 32, \"weight_decay\": 5e-5},  # Reducir weight_decay\n",
    "    {\"optimizer\": \"SGD\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 5e-5},\n",
    "    {\"optimizer\": \"SGD\", \"lr\": 0.001, \"batch_size\": 64, \"weight_decay\": 5e-5},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,  \"batch_size\": 32, \"weight_decay\": 5e-5},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001, \"batch_size\": 16, \"weight_decay\": 5e-5},\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# CICLO DE ENTRENAMIENTO\n",
    "# ==============================\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    try:\n",
    "        wandb.finish()  # Cerrar cualquier run previo\n",
    "    except:\n",
    "        pass\n",
    "    wandb.init(\n",
    "        project=\"esc50-lenet_stratified\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_data, batch_size=config.batch_size)\n",
    "\n",
    "    model = LeNet5(num_classes=len(train_data.classes)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)  # Reducir label smoothing\n",
    "\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # === ENTRENAMIENTO ===\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # === VALIDACIÓN ===\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        val_y_true, val_y_pred = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                \n",
    "                val_y_true.extend(labels.cpu().tolist())\n",
    "                val_y_pred.extend(preds.cpu().tolist())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        # === MÉTRICAS ADICIONALES ===\n",
    "        prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"macro\", zero_division=0\n",
    "        )\n",
    "        _, _, f1_w, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"weighted\", zero_division=0\n",
    "        )\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1_macro\": f1_m,\n",
    "            \"val_f1_weighted\": f1_w,\n",
    "            \"val_precision_macro\": prec_m,\n",
    "            \"val_recall_macro\": rec_m,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "            \"val_confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                y_true=val_y_true,\n",
    "                preds=val_y_pred,\n",
    "                class_names=class_names\n",
    "            )\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # === EARLY STOPPING ===\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/lenet_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > PATIENCE:\n",
    "                print(f\"[Run {i}] Early stopping triggered at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444df42",
   "metadata": {},
   "source": [
    "## Dataset Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26467187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GENERACIÓN DE DATASET AUMENTADO CON SPECAUGMENT\n",
      "============================================================\n",
      "\n",
      "Procesando TRAIN con SpecAugment:\n",
      "   • Frequency masks: 2 (máx ancho: 20)\n",
      "   • Time masks: 2 (máx ancho: 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copiando VAL (sin augmentación)...\n",
      "   300 archivos copiados\n",
      "\n",
      "Copiando TEST (sin augmentación)...\n",
      "   300 archivos copiados\n",
      "\n",
      "============================================================\n",
      "Dataset aumentado generado correctamente\n",
      "============================================================\n",
      "Ubicación: data/spectrograms2/augmented\n",
      "   - train:  CON SpecAugment\n",
      "   - val:    SIN augmentación\n",
      "   - test:   SIN augmentación\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "# ============================================================\n",
    "# SPECAUGMENT DATA GENERATOR \n",
    "# Aplica Time Warping + Frequency Masking + Time Masking\n",
    "# Solo al conjunto de TRAIN. Copia VAL y TEST sin alterar.\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = \"data/spectrograms2/base\"\n",
    "AUG_DIR  = \"data/spectrograms2/augmented\"\n",
    "\n",
    "# --- Parámetros de SpecAugment (Park et al., 2019) ---\n",
    "FREQ_MASK_PARAM = 20       # ancho máximo de bandas de frecuencia\n",
    "TIME_MASK_PARAM = 25       # ancho máximo de regiones de tiempo\n",
    "NUM_FREQ_MASKS  = 2        # cantidad de máscaras de frecuencia\n",
    "NUM_TIME_MASKS  = 2        # cantidad de máscaras de tiempo\n",
    "\n",
    "TIME_WARP_W     = 20       # parámetro de deformación temporal (warping)\n",
    "RANDOM_SEED     = 42       # reproducibilidad\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Crear carpetas base del dataset aumentado\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(AUG_DIR, split), exist_ok=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  TRANSFORMACIONES SPECAUGMENT\n",
    "# ============================================================\n",
    "\n",
    "def time_warp(spec: np.ndarray, W: int = 20) -> np.ndarray:\n",
    "    \"\"\"Aplica deformación temporal (Time Warping) al espectrograma.\"\"\"\n",
    "    if W <= 0:\n",
    "        return spec\n",
    "\n",
    "    num_rows, num_cols = spec.shape\n",
    "    if num_cols < 3:\n",
    "        return spec\n",
    "\n",
    "    center = num_cols // 2\n",
    "    warp = np.random.randint(-W, W + 1)\n",
    "    src_col = center\n",
    "    dst_col = max(W, min(num_cols - W - 1, center + warp))\n",
    "\n",
    "    src_cols = np.arange(num_cols)\n",
    "    dst_cols = np.interp(src_cols, [0, src_col, num_cols - 1],\n",
    "                         [0, dst_col, num_cols - 1])\n",
    "\n",
    "    coords = np.meshgrid(np.arange(num_rows), dst_cols, indexing='ij')\n",
    "    warped = map_coordinates(spec, coords, order=1, mode='reflect')\n",
    "    return warped\n",
    "\n",
    "\n",
    "def freq_mask(spec: np.ndarray, F: int = 20, n_masks: int = 2) -> np.ndarray:\n",
    "    \"\"\"Aplica Frequency Masking (en eje vertical del espectrograma).\"\"\"\n",
    "    for _ in range(n_masks):\n",
    "        f = random.randint(0, F)\n",
    "        if f > 0 and spec.shape[0] >= f:\n",
    "            f0 = random.randint(0, spec.shape[0] - f)\n",
    "            spec[f0:f0 + f, :] = 0\n",
    "    return spec\n",
    "\n",
    "\n",
    "def time_mask(spec: np.ndarray, T: int = 25, n_masks: int = 2) -> np.ndarray:\n",
    "    \"\"\"Aplica Time Masking (en eje horizontal del espectrograma).\"\"\"\n",
    "    for _ in range(n_masks):\n",
    "        t = random.randint(0, T)\n",
    "        if t > 0 and spec.shape[1] >= t:\n",
    "            t0 = random.randint(0, spec.shape[1] - t)\n",
    "            spec[:, t0:t0 + t] = 0\n",
    "    return spec\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  PIPELINE COMPLETO SPECAUGMENT\n",
    "# ============================================================\n",
    "def apply_specaugment(image_path: str, save_path: str):\n",
    "    \"\"\"\n",
    "    Aplica SpecAugment completo (Time Warping + Frequency Masking + Time Masking)\n",
    "    a una imagen de espectrograma en escala de grises.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"L\")\n",
    "        spec = np.array(img, dtype=np.float32)\n",
    "\n",
    "        # Aplicar transformaciones en orden\n",
    "        spec = time_warp(spec, W=TIME_WARP_W)\n",
    "        spec = freq_mask(spec, F=FREQ_MASK_PARAM, n_masks=NUM_FREQ_MASKS)\n",
    "        spec = time_mask(spec, T=TIME_MASK_PARAM, n_masks=NUM_TIME_MASKS)\n",
    "\n",
    "        # Guardar imagen resultante\n",
    "        spec = np.clip(spec, 0, 255).astype(np.uint8)\n",
    "        Image.fromarray(spec).save(save_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error procesando {image_path}: {e}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  PROCESAMIENTO DE CONJUNTO TRAIN\n",
    "# ============================================================\n",
    "def process_train_augmented():\n",
    "    \"\"\"Aplica SpecAugment únicamente al conjunto de entrenamiento.\"\"\"\n",
    "    split_name = \"train\"\n",
    "    base_split_path = os.path.join(BASE_DIR, split_name)\n",
    "    aug_split_path  = os.path.join(AUG_DIR, split_name)\n",
    "\n",
    "    print(\"\\nProcesando TRAIN con SpecAugment:\")\n",
    "    print(f\"   • Frequency masks: {NUM_FREQ_MASKS} (máx ancho: {FREQ_MASK_PARAM})\")\n",
    "    print(f\"   • Time masks: {NUM_TIME_MASKS} (máx ancho: {TIME_MASK_PARAM})\")\n",
    "\n",
    "    for class_name in os.listdir(base_split_path):\n",
    "        class_base_path = os.path.join(base_split_path, class_name)\n",
    "        if not os.path.isdir(class_base_path):\n",
    "            continue\n",
    "\n",
    "        class_aug_path = os.path.join(aug_split_path, class_name)\n",
    "        os.makedirs(class_aug_path, exist_ok=True)\n",
    "\n",
    "        images = [f for f in os.listdir(class_base_path) if f.endswith(\".png\")]\n",
    "\n",
    "        for img_file in tqdm(images, desc=f\"train/{class_name}\", leave=False):\n",
    "            src_path = os.path.join(class_base_path, img_file)\n",
    "            dst_path = os.path.join(class_aug_path, img_file)\n",
    "            apply_specaugment(src_path, dst_path)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  COPIA LIMPIA DE VAL Y TEST\n",
    "# ============================================================\n",
    "def copy_val_test_clean():\n",
    "    \"\"\"Copia val y test desde base a augmented SIN aplicar augmentación.\"\"\"\n",
    "    for split in [\"val\", \"test\"]:\n",
    "        src_dir = os.path.join(BASE_DIR, split)\n",
    "        dst_dir = os.path.join(AUG_DIR, split)\n",
    "\n",
    "        print(f\"\\nCopiando {split.upper()} (sin augmentación)...\")\n",
    "\n",
    "        if os.path.exists(dst_dir):\n",
    "            shutil.rmtree(dst_dir)\n",
    "\n",
    "        shutil.copytree(src_dir, dst_dir)\n",
    "\n",
    "        total_files = sum(len(files) for _, _, files in os.walk(dst_dir))\n",
    "        print(f\"   {total_files} archivos copiados\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  EJECUCIÓN PRINCIPAL\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GENERACIÓN DE DATASET AUMENTADO CON SPECAUGMENT\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 1. Aplicar SpecAugment SOLO a train\n",
    "    process_train_augmented()\n",
    "\n",
    "    # 2. Copiar val y test sin modificar\n",
    "    copy_val_test_clean()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Dataset aumentado generado correctamente\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Ubicación: {AUG_DIR}\")\n",
    "    print(f\"   - train:  CON SpecAugment\")\n",
    "    print(f\"   - val:    SIN augmentación\")\n",
    "    print(f\"   - test:   SIN augmentación\")\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637852f",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Augmented Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ad64dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_201021-6yey3cen</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/6yey3cen' target=\"_blank\">run_1_opt-Adam_lr-0.001_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/6yey3cen' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/6yey3cen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamaño calculado para FC: 43264\n",
      "[Run 1] Epoch 1/40 | Train Acc: 0.038 | Val Acc: 0.063 | Train Loss: 4.3361 | Val Loss: 3.8046\n",
      "[Run 1] Epoch 2/40 | Train Acc: 0.049 | Val Acc: 0.073 | Train Loss: 4.1031 | Val Loss: 3.7396\n",
      "[Run 1] Epoch 3/40 | Train Acc: 0.059 | Val Acc: 0.073 | Train Loss: 4.0263 | Val Loss: 3.7029\n",
      "[Run 1] Epoch 4/40 | Train Acc: 0.063 | Val Acc: 0.100 | Train Loss: 3.9503 | Val Loss: 3.6340\n",
      "[Run 1] Epoch 5/40 | Train Acc: 0.071 | Val Acc: 0.090 | Train Loss: 3.9216 | Val Loss: 3.6088\n",
      "[Run 1] Epoch 6/40 | Train Acc: 0.074 | Val Acc: 0.110 | Train Loss: 3.8430 | Val Loss: 3.6301\n",
      "[Run 1] Epoch 7/40 | Train Acc: 0.081 | Val Acc: 0.127 | Train Loss: 3.8011 | Val Loss: 3.6149\n",
      "[Run 1] Epoch 8/40 | Train Acc: 0.074 | Val Acc: 0.140 | Train Loss: 3.8095 | Val Loss: 3.6693\n",
      "[Run 1] Epoch 9/40 | Train Acc: 0.104 | Val Acc: 0.147 | Train Loss: 3.7178 | Val Loss: 3.5368\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.094 | Val Acc: 0.117 | Train Loss: 3.6442 | Val Loss: 3.6160\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.109 | Val Acc: 0.157 | Train Loss: 3.6185 | Val Loss: 3.4620\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.111 | Val Acc: 0.123 | Train Loss: 3.5505 | Val Loss: 3.4620\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.123 | Val Acc: 0.173 | Train Loss: 3.5242 | Val Loss: 3.3561\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.130 | Val Acc: 0.130 | Train Loss: 3.5323 | Val Loss: 3.4639\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.133 | Val Acc: 0.173 | Train Loss: 3.4272 | Val Loss: 3.4166\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.144 | Val Acc: 0.180 | Train Loss: 3.4177 | Val Loss: 3.3404\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.150 | Val Acc: 0.173 | Train Loss: 3.3852 | Val Loss: 3.3370\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.136 | Val Acc: 0.163 | Train Loss: 3.3832 | Val Loss: 3.4187\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.160 | Val Acc: 0.190 | Train Loss: 3.3449 | Val Loss: 3.3467\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.143 | Val Acc: 0.173 | Train Loss: 3.3493 | Val Loss: 3.3363\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.169 | Val Acc: 0.177 | Train Loss: 3.2720 | Val Loss: 3.2700\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.181 | Val Acc: 0.230 | Train Loss: 3.2462 | Val Loss: 3.2476\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.174 | Val Acc: 0.200 | Train Loss: 3.2092 | Val Loss: 3.2424\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.171 | Val Acc: 0.233 | Train Loss: 3.2421 | Val Loss: 3.1839\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.181 | Val Acc: 0.200 | Train Loss: 3.1988 | Val Loss: 3.2313\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.192 | Val Acc: 0.200 | Train Loss: 3.1808 | Val Loss: 3.2556\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.184 | Val Acc: 0.187 | Train Loss: 3.1835 | Val Loss: 3.3596\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.180 | Val Acc: 0.207 | Train Loss: 3.1336 | Val Loss: 3.2245\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.196 | Val Acc: 0.213 | Train Loss: 3.1361 | Val Loss: 3.2181\n",
      "[Run 1] Epoch 30/40 | Train Acc: 0.204 | Val Acc: 0.213 | Train Loss: 3.0807 | Val Loss: 3.2745\n",
      "[Run 1] Epoch 31/40 | Train Acc: 0.232 | Val Acc: 0.203 | Train Loss: 3.0479 | Val Loss: 3.2129\n",
      "[Run 1] Early stopping triggered at epoch 31.\n",
      "✅ [Run 1] Mejor Val Acc: 0.233\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>█████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▂▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▆▆▇▇█</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▃▂▃▄▄▄▃▅▃▆▄▆▆▆▅▆▆▆█▇█▇▇▆▇▇▇▇</td></tr><tr><td>val_f1_macro</td><td>▁▁▂▂▂▂▄▄▄▃▅▄▅▄▅▆▆▅▆▆▆█▇▇▇▇▆▇▇▇▇</td></tr><tr><td>val_f1_weighted</td><td>▁▁▂▂▂▂▄▄▄▃▅▄▅▄▅▆▆▅▆▆▆█▇▇▇▇▆▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▆▆▆▅▆▄▄▃▄▄▃▃▄▃▃▂▂▂▁▂▂▃▁▁▂▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▂▃▂▂▄▅▅▄▄▄▅▃▅▆▆▅▆▆▅█▇▇▇▇▅▆▆█▇</td></tr><tr><td>val_recall_macro</td><td>▁▁▁▃▂▃▄▄▄▃▅▃▆▄▆▆▆▅▆▆▆█▇█▇▇▆▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.23333</td></tr><tr><td>epoch</td><td>31</td></tr><tr><td>lr</td><td>0.00013</td></tr><tr><td>train_acc</td><td>0.23214</td></tr><tr><td>train_loss</td><td>3.04795</td></tr><tr><td>val_acc</td><td>0.20333</td></tr><tr><td>val_f1_macro</td><td>0.18072</td></tr><tr><td>val_f1_weighted</td><td>0.18072</td></tr><tr><td>val_loss</td><td>3.21286</td></tr><tr><td>val_precision_macro</td><td>0.21507</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-Adam_lr-0.001_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/6yey3cen' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/6yey3cen</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified</a><br>Synced 5 W&B file(s), 31 media file(s), 62 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_201021-6yey3cen/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_201453-25s8e0cr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/25s8e0cr' target=\"_blank\">run_2_opt-Adam_lr-0.0005_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/25s8e0cr' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/25s8e0cr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamaño calculado para FC: 43264\n",
      "[Run 2] Epoch 1/40 | Train Acc: 0.032 | Val Acc: 0.090 | Train Loss: 4.3643 | Val Loss: 3.7036\n",
      "[Run 2] Epoch 1/40 | Train Acc: 0.032 | Val Acc: 0.090 | Train Loss: 4.3643 | Val Loss: 3.7036\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.046 | Val Acc: 0.083 | Train Loss: 4.1346 | Val Loss: 3.7164\n",
      "[Run 2] Epoch 2/40 | Train Acc: 0.046 | Val Acc: 0.083 | Train Loss: 4.1346 | Val Loss: 3.7164\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.063 | Val Acc: 0.097 | Train Loss: 4.0402 | Val Loss: 3.6545\n",
      "[Run 2] Epoch 3/40 | Train Acc: 0.063 | Val Acc: 0.097 | Train Loss: 4.0402 | Val Loss: 3.6545\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.063 | Val Acc: 0.113 | Train Loss: 3.9724 | Val Loss: 3.6718\n",
      "[Run 2] Epoch 4/40 | Train Acc: 0.063 | Val Acc: 0.113 | Train Loss: 3.9724 | Val Loss: 3.6718\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.054 | Val Acc: 0.120 | Train Loss: 3.9768 | Val Loss: 3.5606\n",
      "[Run 2] Epoch 5/40 | Train Acc: 0.054 | Val Acc: 0.120 | Train Loss: 3.9768 | Val Loss: 3.5606\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.068 | Val Acc: 0.123 | Train Loss: 3.8662 | Val Loss: 3.6305\n",
      "[Run 2] Epoch 6/40 | Train Acc: 0.068 | Val Acc: 0.123 | Train Loss: 3.8662 | Val Loss: 3.6305\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.082 | Val Acc: 0.117 | Train Loss: 3.7940 | Val Loss: 3.6585\n",
      "[Run 2] Epoch 7/40 | Train Acc: 0.082 | Val Acc: 0.117 | Train Loss: 3.7940 | Val Loss: 3.6585\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.079 | Val Acc: 0.093 | Train Loss: 3.9231 | Val Loss: 3.6295\n",
      "[Run 2] Epoch 8/40 | Train Acc: 0.079 | Val Acc: 0.093 | Train Loss: 3.9231 | Val Loss: 3.6295\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.069 | Val Acc: 0.117 | Train Loss: 3.8926 | Val Loss: 3.5741\n",
      "[Run 2] Epoch 9/40 | Train Acc: 0.069 | Val Acc: 0.117 | Train Loss: 3.8926 | Val Loss: 3.5741\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.094 | Val Acc: 0.100 | Train Loss: 3.7670 | Val Loss: 3.6141\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.094 | Val Acc: 0.100 | Train Loss: 3.7670 | Val Loss: 3.6141\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.094 | Val Acc: 0.140 | Train Loss: 3.7255 | Val Loss: 3.4907\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.094 | Val Acc: 0.140 | Train Loss: 3.7255 | Val Loss: 3.4907\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.104 | Val Acc: 0.113 | Train Loss: 3.6218 | Val Loss: 3.4838\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.104 | Val Acc: 0.113 | Train Loss: 3.6218 | Val Loss: 3.4838\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.104 | Val Acc: 0.163 | Train Loss: 3.6327 | Val Loss: 3.4250\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.104 | Val Acc: 0.163 | Train Loss: 3.6327 | Val Loss: 3.4250\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.116 | Val Acc: 0.153 | Train Loss: 3.5761 | Val Loss: 3.4481\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.116 | Val Acc: 0.153 | Train Loss: 3.5761 | Val Loss: 3.4481\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.134 | Val Acc: 0.137 | Train Loss: 3.5131 | Val Loss: 3.4502\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.134 | Val Acc: 0.137 | Train Loss: 3.5131 | Val Loss: 3.4502\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.116 | Val Acc: 0.133 | Train Loss: 3.5185 | Val Loss: 3.4232\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.116 | Val Acc: 0.133 | Train Loss: 3.5185 | Val Loss: 3.4232\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.115 | Val Acc: 0.177 | Train Loss: 3.5351 | Val Loss: 3.3581\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.115 | Val Acc: 0.177 | Train Loss: 3.5351 | Val Loss: 3.3581\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.144 | Val Acc: 0.200 | Train Loss: 3.4231 | Val Loss: 3.4306\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.144 | Val Acc: 0.200 | Train Loss: 3.4231 | Val Loss: 3.4306\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.139 | Val Acc: 0.197 | Train Loss: 3.4201 | Val Loss: 3.4053\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.139 | Val Acc: 0.197 | Train Loss: 3.4201 | Val Loss: 3.4053\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.146 | Val Acc: 0.200 | Train Loss: 3.4476 | Val Loss: 3.3364\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.146 | Val Acc: 0.200 | Train Loss: 3.4476 | Val Loss: 3.3364\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.158 | Val Acc: 0.193 | Train Loss: 3.3477 | Val Loss: 3.3137\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.158 | Val Acc: 0.193 | Train Loss: 3.3477 | Val Loss: 3.3137\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.185 | Val Acc: 0.197 | Train Loss: 3.2924 | Val Loss: 3.3610\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.185 | Val Acc: 0.197 | Train Loss: 3.2924 | Val Loss: 3.3610\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.162 | Val Acc: 0.193 | Train Loss: 3.3205 | Val Loss: 3.3069\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.162 | Val Acc: 0.193 | Train Loss: 3.3205 | Val Loss: 3.3069\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.192 | Val Acc: 0.177 | Train Loss: 3.2080 | Val Loss: 3.3326\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.192 | Val Acc: 0.177 | Train Loss: 3.2080 | Val Loss: 3.3326\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.177 | Val Acc: 0.213 | Train Loss: 3.2261 | Val Loss: 3.2481\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.177 | Val Acc: 0.213 | Train Loss: 3.2261 | Val Loss: 3.2481\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.179 | Val Acc: 0.193 | Train Loss: 3.2752 | Val Loss: 3.2886\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.179 | Val Acc: 0.193 | Train Loss: 3.2752 | Val Loss: 3.2886\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.186 | Val Acc: 0.197 | Train Loss: 3.2551 | Val Loss: 3.2717\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.186 | Val Acc: 0.197 | Train Loss: 3.2551 | Val Loss: 3.2717\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.195 | Val Acc: 0.220 | Train Loss: 3.1857 | Val Loss: 3.2648\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.195 | Val Acc: 0.220 | Train Loss: 3.1857 | Val Loss: 3.2648\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.184 | Val Acc: 0.223 | Train Loss: 3.2048 | Val Loss: 3.2686\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.184 | Val Acc: 0.223 | Train Loss: 3.2048 | Val Loss: 3.2686\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.213 | Val Acc: 0.213 | Train Loss: 3.1745 | Val Loss: 3.3109\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.213 | Val Acc: 0.213 | Train Loss: 3.1745 | Val Loss: 3.3109\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.195 | Val Acc: 0.193 | Train Loss: 3.1693 | Val Loss: 3.3080\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.195 | Val Acc: 0.193 | Train Loss: 3.1693 | Val Loss: 3.3080\n",
      "[Run 2] Epoch 32/40 | Train Acc: 0.221 | Val Acc: 0.210 | Train Loss: 3.1332 | Val Loss: 3.2656\n",
      "[Run 2] Epoch 32/40 | Train Acc: 0.221 | Val Acc: 0.210 | Train Loss: 3.1332 | Val Loss: 3.2656\n",
      "[Run 2] Epoch 33/40 | Train Acc: 0.209 | Val Acc: 0.213 | Train Loss: 3.1164 | Val Loss: 3.2873\n",
      "[Run 2] Epoch 33/40 | Train Acc: 0.209 | Val Acc: 0.213 | Train Loss: 3.1164 | Val Loss: 3.2873\n",
      "[Run 2] Epoch 34/40 | Train Acc: 0.234 | Val Acc: 0.187 | Train Loss: 3.1002 | Val Loss: 3.2986\n",
      "[Run 2] Epoch 34/40 | Train Acc: 0.234 | Val Acc: 0.187 | Train Loss: 3.1002 | Val Loss: 3.2986\n",
      "[Run 2] Epoch 35/40 | Train Acc: 0.238 | Val Acc: 0.203 | Train Loss: 3.0499 | Val Loss: 3.2825\n",
      "[Run 2] Epoch 35/40 | Train Acc: 0.238 | Val Acc: 0.203 | Train Loss: 3.0499 | Val Loss: 3.2825\n",
      "[Run 2] Epoch 36/40 | Train Acc: 0.230 | Val Acc: 0.203 | Train Loss: 3.0662 | Val Loss: 3.2477\n",
      "[Run 2] Early stopping triggered at epoch 36.\n",
      "✅ [Run 2] Mejor Val Acc: 0.223\n",
      "[Run 2] Epoch 36/40 | Train Acc: 0.230 | Val Acc: 0.203 | Train Loss: 3.0662 | Val Loss: 3.2477\n",
      "[Run 2] Early stopping triggered at epoch 36.\n",
      "✅ [Run 2] Mejor Val Acc: 0.223\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>█████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▂▃▃▂▃▃▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▇▆▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▆▅▅▅▄▄▄▃▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▃▃▁▃▂▄▃▅▅▄▄▆▇▇▇▆▇▆▆█▆▇███▆▇█▆▇▇</td></tr><tr><td>val_f1_macro</td><td>▂▁▂▂▃▄▃▁▃▂▄▃▅▅▄▃▆▇▇▇▆▇▇▅▇▇▇██▇▇▇█▆▇▇</td></tr><tr><td>val_f1_weighted</td><td>▂▁▂▂▃▄▃▁▃▂▄▃▅▅▄▃▆▇▇▇▆▇▇▅▇▇▇██▇▇▇█▆▇▇</td></tr><tr><td>val_loss</td><td>██▇▇▆▇▇▇▆▆▅▅▄▄▄▄▃▄▃▂▂▃▂▂▁▂▁▁▁▂▂▁▂▂▂▁</td></tr><tr><td>val_precision_macro</td><td>▃▁▂▂▃▄▂▁▄▂▄▁▅▃▄▂▅█▇▇▆█▇▄▇▆▇▆▇▇▇▆█▇▆▆</td></tr><tr><td>val_recall_macro</td><td>▁▁▂▃▃▃▃▁▃▂▄▃▅▅▄▄▆▇▇▇▆▇▆▆█▆▇███▆▇█▆▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.22333</td></tr><tr><td>epoch</td><td>36</td></tr><tr><td>lr</td><td>6e-05</td></tr><tr><td>train_acc</td><td>0.23</td></tr><tr><td>train_loss</td><td>3.06625</td></tr><tr><td>val_acc</td><td>0.20333</td></tr><tr><td>val_f1_macro</td><td>0.15689</td></tr><tr><td>val_f1_weighted</td><td>0.15689</td></tr><tr><td>val_loss</td><td>3.24769</td></tr><tr><td>val_precision_macro</td><td>0.14931</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-Adam_lr-0.0005_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/25s8e0cr' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/25s8e0cr</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified</a><br>Synced 5 W&B file(s), 36 media file(s), 72 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_201453-25s8e0cr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_201950-4avlzcug</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/4avlzcug' target=\"_blank\">run_3_opt-Adam_lr-0.001_bs-64</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/4avlzcug' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/4avlzcug</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamaño calculado para FC: 43264\n",
      "[Run 3] Epoch 1/40 | Train Acc: 0.029 | Val Acc: 0.057 | Train Loss: 4.3466 | Val Loss: 3.6992\n",
      "[Run 3] Epoch 1/40 | Train Acc: 0.029 | Val Acc: 0.057 | Train Loss: 4.3466 | Val Loss: 3.6992\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.056 | Val Acc: 0.097 | Train Loss: 4.0989 | Val Loss: 3.6666\n",
      "[Run 3] Epoch 2/40 | Train Acc: 0.056 | Val Acc: 0.097 | Train Loss: 4.0989 | Val Loss: 3.6666\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.062 | Val Acc: 0.103 | Train Loss: 3.9684 | Val Loss: 3.6041\n",
      "[Run 3] Epoch 3/40 | Train Acc: 0.062 | Val Acc: 0.103 | Train Loss: 3.9684 | Val Loss: 3.6041\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.074 | Val Acc: 0.080 | Train Loss: 3.9314 | Val Loss: 3.6383\n",
      "[Run 3] Epoch 4/40 | Train Acc: 0.074 | Val Acc: 0.080 | Train Loss: 3.9314 | Val Loss: 3.6383\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.064 | Val Acc: 0.110 | Train Loss: 3.9128 | Val Loss: 3.5940\n",
      "[Run 3] Epoch 5/40 | Train Acc: 0.064 | Val Acc: 0.110 | Train Loss: 3.9128 | Val Loss: 3.5940\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.081 | Val Acc: 0.097 | Train Loss: 3.8492 | Val Loss: 3.6099\n",
      "[Run 3] Epoch 6/40 | Train Acc: 0.081 | Val Acc: 0.097 | Train Loss: 3.8492 | Val Loss: 3.6099\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.073 | Val Acc: 0.127 | Train Loss: 3.8263 | Val Loss: 3.6087\n",
      "[Run 3] Epoch 7/40 | Train Acc: 0.073 | Val Acc: 0.127 | Train Loss: 3.8263 | Val Loss: 3.6087\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.080 | Val Acc: 0.067 | Train Loss: 3.8162 | Val Loss: 3.8680\n",
      "[Run 3] Epoch 8/40 | Train Acc: 0.080 | Val Acc: 0.067 | Train Loss: 3.8162 | Val Loss: 3.8680\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.071 | Val Acc: 0.123 | Train Loss: 3.8371 | Val Loss: 3.5417\n",
      "[Run 3] Epoch 9/40 | Train Acc: 0.071 | Val Acc: 0.123 | Train Loss: 3.8371 | Val Loss: 3.5417\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.095 | Val Acc: 0.103 | Train Loss: 3.7539 | Val Loss: 3.5075\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.095 | Val Acc: 0.103 | Train Loss: 3.7539 | Val Loss: 3.5075\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.099 | Val Acc: 0.117 | Train Loss: 3.6859 | Val Loss: 3.4409\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.099 | Val Acc: 0.117 | Train Loss: 3.6859 | Val Loss: 3.4409\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.100 | Val Acc: 0.150 | Train Loss: 3.6303 | Val Loss: 3.3257\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.100 | Val Acc: 0.150 | Train Loss: 3.6303 | Val Loss: 3.3257\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.116 | Val Acc: 0.173 | Train Loss: 3.5650 | Val Loss: 3.3442\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.116 | Val Acc: 0.173 | Train Loss: 3.5650 | Val Loss: 3.3442\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.122 | Val Acc: 0.143 | Train Loss: 3.5353 | Val Loss: 3.3739\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.122 | Val Acc: 0.143 | Train Loss: 3.5353 | Val Loss: 3.3739\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.109 | Val Acc: 0.180 | Train Loss: 3.5222 | Val Loss: 3.3347\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.109 | Val Acc: 0.180 | Train Loss: 3.5222 | Val Loss: 3.3347\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.139 | Val Acc: 0.160 | Train Loss: 3.4822 | Val Loss: 3.4040\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.139 | Val Acc: 0.160 | Train Loss: 3.4822 | Val Loss: 3.4040\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.132 | Val Acc: 0.133 | Train Loss: 3.4521 | Val Loss: 3.3851\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.132 | Val Acc: 0.133 | Train Loss: 3.4521 | Val Loss: 3.3851\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.130 | Val Acc: 0.147 | Train Loss: 3.4281 | Val Loss: 3.3803\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.130 | Val Acc: 0.147 | Train Loss: 3.4281 | Val Loss: 3.3803\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.138 | Val Acc: 0.150 | Train Loss: 3.4048 | Val Loss: 3.4532\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.138 | Val Acc: 0.150 | Train Loss: 3.4048 | Val Loss: 3.4532\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.164 | Val Acc: 0.133 | Train Loss: 3.3411 | Val Loss: 3.5889\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.164 | Val Acc: 0.133 | Train Loss: 3.3411 | Val Loss: 3.5889\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.149 | Val Acc: 0.183 | Train Loss: 3.3168 | Val Loss: 3.3064\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.149 | Val Acc: 0.183 | Train Loss: 3.3168 | Val Loss: 3.3064\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.169 | Val Acc: 0.227 | Train Loss: 3.2825 | Val Loss: 3.1843\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.169 | Val Acc: 0.227 | Train Loss: 3.2825 | Val Loss: 3.1843\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.162 | Val Acc: 0.197 | Train Loss: 3.3013 | Val Loss: 3.2840\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.162 | Val Acc: 0.197 | Train Loss: 3.3013 | Val Loss: 3.2840\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.183 | Val Acc: 0.203 | Train Loss: 3.2363 | Val Loss: 3.2751\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.183 | Val Acc: 0.203 | Train Loss: 3.2363 | Val Loss: 3.2751\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.163 | Val Acc: 0.197 | Train Loss: 3.2552 | Val Loss: 3.2603\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.163 | Val Acc: 0.197 | Train Loss: 3.2552 | Val Loss: 3.2603\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.195 | Val Acc: 0.220 | Train Loss: 3.1998 | Val Loss: 3.1817\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.195 | Val Acc: 0.220 | Train Loss: 3.1998 | Val Loss: 3.1817\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.181 | Val Acc: 0.180 | Train Loss: 3.2078 | Val Loss: 3.2824\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.181 | Val Acc: 0.180 | Train Loss: 3.2078 | Val Loss: 3.2824\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.167 | Val Acc: 0.200 | Train Loss: 3.2284 | Val Loss: 3.2425\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.167 | Val Acc: 0.200 | Train Loss: 3.2284 | Val Loss: 3.2425\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.202 | Val Acc: 0.217 | Train Loss: 3.1549 | Val Loss: 3.1670\n",
      "[Run 3] Early stopping triggered at epoch 29.\n",
      "✅ [Run 3] Mejor Val Acc: 0.227\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.202 | Val Acc: 0.217 | Train Loss: 3.1549 | Val Loss: 3.1670\n",
      "[Run 3] Early stopping triggered at epoch 29.\n",
      "✅ [Run 3] Mejor Val Acc: 0.227\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>█████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▂▃▃▃▃▄▄▄▅▅▄▅▅▅▅▆▆▇▆▇▆█▇▇█</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▁▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▃▂▃▃▄▁▄▃▃▅▆▅▆▅▄▅▅▄▆█▇▇▇█▆▇█</td></tr><tr><td>val_f1_macro</td><td>▁▂▃▃▃▃▄▂▃▃▄▅▆▅▆▅▅▅▆▄▆▇▇▇▇█▆▇▇</td></tr><tr><td>val_f1_weighted</td><td>▁▂▃▃▃▃▄▂▃▃▄▅▆▅▆▅▅▅▆▄▆▇▇▇▇█▆▇▇</td></tr><tr><td>val_loss</td><td>▆▆▅▆▅▅▅█▅▄▄▃▃▃▃▃▃▃▄▅▂▁▂▂▂▁▂▂▁</td></tr><tr><td>val_precision_macro</td><td>▁▂▂▄▃▄▄▂▄▄▃▅▆▅▆▅▄▄▇▅▆▆▆▇▇█▆▆▆</td></tr><tr><td>val_recall_macro</td><td>▁▃▃▂▃▃▄▁▄▃▃▅▆▅▆▅▄▅▅▄▆█▇▇▇█▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.22667</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>lr</td><td>0.00025</td></tr><tr><td>train_acc</td><td>0.20214</td></tr><tr><td>train_loss</td><td>3.15493</td></tr><tr><td>val_acc</td><td>0.21667</td></tr><tr><td>val_f1_macro</td><td>0.17167</td></tr><tr><td>val_f1_weighted</td><td>0.17167</td></tr><tr><td>val_loss</td><td>3.16702</td></tr><tr><td>val_precision_macro</td><td>0.16638</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-Adam_lr-0.001_bs-64</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/4avlzcug' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/4avlzcug</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified</a><br>Synced 5 W&B file(s), 29 media file(s), 58 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_201950-4avlzcug/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_202332-e7lsx0mk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/e7lsx0mk' target=\"_blank\">run_4_opt-AdamW_lr-0.001_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/e7lsx0mk' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/e7lsx0mk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamaño calculado para FC: 43264\n",
      "[Run 4] Epoch 1/40 | Train Acc: 0.040 | Val Acc: 0.087 | Train Loss: 4.3782 | Val Loss: 3.7742\n",
      "[Run 4] Epoch 1/40 | Train Acc: 0.040 | Val Acc: 0.087 | Train Loss: 4.3782 | Val Loss: 3.7742\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.053 | Val Acc: 0.087 | Train Loss: 4.1743 | Val Loss: 3.6625\n",
      "[Run 4] Epoch 2/40 | Train Acc: 0.053 | Val Acc: 0.087 | Train Loss: 4.1743 | Val Loss: 3.6625\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.048 | Val Acc: 0.087 | Train Loss: 4.0762 | Val Loss: 3.7167\n",
      "[Run 4] Epoch 3/40 | Train Acc: 0.048 | Val Acc: 0.087 | Train Loss: 4.0762 | Val Loss: 3.7167\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.049 | Val Acc: 0.107 | Train Loss: 4.0676 | Val Loss: 3.6522\n",
      "[Run 4] Epoch 4/40 | Train Acc: 0.049 | Val Acc: 0.107 | Train Loss: 4.0676 | Val Loss: 3.6522\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.060 | Val Acc: 0.090 | Train Loss: 3.9760 | Val Loss: 3.7255\n",
      "[Run 4] Epoch 5/40 | Train Acc: 0.060 | Val Acc: 0.090 | Train Loss: 3.9760 | Val Loss: 3.7255\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.074 | Val Acc: 0.030 | Train Loss: 3.9043 | Val Loss: 4.1370\n",
      "[Run 4] Epoch 6/40 | Train Acc: 0.074 | Val Acc: 0.030 | Train Loss: 3.9043 | Val Loss: 4.1370\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.076 | Val Acc: 0.107 | Train Loss: 3.8477 | Val Loss: 3.5423\n",
      "[Run 4] Epoch 7/40 | Train Acc: 0.076 | Val Acc: 0.107 | Train Loss: 3.8477 | Val Loss: 3.5423\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.082 | Val Acc: 0.123 | Train Loss: 3.7644 | Val Loss: 3.5752\n",
      "[Run 4] Epoch 8/40 | Train Acc: 0.082 | Val Acc: 0.123 | Train Loss: 3.7644 | Val Loss: 3.5752\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.080 | Val Acc: 0.147 | Train Loss: 3.7797 | Val Loss: 3.4362\n",
      "[Run 4] Epoch 9/40 | Train Acc: 0.080 | Val Acc: 0.147 | Train Loss: 3.7797 | Val Loss: 3.4362\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.084 | Val Acc: 0.130 | Train Loss: 3.6932 | Val Loss: 3.4631\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.084 | Val Acc: 0.130 | Train Loss: 3.6932 | Val Loss: 3.4631\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.110 | Val Acc: 0.087 | Train Loss: 3.6353 | Val Loss: 3.8490\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.110 | Val Acc: 0.087 | Train Loss: 3.6353 | Val Loss: 3.8490\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.092 | Val Acc: 0.103 | Train Loss: 3.6254 | Val Loss: 3.5426\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.092 | Val Acc: 0.103 | Train Loss: 3.6254 | Val Loss: 3.5426\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.104 | Val Acc: 0.163 | Train Loss: 3.5820 | Val Loss: 3.3826\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.104 | Val Acc: 0.163 | Train Loss: 3.5820 | Val Loss: 3.3826\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.108 | Val Acc: 0.163 | Train Loss: 3.5336 | Val Loss: 3.3860\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.108 | Val Acc: 0.163 | Train Loss: 3.5336 | Val Loss: 3.3860\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.122 | Val Acc: 0.157 | Train Loss: 3.4913 | Val Loss: 3.3719\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.122 | Val Acc: 0.157 | Train Loss: 3.4913 | Val Loss: 3.3719\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.126 | Val Acc: 0.133 | Train Loss: 3.5177 | Val Loss: 3.4520\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.126 | Val Acc: 0.133 | Train Loss: 3.5177 | Val Loss: 3.4520\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.136 | Val Acc: 0.180 | Train Loss: 3.4706 | Val Loss: 3.3359\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.136 | Val Acc: 0.180 | Train Loss: 3.4706 | Val Loss: 3.3359\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.126 | Val Acc: 0.183 | Train Loss: 3.4378 | Val Loss: 3.3024\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.126 | Val Acc: 0.183 | Train Loss: 3.4378 | Val Loss: 3.3024\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.126 | Val Acc: 0.180 | Train Loss: 3.4572 | Val Loss: 3.3285\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.126 | Val Acc: 0.180 | Train Loss: 3.4572 | Val Loss: 3.3285\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.151 | Val Acc: 0.113 | Train Loss: 3.3898 | Val Loss: 3.6052\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.151 | Val Acc: 0.113 | Train Loss: 3.3898 | Val Loss: 3.6052\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.149 | Val Acc: 0.167 | Train Loss: 3.3408 | Val Loss: 3.4135\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.149 | Val Acc: 0.167 | Train Loss: 3.3408 | Val Loss: 3.4135\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.149 | Val Acc: 0.203 | Train Loss: 3.3084 | Val Loss: 3.3206\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.149 | Val Acc: 0.203 | Train Loss: 3.3084 | Val Loss: 3.3206\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.155 | Val Acc: 0.177 | Train Loss: 3.3188 | Val Loss: 3.3697\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.155 | Val Acc: 0.177 | Train Loss: 3.3188 | Val Loss: 3.3697\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.175 | Val Acc: 0.197 | Train Loss: 3.2431 | Val Loss: 3.2599\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.175 | Val Acc: 0.197 | Train Loss: 3.2431 | Val Loss: 3.2599\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.171 | Val Acc: 0.213 | Train Loss: 3.2515 | Val Loss: 3.2431\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.171 | Val Acc: 0.213 | Train Loss: 3.2515 | Val Loss: 3.2431\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.175 | Val Acc: 0.203 | Train Loss: 3.2166 | Val Loss: 3.1969\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.175 | Val Acc: 0.203 | Train Loss: 3.2166 | Val Loss: 3.1969\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.181 | Val Acc: 0.187 | Train Loss: 3.2003 | Val Loss: 3.2533\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.181 | Val Acc: 0.187 | Train Loss: 3.2003 | Val Loss: 3.2533\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.171 | Val Acc: 0.210 | Train Loss: 3.2487 | Val Loss: 3.2836\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.171 | Val Acc: 0.210 | Train Loss: 3.2487 | Val Loss: 3.2836\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.162 | Val Acc: 0.227 | Train Loss: 3.2316 | Val Loss: 3.1881\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.162 | Val Acc: 0.227 | Train Loss: 3.2316 | Val Loss: 3.1881\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.213 | Val Acc: 0.233 | Train Loss: 3.1300 | Val Loss: 3.1615\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.213 | Val Acc: 0.233 | Train Loss: 3.1300 | Val Loss: 3.1615\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.214 | Val Acc: 0.220 | Train Loss: 3.1035 | Val Loss: 3.1625\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.214 | Val Acc: 0.220 | Train Loss: 3.1035 | Val Loss: 3.1625\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.218 | Val Acc: 0.237 | Train Loss: 3.0879 | Val Loss: 3.1516\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.218 | Val Acc: 0.237 | Train Loss: 3.0879 | Val Loss: 3.1516\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.189 | Val Acc: 0.203 | Train Loss: 3.1400 | Val Loss: 3.2494\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.189 | Val Acc: 0.203 | Train Loss: 3.1400 | Val Loss: 3.2494\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.218 | Val Acc: 0.227 | Train Loss: 3.0758 | Val Loss: 3.1654\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.218 | Val Acc: 0.227 | Train Loss: 3.0758 | Val Loss: 3.1654\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.196 | Val Acc: 0.220 | Train Loss: 3.1040 | Val Loss: 3.1194\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.196 | Val Acc: 0.220 | Train Loss: 3.1040 | Val Loss: 3.1194\n",
      "[Run 4] Epoch 36/40 | Train Acc: 0.216 | Val Acc: 0.243 | Train Loss: 3.0471 | Val Loss: 3.1637\n",
      "[Run 4] Epoch 36/40 | Train Acc: 0.216 | Val Acc: 0.243 | Train Loss: 3.0471 | Val Loss: 3.1637\n",
      "[Run 4] Epoch 37/40 | Train Acc: 0.235 | Val Acc: 0.253 | Train Loss: 3.0011 | Val Loss: 3.1114\n",
      "[Run 4] Epoch 37/40 | Train Acc: 0.235 | Val Acc: 0.253 | Train Loss: 3.0011 | Val Loss: 3.1114\n",
      "[Run 4] Epoch 38/40 | Train Acc: 0.239 | Val Acc: 0.243 | Train Loss: 3.0056 | Val Loss: 3.1354\n",
      "[Run 4] Epoch 38/40 | Train Acc: 0.239 | Val Acc: 0.243 | Train Loss: 3.0056 | Val Loss: 3.1354\n",
      "[Run 4] Epoch 39/40 | Train Acc: 0.246 | Val Acc: 0.240 | Train Loss: 3.0325 | Val Loss: 3.1379\n",
      "[Run 4] Epoch 39/40 | Train Acc: 0.246 | Val Acc: 0.240 | Train Loss: 3.0325 | Val Loss: 3.1379\n",
      "[Run 4] Epoch 40/40 | Train Acc: 0.213 | Val Acc: 0.240 | Train Loss: 3.0068 | Val Loss: 3.1257\n",
      "✅ [Run 4] Mejor Val Acc: 0.253\n",
      "[Run 4] Epoch 40/40 | Train Acc: 0.213 | Val Acc: 0.240 | Train Loss: 3.0068 | Val Loss: 3.1257\n",
      "✅ [Run 4] Mejor Val Acc: 0.253\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>█████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▅▆▆▅▅▇▇▇▆▇▆▇███▇</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▆▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▃▃▃▃▃▁▃▄▅▄▃▃▅▅▅▄▆▆▆▄▅▆▆▆▇▆▆▇▇▇▇▇▆▇▇█████</td></tr><tr><td>val_f1_macro</td><td>▂▂▂▃▂▁▃▃▄▄▂▃▅▅▅▄▅▅▆▃▅▆▅▆▇▆▆▇▇▇▇▇▆▇▇███▇▇</td></tr><tr><td>val_f1_weighted</td><td>▂▂▂▃▂▁▃▃▄▄▂▃▅▅▅▄▅▅▆▃▅▆▅▆▇▆▆▇▇▇▇▇▆▇▇███▇▇</td></tr><tr><td>val_loss</td><td>▆▅▅▅▅█▄▄▃▃▆▄▃▃▃▃▃▂▂▄▃▂▃▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▂▂▂▃▂▁▃▃▄▄▃▃▄▅▄▅▆▄▆▃▄▅▆▆▇▆▆▇▆▇▆▇▆▆█▇██▇█</td></tr><tr><td>val_recall_macro</td><td>▃▃▃▃▃▁▃▄▅▄▃▃▅▅▅▄▆▆▆▄▅▆▆▆▇▆▆▇▇▇▇▇▆▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.25333</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>6e-05</td></tr><tr><td>train_acc</td><td>0.21286</td></tr><tr><td>train_loss</td><td>3.00682</td></tr><tr><td>val_acc</td><td>0.24</td></tr><tr><td>val_f1_macro</td><td>0.20253</td></tr><tr><td>val_f1_weighted</td><td>0.20253</td></tr><tr><td>val_loss</td><td>3.12573</td></tr><tr><td>val_precision_macro</td><td>0.23907</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-AdamW_lr-0.001_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/e7lsx0mk' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/e7lsx0mk</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_202332-e7lsx0mk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_202842-sci8z0oo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/sci8z0oo' target=\"_blank\">run_5_opt-SGD_lr-0.01_bs-32</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/sci8z0oo' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/sci8z0oo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamaño calculado para FC: 43264\n",
      "[Run 5] Epoch 1/40 | Train Acc: 0.049 | Val Acc: 0.073 | Train Loss: 4.2707 | Val Loss: 3.7770\n",
      "[Run 5] Epoch 1/40 | Train Acc: 0.049 | Val Acc: 0.073 | Train Loss: 4.2707 | Val Loss: 3.7770\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.064 | Val Acc: 0.077 | Train Loss: 4.0033 | Val Loss: 3.8424\n",
      "[Run 5] Epoch 2/40 | Train Acc: 0.064 | Val Acc: 0.077 | Train Loss: 4.0033 | Val Loss: 3.8424\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.071 | Val Acc: 0.103 | Train Loss: 3.8861 | Val Loss: 3.6279\n",
      "[Run 5] Epoch 3/40 | Train Acc: 0.071 | Val Acc: 0.103 | Train Loss: 3.8861 | Val Loss: 3.6279\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.090 | Val Acc: 0.110 | Train Loss: 3.8336 | Val Loss: 3.7146\n",
      "[Run 5] Epoch 4/40 | Train Acc: 0.090 | Val Acc: 0.110 | Train Loss: 3.8336 | Val Loss: 3.7146\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.111 | Val Acc: 0.130 | Train Loss: 3.6226 | Val Loss: 3.6607\n",
      "[Run 5] Epoch 5/40 | Train Acc: 0.111 | Val Acc: 0.130 | Train Loss: 3.6226 | Val Loss: 3.6607\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.104 | Val Acc: 0.100 | Train Loss: 3.6202 | Val Loss: 3.6926\n",
      "[Run 5] Epoch 6/40 | Train Acc: 0.104 | Val Acc: 0.100 | Train Loss: 3.6202 | Val Loss: 3.6926\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.118 | Val Acc: 0.140 | Train Loss: 3.5129 | Val Loss: 3.4752\n",
      "[Run 5] Epoch 7/40 | Train Acc: 0.118 | Val Acc: 0.140 | Train Loss: 3.5129 | Val Loss: 3.4752\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.155 | Val Acc: 0.130 | Train Loss: 3.4378 | Val Loss: 3.6468\n",
      "[Run 5] Epoch 8/40 | Train Acc: 0.155 | Val Acc: 0.130 | Train Loss: 3.4378 | Val Loss: 3.6468\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.142 | Val Acc: 0.117 | Train Loss: 3.3856 | Val Loss: 3.5565\n",
      "[Run 5] Epoch 9/40 | Train Acc: 0.142 | Val Acc: 0.117 | Train Loss: 3.3856 | Val Loss: 3.5565\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.151 | Val Acc: 0.150 | Train Loss: 3.3597 | Val Loss: 3.4197\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.151 | Val Acc: 0.150 | Train Loss: 3.3597 | Val Loss: 3.4197\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.199 | Val Acc: 0.143 | Train Loss: 3.2264 | Val Loss: 3.5386\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.199 | Val Acc: 0.143 | Train Loss: 3.2264 | Val Loss: 3.5386\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.227 | Val Acc: 0.120 | Train Loss: 3.0895 | Val Loss: 3.5571\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.227 | Val Acc: 0.120 | Train Loss: 3.0895 | Val Loss: 3.5571\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.227 | Val Acc: 0.177 | Train Loss: 3.0064 | Val Loss: 3.3929\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.227 | Val Acc: 0.177 | Train Loss: 3.0064 | Val Loss: 3.3929\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.251 | Val Acc: 0.193 | Train Loss: 2.9526 | Val Loss: 3.4709\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.251 | Val Acc: 0.193 | Train Loss: 2.9526 | Val Loss: 3.4709\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.284 | Val Acc: 0.153 | Train Loss: 2.8677 | Val Loss: 3.5573\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.284 | Val Acc: 0.153 | Train Loss: 2.8677 | Val Loss: 3.5573\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.282 | Val Acc: 0.190 | Train Loss: 2.8499 | Val Loss: 3.3677\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.282 | Val Acc: 0.190 | Train Loss: 2.8499 | Val Loss: 3.3677\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.299 | Val Acc: 0.183 | Train Loss: 2.7500 | Val Loss: 3.3938\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.299 | Val Acc: 0.183 | Train Loss: 2.7500 | Val Loss: 3.3938\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.341 | Val Acc: 0.203 | Train Loss: 2.6738 | Val Loss: 3.4989\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.341 | Val Acc: 0.203 | Train Loss: 2.6738 | Val Loss: 3.4989\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.334 | Val Acc: 0.227 | Train Loss: 2.6504 | Val Loss: 3.3138\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.334 | Val Acc: 0.227 | Train Loss: 2.6504 | Val Loss: 3.3138\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.358 | Val Acc: 0.213 | Train Loss: 2.5683 | Val Loss: 3.3867\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.358 | Val Acc: 0.213 | Train Loss: 2.5683 | Val Loss: 3.3867\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.390 | Val Acc: 0.230 | Train Loss: 2.5255 | Val Loss: 3.3430\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.390 | Val Acc: 0.230 | Train Loss: 2.5255 | Val Loss: 3.3430\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.428 | Val Acc: 0.197 | Train Loss: 2.4201 | Val Loss: 3.2987\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.428 | Val Acc: 0.197 | Train Loss: 2.4201 | Val Loss: 3.2987\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.434 | Val Acc: 0.247 | Train Loss: 2.3701 | Val Loss: 3.3663\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.434 | Val Acc: 0.247 | Train Loss: 2.3701 | Val Loss: 3.3663\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.467 | Val Acc: 0.240 | Train Loss: 2.3070 | Val Loss: 3.3202\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.467 | Val Acc: 0.240 | Train Loss: 2.3070 | Val Loss: 3.3202\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.467 | Val Acc: 0.197 | Train Loss: 2.2923 | Val Loss: 3.2881\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.467 | Val Acc: 0.197 | Train Loss: 2.2923 | Val Loss: 3.2881\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.499 | Val Acc: 0.243 | Train Loss: 2.2444 | Val Loss: 3.3237\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.499 | Val Acc: 0.243 | Train Loss: 2.2444 | Val Loss: 3.3237\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.486 | Val Acc: 0.237 | Train Loss: 2.2493 | Val Loss: 3.3236\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.486 | Val Acc: 0.237 | Train Loss: 2.2493 | Val Loss: 3.3236\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.519 | Val Acc: 0.263 | Train Loss: 2.1596 | Val Loss: 3.3012\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.519 | Val Acc: 0.263 | Train Loss: 2.1596 | Val Loss: 3.3012\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.536 | Val Acc: 0.247 | Train Loss: 2.1236 | Val Loss: 3.3709\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.536 | Val Acc: 0.247 | Train Loss: 2.1236 | Val Loss: 3.3709\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.539 | Val Acc: 0.270 | Train Loss: 2.1056 | Val Loss: 3.3219\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.539 | Val Acc: 0.270 | Train Loss: 2.1056 | Val Loss: 3.3219\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.544 | Val Acc: 0.257 | Train Loss: 2.0942 | Val Loss: 3.2911\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.544 | Val Acc: 0.257 | Train Loss: 2.0942 | Val Loss: 3.2911\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.567 | Val Acc: 0.250 | Train Loss: 2.0698 | Val Loss: 3.2921\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.567 | Val Acc: 0.250 | Train Loss: 2.0698 | Val Loss: 3.2921\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.603 | Val Acc: 0.253 | Train Loss: 1.9958 | Val Loss: 3.3317\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.603 | Val Acc: 0.253 | Train Loss: 1.9958 | Val Loss: 3.3317\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.586 | Val Acc: 0.277 | Train Loss: 1.9885 | Val Loss: 3.3104\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.586 | Val Acc: 0.277 | Train Loss: 1.9885 | Val Loss: 3.3104\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.629 | Val Acc: 0.263 | Train Loss: 1.9130 | Val Loss: 3.3083\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.629 | Val Acc: 0.263 | Train Loss: 1.9130 | Val Loss: 3.3083\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.608 | Val Acc: 0.270 | Train Loss: 1.9321 | Val Loss: 3.2776\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.608 | Val Acc: 0.270 | Train Loss: 1.9321 | Val Loss: 3.2776\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.623 | Val Acc: 0.267 | Train Loss: 1.9392 | Val Loss: 3.3238\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.623 | Val Acc: 0.267 | Train Loss: 1.9392 | Val Loss: 3.3238\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.616 | Val Acc: 0.270 | Train Loss: 1.9328 | Val Loss: 3.3412\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.616 | Val Acc: 0.270 | Train Loss: 1.9328 | Val Loss: 3.3412\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.626 | Val Acc: 0.277 | Train Loss: 1.8923 | Val Loss: 3.3282\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.626 | Val Acc: 0.277 | Train Loss: 1.8923 | Val Loss: 3.3282\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.664 | Val Acc: 0.273 | Train Loss: 1.8445 | Val Loss: 3.2634\n",
      "✅ [Run 5] Mejor Val Acc: 0.277\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.664 | Val Acc: 0.273 | Train Loss: 1.8445 | Val Loss: 3.2634\n",
      "✅ [Run 5] Mejor Val Acc: 0.277\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>█████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█▇█▇██</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▂▃▂▃▃▂▄▃▃▅▅▄▅▅▅▆▆▆▅▇▇▅▇▇█▇█▇▇▇███████</td></tr><tr><td>val_f1_macro</td><td>▁▂▂▂▃▂▃▃▃▄▃▃▄▅▄▅▅▅▇▆▇▆▇▇▅▇▇█▇█▇▇████████</td></tr><tr><td>val_f1_weighted</td><td>▁▂▂▂▃▂▃▃▃▄▃▃▄▅▄▅▅▅▇▆▇▆▇▇▅▇▇█▇█▇▇████████</td></tr><tr><td>val_loss</td><td>▇█▅▆▆▆▄▆▅▃▄▅▃▄▅▂▃▄▂▂▂▁▂▂▁▂▂▁▂▂▁▁▂▂▂▁▂▂▂▁</td></tr><tr><td>val_precision_macro</td><td>▁▂▂▂▂▂▃▃▃▃▄▂▄▅▅▅▅▅▇▆▆▆▇▇▅▇▇▇█▇▇▇█▇▇▇█▇▇█</td></tr><tr><td>val_recall_macro</td><td>▁▁▂▂▃▂▃▃▂▄▃▃▅▅▄▅▅▅▆▆▆▅▇▇▅▇▇█▇█▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.27667</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00063</td></tr><tr><td>train_acc</td><td>0.66357</td></tr><tr><td>train_loss</td><td>1.84448</td></tr><tr><td>val_acc</td><td>0.27333</td></tr><tr><td>val_f1_macro</td><td>0.24887</td></tr><tr><td>val_f1_weighted</td><td>0.24887</td></tr><tr><td>val_loss</td><td>3.26343</td></tr><tr><td>val_precision_macro</td><td>0.31134</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.01_bs-32</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/sci8z0oo' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified/runs/sci8z0oo</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-lenet-augmented_stratified</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_202842-sci8z0oo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# ==============================\n",
    "# CONFIGURACIÓN\n",
    "# ==============================\n",
    "DATA_DIR = \"data/spectrograms2/augmented\"\n",
    "IMG_SIZE = (224, 224)\n",
    "EPOCHS = 40\n",
    "PATIENCE = 6\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==============================\n",
    "# TRANSFORMACIONES\n",
    "# ==============================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\", transform=transform)\n",
    "\n",
    "class_names = train_data.classes\n",
    "\n",
    "# ==============================\n",
    "# EXPERIMENTOS (Optimizados para dataset aumentado)\n",
    "# ==============================\n",
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001, \"batch_size\": 64, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 0.001, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\", \"lr\": 0.01, \"batch_size\": 32, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# CICLO DE ENTRENAMIENTO\n",
    "# ==============================\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    try:\n",
    "        wandb.finish()  # Cerrar cualquier run previo\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    wandb.init(\n",
    "        project=\"esc50-lenet-augmented_stratified\",\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_data, batch_size=config.batch_size)\n",
    "\n",
    "    model = LeNet5(num_classes=len(train_data.classes)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label smoothing para augmented data\n",
    "\n",
    "    if config.optimizer in [\"Adam\", \"AdamW\"]:\n",
    "        if config.optimizer == \"Adam\":\n",
    "            optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        else:\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)  # Scheduler más suave para augmented\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # === ENTRENAMIENTO ===\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # === VALIDACIÓN ===\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        val_y_true, val_y_pred = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                \n",
    "                val_y_true.extend(labels.cpu().tolist())\n",
    "                val_y_pred.extend(preds.cpu().tolist())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        # === MÉTRICAS ADICIONALES ===\n",
    "        prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"macro\", zero_division=0\n",
    "        )\n",
    "        _, _, f1_w, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"weighted\", zero_division=0\n",
    "        )\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1_macro\": f1_m,\n",
    "            \"val_f1_weighted\": f1_w,\n",
    "            \"val_precision_macro\": prec_m,\n",
    "            \"val_recall_macro\": rec_m,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "            \"val_confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                y_true=val_y_true,\n",
    "                preds=val_y_pred,\n",
    "                class_names=class_names\n",
    "            )\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # === EARLY STOPPING ===\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/lenet5_aug_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > PATIENCE:\n",
    "                print(f\"[Run {i}] Early stopping triggered at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f633eb",
   "metadata": {},
   "source": [
    "# Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca37970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Type, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utilidades de convolución\n",
    "# -------------------------\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"Conv 3×3 con padding=1, sin bias (BN lo compensa).\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"Conv 1×1 para proyección en atajos (ajustar canales/stride).\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Bloque residual \"básico\"\n",
    "# -------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Estructura:\n",
    "        Conv3x3 → BN → ReLU → Conv3x3 → BN → (Suma con atajo) → ReLU\n",
    "    Donde el atajo (identity) puede incluir una proyección 1×1 si cambia\n",
    "    la resolución (stride > 1) o el número de canales.\n",
    "    \"\"\"\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1   = norm_layer(planes)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2   = norm_layer(planes)\n",
    "\n",
    "        self.downsample = downsample  # Proyección para el atajo, si aplica\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x  # Atajo\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Alinear dimensiones del atajo si cambió stride o # de canales\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# -----------\n",
    "# ResNet base\n",
    "# -----------\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Constructor general de ResNet con BasicBlock y configuración [2,2,2,2].\n",
    "    Parámetros clave:\n",
    "        - small_input=True: conv1=3×3 s=1 y sin MaxPool (mejor para 64–224 px).\n",
    "        - small_input=False: conv1=7×7 s=2 + MaxPool (clásico de ResNet).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[BasicBlock],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 50,\n",
    "        in_channels: int = 1,\n",
    "        small_input: bool = True,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "\n",
    "        # Capa inicial: variante \"small_input\" recomendada para espectrogramas\n",
    "        if small_input:\n",
    "            # Preserva más detalle inicial (sin MaxPool temprano)\n",
    "            self.conv1   = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.maxpool = nn.Identity()\n",
    "        else:\n",
    "            # Estilo ResNet clásico para entradas grandes\n",
    "            self.conv1   = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.bn1  = norm_layer(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Stages: [64, 128, 256, 512] con [2, 2, 2, 2] bloques\n",
    "        self.layer1 = self._make_layer(block,  64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        # Cabeza de clasificación\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Global Average Pooling\n",
    "        self.fc      = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Inicialización recomendada para ReLU/BN\n",
    "        self._init_weights()\n",
    "\n",
    "    def _make_layer(self, block: Type[BasicBlock], planes: int, blocks: int, stride: int = 1) -> nn.Sequential:\n",
    "        \"\"\"\n",
    "        Crea un stage con 'blocks' bloques. El primer bloque puede hacer downsample\n",
    "        (stride=2) para reducir resolución y duplicar canales.\n",
    "        \"\"\"\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "\n",
    "        # Si cambia resolución o # de canales, proyectamos el atajo (1×1)\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _init_weights(self) -> None:\n",
    "        \"\"\"Inicialización Kaiming para conv; constantes para BN; normal para FC.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Entrada → conv1 → BN → ReLU → (posible MaxPool/Identity)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Stages residuales\n",
    "        x = self.layer1(x)  # 64\n",
    "        x = self.layer2(x)  # 128\n",
    "        x = self.layer3(x)  # 256\n",
    "        x = self.layer4(x)  # 512\n",
    "\n",
    "        # Cabeza\n",
    "        x = self.avgpool(x)           # (B, 512, 1, 1)\n",
    "        x = torch.flatten(x, 1)       # (B, 512)\n",
    "        x = self.fc(x)                # (B, num_classes)\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Fábrica de ResNet-18\n",
    "# -------------------------\n",
    "def resnet18_audio(num_classes: int = 50, in_channels: int = 1, small_input: bool = True) -> ResNet:\n",
    "    \"\"\"\n",
    "    Retorna una ResNet-18 lista para espectrogramas:\n",
    "        - num_classes: # de clases del dataset (ESC-50 → 50)\n",
    "        - in_channels: 1 para grises; 3 si usas RGB (replicar canal)\n",
    "        - small_input: True recomendado para ~128–224 px\n",
    "    \"\"\"\n",
    "    return ResNet(\n",
    "        block=BasicBlock,\n",
    "        layers=[2, 2, 2, 2],\n",
    "        num_classes=num_classes,\n",
    "        in_channels=in_channels,\n",
    "        small_input=small_input,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf849e1",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Raw Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1b2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Clases detectadas: 50\n",
      "\n",
      "===== Iniciando experimento 1 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/offline-run-20251027_204434-p8e4s2ga</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Ep 01/40 | Train Acc: 0.063 | Val Acc: 0.107 | Train Loss: 3.5940 | Val Loss: 3.2807\n",
      "[Run 1] Ep 02/40 | Train Acc: 0.114 | Val Acc: 0.233 | Train Loss: 3.1759 | Val Loss: 2.8340\n",
      "[Run 1] Ep 02/40 | Train Acc: 0.114 | Val Acc: 0.233 | Train Loss: 3.1759 | Val Loss: 2.8340\n",
      "[Run 1] Ep 03/40 | Train Acc: 0.194 | Val Acc: 0.173 | Train Loss: 2.9165 | Val Loss: 2.8972\n",
      "[Run 1] Ep 03/40 | Train Acc: 0.194 | Val Acc: 0.173 | Train Loss: 2.9165 | Val Loss: 2.8972\n",
      "[Run 1] Ep 04/40 | Train Acc: 0.225 | Val Acc: 0.263 | Train Loss: 2.7275 | Val Loss: 2.6050\n",
      "[Run 1] Ep 04/40 | Train Acc: 0.225 | Val Acc: 0.263 | Train Loss: 2.7275 | Val Loss: 2.6050\n",
      "[Run 1] Ep 05/40 | Train Acc: 0.276 | Val Acc: 0.240 | Train Loss: 2.5378 | Val Loss: 2.6645\n",
      "[Run 1] Ep 05/40 | Train Acc: 0.276 | Val Acc: 0.240 | Train Loss: 2.5378 | Val Loss: 2.6645\n",
      "[Run 1] Ep 06/40 | Train Acc: 0.311 | Val Acc: 0.330 | Train Loss: 2.4449 | Val Loss: 2.2783\n",
      "[Run 1] Ep 06/40 | Train Acc: 0.311 | Val Acc: 0.330 | Train Loss: 2.4449 | Val Loss: 2.2783\n",
      "[Run 1] Ep 07/40 | Train Acc: 0.344 | Val Acc: 0.350 | Train Loss: 2.2714 | Val Loss: 2.4133\n",
      "[Run 1] Ep 07/40 | Train Acc: 0.344 | Val Acc: 0.350 | Train Loss: 2.2714 | Val Loss: 2.4133\n",
      "[Run 1] Ep 08/40 | Train Acc: 0.364 | Val Acc: 0.433 | Train Loss: 2.1212 | Val Loss: 1.8733\n",
      "[Run 1] Ep 08/40 | Train Acc: 0.364 | Val Acc: 0.433 | Train Loss: 2.1212 | Val Loss: 1.8733\n",
      "[Run 1] Ep 09/40 | Train Acc: 0.439 | Val Acc: 0.437 | Train Loss: 1.9089 | Val Loss: 1.8436\n",
      "[Run 1] Ep 09/40 | Train Acc: 0.439 | Val Acc: 0.437 | Train Loss: 1.9089 | Val Loss: 1.8436\n",
      "[Run 1] Ep 10/40 | Train Acc: 0.470 | Val Acc: 0.447 | Train Loss: 1.8186 | Val Loss: 1.6704\n",
      "[Run 1] Ep 10/40 | Train Acc: 0.470 | Val Acc: 0.447 | Train Loss: 1.8186 | Val Loss: 1.6704\n",
      "[Run 1] Ep 11/40 | Train Acc: 0.476 | Val Acc: 0.433 | Train Loss: 1.7722 | Val Loss: 1.7808\n",
      "[Run 1] Ep 11/40 | Train Acc: 0.476 | Val Acc: 0.433 | Train Loss: 1.7722 | Val Loss: 1.7808\n",
      "[Run 1] Ep 12/40 | Train Acc: 0.506 | Val Acc: 0.483 | Train Loss: 1.7267 | Val Loss: 1.7553\n",
      "[Run 1] Ep 12/40 | Train Acc: 0.506 | Val Acc: 0.483 | Train Loss: 1.7267 | Val Loss: 1.7553\n",
      "[Run 1] Ep 13/40 | Train Acc: 0.518 | Val Acc: 0.467 | Train Loss: 1.6530 | Val Loss: 1.7273\n",
      "[Run 1] Ep 13/40 | Train Acc: 0.518 | Val Acc: 0.467 | Train Loss: 1.6530 | Val Loss: 1.7273\n",
      "[Run 1] Ep 14/40 | Train Acc: 0.539 | Val Acc: 0.517 | Train Loss: 1.5462 | Val Loss: 1.6115\n",
      "[Run 1] Ep 14/40 | Train Acc: 0.539 | Val Acc: 0.517 | Train Loss: 1.5462 | Val Loss: 1.6115\n",
      "[Run 1] Ep 15/40 | Train Acc: 0.578 | Val Acc: 0.590 | Train Loss: 1.4551 | Val Loss: 1.4590\n",
      "[Run 1] Ep 15/40 | Train Acc: 0.578 | Val Acc: 0.590 | Train Loss: 1.4551 | Val Loss: 1.4590\n",
      "[Run 1] Ep 16/40 | Train Acc: 0.598 | Val Acc: 0.587 | Train Loss: 1.3833 | Val Loss: 1.4096\n",
      "[Run 1] Ep 16/40 | Train Acc: 0.598 | Val Acc: 0.587 | Train Loss: 1.3833 | Val Loss: 1.4096\n",
      "[Run 1] Ep 17/40 | Train Acc: 0.613 | Val Acc: 0.527 | Train Loss: 1.2890 | Val Loss: 1.5709\n",
      "[Run 1] Ep 17/40 | Train Acc: 0.613 | Val Acc: 0.527 | Train Loss: 1.2890 | Val Loss: 1.5709\n",
      "[Run 1] Ep 18/40 | Train Acc: 0.662 | Val Acc: 0.587 | Train Loss: 1.2073 | Val Loss: 1.4509\n",
      "[Run 1] Ep 18/40 | Train Acc: 0.662 | Val Acc: 0.587 | Train Loss: 1.2073 | Val Loss: 1.4509\n",
      "[Run 1] Ep 19/40 | Train Acc: 0.681 | Val Acc: 0.623 | Train Loss: 1.1467 | Val Loss: 1.2755\n",
      "[Run 1] Ep 19/40 | Train Acc: 0.681 | Val Acc: 0.623 | Train Loss: 1.1467 | Val Loss: 1.2755\n",
      "[Run 1] Ep 20/40 | Train Acc: 0.667 | Val Acc: 0.633 | Train Loss: 1.1233 | Val Loss: 1.2785\n",
      "[Run 1] Ep 20/40 | Train Acc: 0.667 | Val Acc: 0.633 | Train Loss: 1.1233 | Val Loss: 1.2785\n",
      "[Run 1] Ep 21/40 | Train Acc: 0.673 | Val Acc: 0.617 | Train Loss: 1.0705 | Val Loss: 1.2810\n",
      "[Run 1] Ep 21/40 | Train Acc: 0.673 | Val Acc: 0.617 | Train Loss: 1.0705 | Val Loss: 1.2810\n",
      "[Run 1] Ep 22/40 | Train Acc: 0.686 | Val Acc: 0.657 | Train Loss: 1.0433 | Val Loss: 1.2739\n",
      "[Run 1] Ep 22/40 | Train Acc: 0.686 | Val Acc: 0.657 | Train Loss: 1.0433 | Val Loss: 1.2739\n",
      "[Run 1] Ep 23/40 | Train Acc: 0.705 | Val Acc: 0.637 | Train Loss: 0.9896 | Val Loss: 1.2517\n",
      "[Run 1] Ep 23/40 | Train Acc: 0.705 | Val Acc: 0.637 | Train Loss: 0.9896 | Val Loss: 1.2517\n",
      "[Run 1] Ep 24/40 | Train Acc: 0.711 | Val Acc: 0.603 | Train Loss: 0.9714 | Val Loss: 1.2197\n",
      "[Run 1] Ep 24/40 | Train Acc: 0.711 | Val Acc: 0.603 | Train Loss: 0.9714 | Val Loss: 1.2197\n",
      "[Run 1] Ep 25/40 | Train Acc: 0.759 | Val Acc: 0.680 | Train Loss: 0.8696 | Val Loss: 1.1484\n",
      "[Run 1] Ep 25/40 | Train Acc: 0.759 | Val Acc: 0.680 | Train Loss: 0.8696 | Val Loss: 1.1484\n",
      "[Run 1] Ep 26/40 | Train Acc: 0.779 | Val Acc: 0.673 | Train Loss: 0.8167 | Val Loss: 1.0918\n",
      "[Run 1] Ep 26/40 | Train Acc: 0.779 | Val Acc: 0.673 | Train Loss: 0.8167 | Val Loss: 1.0918\n",
      "[Run 1] Ep 27/40 | Train Acc: 0.797 | Val Acc: 0.673 | Train Loss: 0.7652 | Val Loss: 1.0853\n",
      "[Run 1] Ep 27/40 | Train Acc: 0.797 | Val Acc: 0.673 | Train Loss: 0.7652 | Val Loss: 1.0853\n",
      "[Run 1] Ep 28/40 | Train Acc: 0.792 | Val Acc: 0.697 | Train Loss: 0.7497 | Val Loss: 1.0848\n",
      "[Run 1] Ep 28/40 | Train Acc: 0.792 | Val Acc: 0.697 | Train Loss: 0.7497 | Val Loss: 1.0848\n",
      "[Run 1] Ep 29/40 | Train Acc: 0.804 | Val Acc: 0.707 | Train Loss: 0.7205 | Val Loss: 1.0948\n",
      "[Run 1] Ep 29/40 | Train Acc: 0.804 | Val Acc: 0.707 | Train Loss: 0.7205 | Val Loss: 1.0948\n",
      "[Run 1] Ep 30/40 | Train Acc: 0.812 | Val Acc: 0.710 | Train Loss: 0.6933 | Val Loss: 1.0457\n",
      "[Run 1] Ep 30/40 | Train Acc: 0.812 | Val Acc: 0.710 | Train Loss: 0.6933 | Val Loss: 1.0457\n",
      "[Run 1] Ep 31/40 | Train Acc: 0.832 | Val Acc: 0.710 | Train Loss: 0.6603 | Val Loss: 1.1620\n",
      "[Run 1] Ep 31/40 | Train Acc: 0.832 | Val Acc: 0.710 | Train Loss: 0.6603 | Val Loss: 1.1620\n",
      "[Run 1] Ep 32/40 | Train Acc: 0.829 | Val Acc: 0.693 | Train Loss: 0.6364 | Val Loss: 1.0174\n",
      "[Run 1] Ep 32/40 | Train Acc: 0.829 | Val Acc: 0.693 | Train Loss: 0.6364 | Val Loss: 1.0174\n",
      "[Run 1] Ep 33/40 | Train Acc: 0.853 | Val Acc: 0.760 | Train Loss: 0.5662 | Val Loss: 0.9560\n",
      "[Run 1] Ep 33/40 | Train Acc: 0.853 | Val Acc: 0.760 | Train Loss: 0.5662 | Val Loss: 0.9560\n",
      "[Run 1] Ep 34/40 | Train Acc: 0.871 | Val Acc: 0.737 | Train Loss: 0.5286 | Val Loss: 0.9298\n",
      "[Run 1] Ep 34/40 | Train Acc: 0.871 | Val Acc: 0.737 | Train Loss: 0.5286 | Val Loss: 0.9298\n",
      "[Run 1] Ep 35/40 | Train Acc: 0.878 | Val Acc: 0.747 | Train Loss: 0.5380 | Val Loss: 0.9286\n",
      "[Run 1] Ep 35/40 | Train Acc: 0.878 | Val Acc: 0.747 | Train Loss: 0.5380 | Val Loss: 0.9286\n",
      "[Run 1] Ep 36/40 | Train Acc: 0.881 | Val Acc: 0.707 | Train Loss: 0.5010 | Val Loss: 1.0180\n",
      "[Run 1] Ep 36/40 | Train Acc: 0.881 | Val Acc: 0.707 | Train Loss: 0.5010 | Val Loss: 1.0180\n",
      "[Run 1] Ep 37/40 | Train Acc: 0.880 | Val Acc: 0.723 | Train Loss: 0.5156 | Val Loss: 0.9334\n",
      "[Run 1] Ep 37/40 | Train Acc: 0.880 | Val Acc: 0.723 | Train Loss: 0.5156 | Val Loss: 0.9334\n",
      "[Run 1] Ep 38/40 | Train Acc: 0.889 | Val Acc: 0.740 | Train Loss: 0.4761 | Val Loss: 0.8861\n",
      "[Run 1] Ep 38/40 | Train Acc: 0.889 | Val Acc: 0.740 | Train Loss: 0.4761 | Val Loss: 0.8861\n",
      "[Run 1] Ep 39/40 | Train Acc: 0.876 | Val Acc: 0.727 | Train Loss: 0.4961 | Val Loss: 0.9209\n",
      "[Run 1] Ep 39/40 | Train Acc: 0.876 | Val Acc: 0.727 | Train Loss: 0.4961 | Val Loss: 0.9209\n",
      "[Run 1] Ep 40/40 | Train Acc: 0.898 | Val Acc: 0.737 | Train Loss: 0.4505 | Val Loss: 0.9135\n",
      "[Run 1] Early stopping en epoch 40.\n",
      "✅ [Run 1] Mejor Val Acc: 0.760\n",
      "[Run 1] Ep 40/40 | Train Acc: 0.898 | Val Acc: 0.737 | Train Loss: 0.4505 | Val Loss: 0.9135\n",
      "[Run 1] Early stopping en epoch 40.\n",
      "✅ [Run 1] Mejor Val Acc: 0.760\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▃▂▃▄▅▅▅▅▅▅▅▆▆▅▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇███▇████</td></tr><tr><td>val_f1_macro</td><td>▁▂▁▂▂▃▃▄▅▅▅▅▅▅▆▆▆▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇███▇████</td></tr><tr><td>val_f1_weighted</td><td>▁▂▁▂▂▃▃▄▅▅▅▅▅▅▆▆▆▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇███▇████</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▅▅▄▄▃▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▂▁▃▂▄▄▅▅▅▅▅▅▅▇▇▆▆▇▇▇▇▇▆▇▇▇███████████▇█</td></tr><tr><td>val_recall_macro</td><td>▁▂▂▃▂▃▄▅▅▅▅▅▅▅▆▆▅▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇███▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.76</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>5e-05</td></tr><tr><td>train_acc</td><td>0.89786</td></tr><tr><td>train_loss</td><td>0.45052</td></tr><tr><td>val_acc</td><td>0.73667</td></tr><tr><td>val_f1_macro</td><td>0.73001</td></tr><tr><td>val_f1_weighted</td><td>0.73001</td></tr><tr><td>val_loss</td><td>0.91348</td></tr><tr><td>val_precision_macro</td><td>0.76383</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br><code>wandb sync /home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/offline-run-20251027_204434-p8e4s2ga<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20251027_204434-p8e4s2ga/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Iniciando experimento 2 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/offline-run-20251027_213437-53m74zow</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Ep 01/40 | Train Acc: 0.084 | Val Acc: 0.160 | Train Loss: 3.5569 | Val Loss: 3.0882\n",
      "[Run 2] Ep 02/40 | Train Acc: 0.175 | Val Acc: 0.203 | Train Loss: 3.0771 | Val Loss: 2.8628\n",
      "[Run 2] Ep 02/40 | Train Acc: 0.175 | Val Acc: 0.203 | Train Loss: 3.0771 | Val Loss: 2.8628\n",
      "[Run 2] Ep 03/40 | Train Acc: 0.221 | Val Acc: 0.250 | Train Loss: 2.8034 | Val Loss: 2.6208\n",
      "[Run 2] Ep 03/40 | Train Acc: 0.221 | Val Acc: 0.250 | Train Loss: 2.8034 | Val Loss: 2.6208\n",
      "[Run 2] Ep 04/40 | Train Acc: 0.284 | Val Acc: 0.290 | Train Loss: 2.6132 | Val Loss: 2.5024\n",
      "[Run 2] Ep 04/40 | Train Acc: 0.284 | Val Acc: 0.290 | Train Loss: 2.6132 | Val Loss: 2.5024\n",
      "[Run 2] Ep 05/40 | Train Acc: 0.316 | Val Acc: 0.383 | Train Loss: 2.4464 | Val Loss: 2.2706\n",
      "[Run 2] Ep 05/40 | Train Acc: 0.316 | Val Acc: 0.383 | Train Loss: 2.4464 | Val Loss: 2.2706\n",
      "[Run 2] Ep 06/40 | Train Acc: 0.373 | Val Acc: 0.320 | Train Loss: 2.2540 | Val Loss: 2.4468\n",
      "[Run 2] Ep 06/40 | Train Acc: 0.373 | Val Acc: 0.320 | Train Loss: 2.2540 | Val Loss: 2.4468\n",
      "[Run 2] Ep 07/40 | Train Acc: 0.381 | Val Acc: 0.457 | Train Loss: 2.1690 | Val Loss: 1.9421\n",
      "[Run 2] Ep 07/40 | Train Acc: 0.381 | Val Acc: 0.457 | Train Loss: 2.1690 | Val Loss: 1.9421\n",
      "[Run 2] Ep 08/40 | Train Acc: 0.451 | Val Acc: 0.480 | Train Loss: 2.0087 | Val Loss: 1.8747\n",
      "[Run 2] Ep 08/40 | Train Acc: 0.451 | Val Acc: 0.480 | Train Loss: 2.0087 | Val Loss: 1.8747\n",
      "[Run 2] Ep 09/40 | Train Acc: 0.520 | Val Acc: 0.427 | Train Loss: 1.8533 | Val Loss: 1.8173\n",
      "[Run 2] Ep 09/40 | Train Acc: 0.520 | Val Acc: 0.427 | Train Loss: 1.8533 | Val Loss: 1.8173\n",
      "[Run 2] Ep 10/40 | Train Acc: 0.524 | Val Acc: 0.523 | Train Loss: 1.7444 | Val Loss: 1.7290\n",
      "[Run 2] Ep 10/40 | Train Acc: 0.524 | Val Acc: 0.523 | Train Loss: 1.7444 | Val Loss: 1.7290\n",
      "[Run 2] Ep 11/40 | Train Acc: 0.570 | Val Acc: 0.537 | Train Loss: 1.6543 | Val Loss: 1.6082\n",
      "[Run 2] Ep 11/40 | Train Acc: 0.570 | Val Acc: 0.537 | Train Loss: 1.6543 | Val Loss: 1.6082\n",
      "[Run 2] Ep 12/40 | Train Acc: 0.586 | Val Acc: 0.560 | Train Loss: 1.5795 | Val Loss: 1.5355\n",
      "[Run 2] Ep 12/40 | Train Acc: 0.586 | Val Acc: 0.560 | Train Loss: 1.5795 | Val Loss: 1.5355\n",
      "[Run 2] Ep 13/40 | Train Acc: 0.607 | Val Acc: 0.553 | Train Loss: 1.5127 | Val Loss: 1.5733\n",
      "[Run 2] Ep 13/40 | Train Acc: 0.607 | Val Acc: 0.553 | Train Loss: 1.5127 | Val Loss: 1.5733\n",
      "[Run 2] Ep 14/40 | Train Acc: 0.629 | Val Acc: 0.600 | Train Loss: 1.4078 | Val Loss: 1.5837\n",
      "[Run 2] Ep 14/40 | Train Acc: 0.629 | Val Acc: 0.600 | Train Loss: 1.4078 | Val Loss: 1.5837\n",
      "[Run 2] Ep 15/40 | Train Acc: 0.628 | Val Acc: 0.597 | Train Loss: 1.3826 | Val Loss: 1.4053\n",
      "[Run 2] Ep 15/40 | Train Acc: 0.628 | Val Acc: 0.597 | Train Loss: 1.3826 | Val Loss: 1.4053\n",
      "[Run 2] Ep 16/40 | Train Acc: 0.661 | Val Acc: 0.573 | Train Loss: 1.2865 | Val Loss: 1.4782\n",
      "[Run 2] Ep 16/40 | Train Acc: 0.661 | Val Acc: 0.573 | Train Loss: 1.2865 | Val Loss: 1.4782\n",
      "[Run 2] Ep 17/40 | Train Acc: 0.681 | Val Acc: 0.650 | Train Loss: 1.2118 | Val Loss: 1.3429\n",
      "[Run 2] Ep 17/40 | Train Acc: 0.681 | Val Acc: 0.650 | Train Loss: 1.2118 | Val Loss: 1.3429\n",
      "[Run 2] Ep 18/40 | Train Acc: 0.704 | Val Acc: 0.617 | Train Loss: 1.1686 | Val Loss: 1.3328\n",
      "[Run 2] Ep 18/40 | Train Acc: 0.704 | Val Acc: 0.617 | Train Loss: 1.1686 | Val Loss: 1.3328\n",
      "[Run 2] Ep 19/40 | Train Acc: 0.705 | Val Acc: 0.637 | Train Loss: 1.1405 | Val Loss: 1.2927\n",
      "[Run 2] Ep 19/40 | Train Acc: 0.705 | Val Acc: 0.637 | Train Loss: 1.1405 | Val Loss: 1.2927\n",
      "[Run 2] Ep 20/40 | Train Acc: 0.737 | Val Acc: 0.637 | Train Loss: 1.0650 | Val Loss: 1.2371\n",
      "[Run 2] Ep 20/40 | Train Acc: 0.737 | Val Acc: 0.637 | Train Loss: 1.0650 | Val Loss: 1.2371\n",
      "[Run 2] Ep 21/40 | Train Acc: 0.761 | Val Acc: 0.643 | Train Loss: 0.9767 | Val Loss: 1.2768\n",
      "[Run 2] Ep 21/40 | Train Acc: 0.761 | Val Acc: 0.643 | Train Loss: 0.9767 | Val Loss: 1.2768\n",
      "[Run 2] Ep 22/40 | Train Acc: 0.776 | Val Acc: 0.647 | Train Loss: 0.9564 | Val Loss: 1.3087\n",
      "[Run 2] Ep 22/40 | Train Acc: 0.776 | Val Acc: 0.647 | Train Loss: 0.9564 | Val Loss: 1.3087\n",
      "[Run 2] Ep 23/40 | Train Acc: 0.767 | Val Acc: 0.627 | Train Loss: 0.9557 | Val Loss: 1.1685\n",
      "[Run 2] Ep 23/40 | Train Acc: 0.767 | Val Acc: 0.627 | Train Loss: 0.9557 | Val Loss: 1.1685\n",
      "[Run 2] Ep 24/40 | Train Acc: 0.786 | Val Acc: 0.743 | Train Loss: 0.8760 | Val Loss: 1.0301\n",
      "[Run 2] Ep 24/40 | Train Acc: 0.786 | Val Acc: 0.743 | Train Loss: 0.8760 | Val Loss: 1.0301\n",
      "[Run 2] Ep 25/40 | Train Acc: 0.821 | Val Acc: 0.727 | Train Loss: 0.7903 | Val Loss: 1.0852\n",
      "[Run 2] Ep 25/40 | Train Acc: 0.821 | Val Acc: 0.727 | Train Loss: 0.7903 | Val Loss: 1.0852\n",
      "[Run 2] Ep 26/40 | Train Acc: 0.842 | Val Acc: 0.723 | Train Loss: 0.7644 | Val Loss: 1.0316\n",
      "[Run 2] Ep 26/40 | Train Acc: 0.842 | Val Acc: 0.723 | Train Loss: 0.7644 | Val Loss: 1.0316\n",
      "[Run 2] Ep 27/40 | Train Acc: 0.846 | Val Acc: 0.697 | Train Loss: 0.7524 | Val Loss: 1.1126\n",
      "[Run 2] Ep 27/40 | Train Acc: 0.846 | Val Acc: 0.697 | Train Loss: 0.7524 | Val Loss: 1.1126\n",
      "[Run 2] Ep 28/40 | Train Acc: 0.837 | Val Acc: 0.733 | Train Loss: 0.7150 | Val Loss: 1.0325\n",
      "[Run 2] Ep 28/40 | Train Acc: 0.837 | Val Acc: 0.733 | Train Loss: 0.7150 | Val Loss: 1.0325\n",
      "[Run 2] Ep 29/40 | Train Acc: 0.871 | Val Acc: 0.727 | Train Loss: 0.6762 | Val Loss: 1.1126\n",
      "[Run 2] Ep 29/40 | Train Acc: 0.871 | Val Acc: 0.727 | Train Loss: 0.6762 | Val Loss: 1.1126\n",
      "[Run 2] Ep 30/40 | Train Acc: 0.880 | Val Acc: 0.713 | Train Loss: 0.6385 | Val Loss: 1.0247\n",
      "[Run 2] Ep 30/40 | Train Acc: 0.880 | Val Acc: 0.713 | Train Loss: 0.6385 | Val Loss: 1.0247\n",
      "[Run 2] Ep 31/40 | Train Acc: 0.890 | Val Acc: 0.740 | Train Loss: 0.6037 | Val Loss: 1.0024\n",
      "[Run 2] Early stopping en epoch 31.\n",
      "✅ [Run 2] Mejor Val Acc: 0.743\n",
      "[Run 2] Ep 31/40 | Train Acc: 0.890 | Val Acc: 0.740 | Train Loss: 0.6037 | Val Loss: 1.0024\n",
      "[Run 2] Early stopping en epoch 31.\n",
      "✅ [Run 2] Mejor Val Acc: 0.743\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▃▄▃▅▅▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇███▇████</td></tr><tr><td>val_f1_macro</td><td>▁▁▂▂▄▃▄▅▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇███▇████</td></tr><tr><td>val_f1_weighted</td><td>▁▁▂▂▄▃▄▅▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇███▇████</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▆▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▂▂▃▄▄▅▅▄▅▆▆▆▇▆▆▇▇▇▇▇▇▇███▇████</td></tr><tr><td>val_recall_macro</td><td>▁▂▂▃▄▃▅▅▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇███▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.74333</td></tr><tr><td>epoch</td><td>31</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>train_acc</td><td>0.89</td></tr><tr><td>train_loss</td><td>0.60365</td></tr><tr><td>val_acc</td><td>0.74</td></tr><tr><td>val_f1_macro</td><td>0.73624</td></tr><tr><td>val_f1_weighted</td><td>0.73624</td></tr><tr><td>val_loss</td><td>1.00237</td></tr><tr><td>val_precision_macro</td><td>0.77265</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br><code>wandb sync /home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/offline-run-20251027_213437-53m74zow<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20251027_213437-53m74zow/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Iniciando experimento 3 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/offline-run-20251027_220959-ev95eteb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Ep 01/40 | Train Acc: 0.049 | Val Acc: 0.067 | Train Loss: 3.9160 | Val Loss: 3.5599\n",
      "[Run 3] Ep 02/40 | Train Acc: 0.096 | Val Acc: 0.100 | Train Loss: 3.4126 | Val Loss: 3.2587\n",
      "[Run 3] Ep 02/40 | Train Acc: 0.096 | Val Acc: 0.100 | Train Loss: 3.4126 | Val Loss: 3.2587\n",
      "[Run 3] Ep 03/40 | Train Acc: 0.129 | Val Acc: 0.133 | Train Loss: 3.1493 | Val Loss: 3.2062\n",
      "[Run 3] Ep 03/40 | Train Acc: 0.129 | Val Acc: 0.133 | Train Loss: 3.1493 | Val Loss: 3.2062\n",
      "[Run 3] Ep 04/40 | Train Acc: 0.193 | Val Acc: 0.240 | Train Loss: 2.8510 | Val Loss: 2.6457\n",
      "[Run 3] Ep 04/40 | Train Acc: 0.193 | Val Acc: 0.240 | Train Loss: 2.8510 | Val Loss: 2.6457\n",
      "[Run 3] Ep 05/40 | Train Acc: 0.243 | Val Acc: 0.200 | Train Loss: 2.5899 | Val Loss: 3.1046\n",
      "[Run 3] Ep 05/40 | Train Acc: 0.243 | Val Acc: 0.200 | Train Loss: 2.5899 | Val Loss: 3.1046\n",
      "[Run 3] Ep 06/40 | Train Acc: 0.314 | Val Acc: 0.307 | Train Loss: 2.3783 | Val Loss: 2.7760\n",
      "[Run 3] Ep 06/40 | Train Acc: 0.314 | Val Acc: 0.307 | Train Loss: 2.3783 | Val Loss: 2.7760\n",
      "[Run 3] Ep 07/40 | Train Acc: 0.332 | Val Acc: 0.400 | Train Loss: 2.2143 | Val Loss: 2.3846\n",
      "[Run 3] Ep 07/40 | Train Acc: 0.332 | Val Acc: 0.400 | Train Loss: 2.2143 | Val Loss: 2.3846\n",
      "[Run 3] Ep 08/40 | Train Acc: 0.402 | Val Acc: 0.297 | Train Loss: 2.0262 | Val Loss: 2.3567\n",
      "[Run 3] Ep 08/40 | Train Acc: 0.402 | Val Acc: 0.297 | Train Loss: 2.0262 | Val Loss: 2.3567\n",
      "[Run 3] Ep 09/40 | Train Acc: 0.454 | Val Acc: 0.423 | Train Loss: 1.7551 | Val Loss: 2.0516\n",
      "[Run 3] Ep 09/40 | Train Acc: 0.454 | Val Acc: 0.423 | Train Loss: 1.7551 | Val Loss: 2.0516\n",
      "[Run 3] Ep 10/40 | Train Acc: 0.498 | Val Acc: 0.433 | Train Loss: 1.6538 | Val Loss: 1.8325\n",
      "[Run 3] Ep 10/40 | Train Acc: 0.498 | Val Acc: 0.433 | Train Loss: 1.6538 | Val Loss: 1.8325\n",
      "[Run 3] Ep 11/40 | Train Acc: 0.528 | Val Acc: 0.537 | Train Loss: 1.5684 | Val Loss: 1.7345\n",
      "[Run 3] Ep 11/40 | Train Acc: 0.528 | Val Acc: 0.537 | Train Loss: 1.5684 | Val Loss: 1.7345\n",
      "[Run 3] Ep 12/40 | Train Acc: 0.556 | Val Acc: 0.520 | Train Loss: 1.4338 | Val Loss: 1.7030\n",
      "[Run 3] Ep 12/40 | Train Acc: 0.556 | Val Acc: 0.520 | Train Loss: 1.4338 | Val Loss: 1.7030\n",
      "[Run 3] Ep 13/40 | Train Acc: 0.569 | Val Acc: 0.487 | Train Loss: 1.3822 | Val Loss: 1.7980\n",
      "[Run 3] Ep 13/40 | Train Acc: 0.569 | Val Acc: 0.487 | Train Loss: 1.3822 | Val Loss: 1.7980\n",
      "[Run 3] Ep 14/40 | Train Acc: 0.576 | Val Acc: 0.453 | Train Loss: 1.3358 | Val Loss: 1.8491\n",
      "[Run 3] Ep 14/40 | Train Acc: 0.576 | Val Acc: 0.453 | Train Loss: 1.3358 | Val Loss: 1.8491\n",
      "[Run 3] Ep 15/40 | Train Acc: 0.627 | Val Acc: 0.563 | Train Loss: 1.2351 | Val Loss: 1.5498\n",
      "[Run 3] Ep 15/40 | Train Acc: 0.627 | Val Acc: 0.563 | Train Loss: 1.2351 | Val Loss: 1.5498\n",
      "[Run 3] Ep 16/40 | Train Acc: 0.650 | Val Acc: 0.567 | Train Loss: 1.1463 | Val Loss: 1.5036\n",
      "[Run 3] Ep 16/40 | Train Acc: 0.650 | Val Acc: 0.567 | Train Loss: 1.1463 | Val Loss: 1.5036\n",
      "[Run 3] Ep 17/40 | Train Acc: 0.725 | Val Acc: 0.590 | Train Loss: 0.9127 | Val Loss: 1.3837\n",
      "[Run 3] Ep 17/40 | Train Acc: 0.725 | Val Acc: 0.590 | Train Loss: 0.9127 | Val Loss: 1.3837\n",
      "[Run 3] Ep 18/40 | Train Acc: 0.757 | Val Acc: 0.627 | Train Loss: 0.8328 | Val Loss: 1.3330\n",
      "[Run 3] Ep 18/40 | Train Acc: 0.757 | Val Acc: 0.627 | Train Loss: 0.8328 | Val Loss: 1.3330\n",
      "[Run 3] Ep 19/40 | Train Acc: 0.764 | Val Acc: 0.630 | Train Loss: 0.7942 | Val Loss: 1.4475\n",
      "[Run 3] Ep 19/40 | Train Acc: 0.764 | Val Acc: 0.630 | Train Loss: 0.7942 | Val Loss: 1.4475\n",
      "[Run 3] Ep 20/40 | Train Acc: 0.764 | Val Acc: 0.647 | Train Loss: 0.7316 | Val Loss: 1.2600\n",
      "[Run 3] Ep 20/40 | Train Acc: 0.764 | Val Acc: 0.647 | Train Loss: 0.7316 | Val Loss: 1.2600\n",
      "[Run 3] Ep 21/40 | Train Acc: 0.791 | Val Acc: 0.623 | Train Loss: 0.6978 | Val Loss: 1.4735\n",
      "[Run 3] Ep 21/40 | Train Acc: 0.791 | Val Acc: 0.623 | Train Loss: 0.6978 | Val Loss: 1.4735\n",
      "[Run 3] Ep 22/40 | Train Acc: 0.786 | Val Acc: 0.547 | Train Loss: 0.7152 | Val Loss: 1.9471\n",
      "[Run 3] Ep 22/40 | Train Acc: 0.786 | Val Acc: 0.547 | Train Loss: 0.7152 | Val Loss: 1.9471\n",
      "[Run 3] Ep 23/40 | Train Acc: 0.802 | Val Acc: 0.647 | Train Loss: 0.6555 | Val Loss: 1.3256\n",
      "[Run 3] Ep 23/40 | Train Acc: 0.802 | Val Acc: 0.647 | Train Loss: 0.6555 | Val Loss: 1.3256\n",
      "[Run 3] Ep 24/40 | Train Acc: 0.816 | Val Acc: 0.613 | Train Loss: 0.6139 | Val Loss: 1.5958\n",
      "[Run 3] Ep 24/40 | Train Acc: 0.816 | Val Acc: 0.613 | Train Loss: 0.6139 | Val Loss: 1.5958\n",
      "[Run 3] Ep 25/40 | Train Acc: 0.870 | Val Acc: 0.703 | Train Loss: 0.4702 | Val Loss: 1.1249\n",
      "[Run 3] Ep 25/40 | Train Acc: 0.870 | Val Acc: 0.703 | Train Loss: 0.4702 | Val Loss: 1.1249\n",
      "[Run 3] Ep 26/40 | Train Acc: 0.891 | Val Acc: 0.707 | Train Loss: 0.4132 | Val Loss: 1.2324\n",
      "[Run 3] Ep 26/40 | Train Acc: 0.891 | Val Acc: 0.707 | Train Loss: 0.4132 | Val Loss: 1.2324\n",
      "[Run 3] Ep 27/40 | Train Acc: 0.881 | Val Acc: 0.637 | Train Loss: 0.3893 | Val Loss: 1.3209\n",
      "[Run 3] Ep 27/40 | Train Acc: 0.881 | Val Acc: 0.637 | Train Loss: 0.3893 | Val Loss: 1.3209\n",
      "[Run 3] Ep 28/40 | Train Acc: 0.897 | Val Acc: 0.647 | Train Loss: 0.3917 | Val Loss: 1.2711\n",
      "[Run 3] Ep 28/40 | Train Acc: 0.897 | Val Acc: 0.647 | Train Loss: 0.3917 | Val Loss: 1.2711\n",
      "[Run 3] Ep 29/40 | Train Acc: 0.912 | Val Acc: 0.707 | Train Loss: 0.3575 | Val Loss: 1.1803\n",
      "[Run 3] Ep 29/40 | Train Acc: 0.912 | Val Acc: 0.707 | Train Loss: 0.3575 | Val Loss: 1.1803\n",
      "[Run 3] Ep 30/40 | Train Acc: 0.923 | Val Acc: 0.657 | Train Loss: 0.2943 | Val Loss: 1.2981\n",
      "[Run 3] Ep 30/40 | Train Acc: 0.923 | Val Acc: 0.657 | Train Loss: 0.2943 | Val Loss: 1.2981\n",
      "[Run 3] Ep 31/40 | Train Acc: 0.931 | Val Acc: 0.700 | Train Loss: 0.2788 | Val Loss: 1.1482\n",
      "[Run 3] Ep 31/40 | Train Acc: 0.931 | Val Acc: 0.700 | Train Loss: 0.2788 | Val Loss: 1.1482\n",
      "[Run 3] Ep 32/40 | Train Acc: 0.933 | Val Acc: 0.693 | Train Loss: 0.2601 | Val Loss: 1.1324\n",
      "[Run 3] Ep 32/40 | Train Acc: 0.933 | Val Acc: 0.693 | Train Loss: 0.2601 | Val Loss: 1.1324\n",
      "[Run 3] Ep 33/40 | Train Acc: 0.950 | Val Acc: 0.697 | Train Loss: 0.2267 | Val Loss: 1.0828\n",
      "[Run 3] Early stopping en epoch 33.\n",
      "✅ [Run 3] Mejor Val Acc: 0.707\n",
      "[Run 3] Ep 33/40 | Train Acc: 0.950 | Val Acc: 0.697 | Train Loss: 0.2267 | Val Loss: 1.0828\n",
      "[Run 3] Early stopping en epoch 33.\n",
      "✅ [Run 3] Mejor Val Acc: 0.707\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇█▇██████</td></tr><tr><td>train_loss</td><td>█▇▇▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▂▄▅▄▅▅▆▆▆▅▆▆▇▇▇▇▇▆▇▇██▇▇█▇███</td></tr><tr><td>val_f1_macro</td><td>▁▁▂▃▂▄▅▃▅▅▆▆▆▅▆▆▇▇▇▇▇▆▇▇██▇▇█▇███</td></tr><tr><td>val_f1_weighted</td><td>▁▁▂▃▂▄▅▃▅▅▆▆▆▅▆▆▇▇▇▇▇▆▇▇██▇▇█▇███</td></tr><tr><td>val_loss</td><td>█▇▇▅▇▆▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▃▂▂▁▁▂▂▁▂▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▂▃▂▄▅▄▆▆▆▆▆▆▇▇▇▇▇█▇▇█████▇█████</td></tr><tr><td>val_recall_macro</td><td>▁▁▂▃▂▄▅▄▅▅▆▆▆▅▆▆▇▇▇▇▇▆▇▇██▇▇█▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.70667</td></tr><tr><td>epoch</td><td>33</td></tr><tr><td>lr</td><td>0.0024</td></tr><tr><td>train_acc</td><td>0.95</td></tr><tr><td>train_loss</td><td>0.22666</td></tr><tr><td>val_acc</td><td>0.69667</td></tr><tr><td>val_f1_macro</td><td>0.69614</td></tr><tr><td>val_f1_weighted</td><td>0.69614</td></tr><tr><td>val_loss</td><td>1.08284</td></tr><tr><td>val_precision_macro</td><td>0.74075</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br><code>wandb sync /home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/offline-run-20251027_220959-ev95eteb<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20251027_220959-ev95eteb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Iniciando experimento 4 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/offline-run-20251027_224651-dw9hpx9h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Ep 01/40 | Train Acc: 0.049 | Val Acc: 0.057 | Train Loss: 3.8718 | Val Loss: 3.7734\n",
      "[Run 4] Ep 02/40 | Train Acc: 0.110 | Val Acc: 0.137 | Train Loss: 3.2791 | Val Loss: 3.0903\n",
      "[Run 4] Ep 02/40 | Train Acc: 0.110 | Val Acc: 0.137 | Train Loss: 3.2791 | Val Loss: 3.0903\n",
      "[Run 4] Ep 03/40 | Train Acc: 0.174 | Val Acc: 0.223 | Train Loss: 2.9337 | Val Loss: 2.8399\n",
      "[Run 4] Ep 03/40 | Train Acc: 0.174 | Val Acc: 0.223 | Train Loss: 2.9337 | Val Loss: 2.8399\n",
      "[Run 4] Ep 04/40 | Train Acc: 0.199 | Val Acc: 0.197 | Train Loss: 2.7773 | Val Loss: 3.1860\n",
      "[Run 4] Ep 04/40 | Train Acc: 0.199 | Val Acc: 0.197 | Train Loss: 2.7773 | Val Loss: 3.1860\n",
      "[Run 4] Ep 05/40 | Train Acc: 0.278 | Val Acc: 0.277 | Train Loss: 2.4990 | Val Loss: 2.8326\n",
      "[Run 4] Ep 05/40 | Train Acc: 0.278 | Val Acc: 0.277 | Train Loss: 2.4990 | Val Loss: 2.8326\n",
      "[Run 4] Ep 06/40 | Train Acc: 0.293 | Val Acc: 0.373 | Train Loss: 2.3815 | Val Loss: 2.2385\n",
      "[Run 4] Ep 06/40 | Train Acc: 0.293 | Val Acc: 0.373 | Train Loss: 2.3815 | Val Loss: 2.2385\n",
      "[Run 4] Ep 07/40 | Train Acc: 0.342 | Val Acc: 0.343 | Train Loss: 2.1868 | Val Loss: 2.4115\n",
      "[Run 4] Ep 07/40 | Train Acc: 0.342 | Val Acc: 0.343 | Train Loss: 2.1868 | Val Loss: 2.4115\n",
      "[Run 4] Ep 08/40 | Train Acc: 0.364 | Val Acc: 0.390 | Train Loss: 2.0779 | Val Loss: 2.0681\n",
      "[Run 4] Ep 08/40 | Train Acc: 0.364 | Val Acc: 0.390 | Train Loss: 2.0779 | Val Loss: 2.0681\n",
      "[Run 4] Ep 09/40 | Train Acc: 0.459 | Val Acc: 0.433 | Train Loss: 1.8353 | Val Loss: 2.0680\n",
      "[Run 4] Ep 09/40 | Train Acc: 0.459 | Val Acc: 0.433 | Train Loss: 1.8353 | Val Loss: 2.0680\n",
      "[Run 4] Ep 10/40 | Train Acc: 0.476 | Val Acc: 0.417 | Train Loss: 1.7070 | Val Loss: 1.9406\n",
      "[Run 4] Ep 10/40 | Train Acc: 0.476 | Val Acc: 0.417 | Train Loss: 1.7070 | Val Loss: 1.9406\n",
      "[Run 4] Ep 11/40 | Train Acc: 0.493 | Val Acc: 0.450 | Train Loss: 1.6625 | Val Loss: 1.9004\n",
      "[Run 4] Ep 11/40 | Train Acc: 0.493 | Val Acc: 0.450 | Train Loss: 1.6625 | Val Loss: 1.9004\n",
      "[Run 4] Ep 12/40 | Train Acc: 0.559 | Val Acc: 0.443 | Train Loss: 1.5111 | Val Loss: 1.9374\n",
      "[Run 4] Ep 12/40 | Train Acc: 0.559 | Val Acc: 0.443 | Train Loss: 1.5111 | Val Loss: 1.9374\n",
      "[Run 4] Ep 13/40 | Train Acc: 0.551 | Val Acc: 0.400 | Train Loss: 1.4442 | Val Loss: 2.0997\n",
      "[Run 4] Ep 13/40 | Train Acc: 0.551 | Val Acc: 0.400 | Train Loss: 1.4442 | Val Loss: 2.0997\n",
      "[Run 4] Ep 14/40 | Train Acc: 0.565 | Val Acc: 0.563 | Train Loss: 1.4130 | Val Loss: 1.5229\n",
      "[Run 4] Ep 14/40 | Train Acc: 0.565 | Val Acc: 0.563 | Train Loss: 1.4130 | Val Loss: 1.5229\n",
      "[Run 4] Ep 15/40 | Train Acc: 0.586 | Val Acc: 0.503 | Train Loss: 1.3099 | Val Loss: 1.6995\n",
      "[Run 4] Ep 15/40 | Train Acc: 0.586 | Val Acc: 0.503 | Train Loss: 1.3099 | Val Loss: 1.6995\n",
      "[Run 4] Ep 16/40 | Train Acc: 0.623 | Val Acc: 0.570 | Train Loss: 1.2172 | Val Loss: 1.4864\n",
      "[Run 4] Ep 16/40 | Train Acc: 0.623 | Val Acc: 0.570 | Train Loss: 1.2172 | Val Loss: 1.4864\n",
      "[Run 4] Ep 17/40 | Train Acc: 0.685 | Val Acc: 0.573 | Train Loss: 1.0531 | Val Loss: 1.4535\n",
      "[Run 4] Ep 17/40 | Train Acc: 0.685 | Val Acc: 0.573 | Train Loss: 1.0531 | Val Loss: 1.4535\n",
      "[Run 4] Ep 18/40 | Train Acc: 0.711 | Val Acc: 0.577 | Train Loss: 0.9513 | Val Loss: 1.4419\n",
      "[Run 4] Ep 18/40 | Train Acc: 0.711 | Val Acc: 0.577 | Train Loss: 0.9513 | Val Loss: 1.4419\n",
      "[Run 4] Ep 19/40 | Train Acc: 0.723 | Val Acc: 0.607 | Train Loss: 0.9190 | Val Loss: 1.3898\n",
      "[Run 4] Ep 19/40 | Train Acc: 0.723 | Val Acc: 0.607 | Train Loss: 0.9190 | Val Loss: 1.3898\n",
      "[Run 4] Ep 20/40 | Train Acc: 0.734 | Val Acc: 0.593 | Train Loss: 0.8861 | Val Loss: 1.5084\n",
      "[Run 4] Ep 20/40 | Train Acc: 0.734 | Val Acc: 0.593 | Train Loss: 0.8861 | Val Loss: 1.5084\n",
      "[Run 4] Ep 21/40 | Train Acc: 0.764 | Val Acc: 0.617 | Train Loss: 0.8004 | Val Loss: 1.3440\n",
      "[Run 4] Ep 21/40 | Train Acc: 0.764 | Val Acc: 0.617 | Train Loss: 0.8004 | Val Loss: 1.3440\n",
      "[Run 4] Ep 22/40 | Train Acc: 0.758 | Val Acc: 0.527 | Train Loss: 0.8270 | Val Loss: 1.6021\n",
      "[Run 4] Ep 22/40 | Train Acc: 0.758 | Val Acc: 0.527 | Train Loss: 0.8270 | Val Loss: 1.6021\n",
      "[Run 4] Ep 23/40 | Train Acc: 0.779 | Val Acc: 0.543 | Train Loss: 0.7339 | Val Loss: 1.6664\n",
      "[Run 4] Ep 23/40 | Train Acc: 0.779 | Val Acc: 0.543 | Train Loss: 0.7339 | Val Loss: 1.6664\n",
      "[Run 4] Ep 24/40 | Train Acc: 0.794 | Val Acc: 0.607 | Train Loss: 0.6898 | Val Loss: 1.4627\n",
      "[Run 4] Ep 24/40 | Train Acc: 0.794 | Val Acc: 0.607 | Train Loss: 0.6898 | Val Loss: 1.4627\n",
      "[Run 4] Ep 25/40 | Train Acc: 0.840 | Val Acc: 0.637 | Train Loss: 0.5736 | Val Loss: 1.2043\n",
      "[Run 4] Ep 25/40 | Train Acc: 0.840 | Val Acc: 0.637 | Train Loss: 0.5736 | Val Loss: 1.2043\n",
      "[Run 4] Ep 26/40 | Train Acc: 0.854 | Val Acc: 0.660 | Train Loss: 0.5398 | Val Loss: 1.1850\n",
      "[Run 4] Ep 26/40 | Train Acc: 0.854 | Val Acc: 0.660 | Train Loss: 0.5398 | Val Loss: 1.1850\n",
      "[Run 4] Ep 27/40 | Train Acc: 0.849 | Val Acc: 0.680 | Train Loss: 0.5271 | Val Loss: 1.1833\n",
      "[Run 4] Ep 27/40 | Train Acc: 0.849 | Val Acc: 0.680 | Train Loss: 0.5271 | Val Loss: 1.1833\n",
      "[Run 4] Ep 28/40 | Train Acc: 0.875 | Val Acc: 0.663 | Train Loss: 0.4601 | Val Loss: 1.3435\n",
      "[Run 4] Ep 28/40 | Train Acc: 0.875 | Val Acc: 0.663 | Train Loss: 0.4601 | Val Loss: 1.3435\n",
      "[Run 4] Ep 29/40 | Train Acc: 0.890 | Val Acc: 0.657 | Train Loss: 0.4438 | Val Loss: 1.3256\n",
      "[Run 4] Ep 29/40 | Train Acc: 0.890 | Val Acc: 0.657 | Train Loss: 0.4438 | Val Loss: 1.3256\n",
      "[Run 4] Ep 30/40 | Train Acc: 0.889 | Val Acc: 0.673 | Train Loss: 0.4353 | Val Loss: 1.2423\n",
      "[Run 4] Ep 30/40 | Train Acc: 0.889 | Val Acc: 0.673 | Train Loss: 0.4353 | Val Loss: 1.2423\n",
      "[Run 4] Ep 31/40 | Train Acc: 0.905 | Val Acc: 0.703 | Train Loss: 0.3980 | Val Loss: 1.2073\n",
      "[Run 4] Ep 31/40 | Train Acc: 0.905 | Val Acc: 0.703 | Train Loss: 0.3980 | Val Loss: 1.2073\n",
      "[Run 4] Ep 32/40 | Train Acc: 0.916 | Val Acc: 0.700 | Train Loss: 0.3517 | Val Loss: 1.1849\n",
      "[Run 4] Ep 32/40 | Train Acc: 0.916 | Val Acc: 0.700 | Train Loss: 0.3517 | Val Loss: 1.1849\n",
      "[Run 4] Ep 33/40 | Train Acc: 0.925 | Val Acc: 0.737 | Train Loss: 0.3107 | Val Loss: 0.9866\n",
      "[Run 4] Ep 33/40 | Train Acc: 0.925 | Val Acc: 0.737 | Train Loss: 0.3107 | Val Loss: 0.9866\n",
      "[Run 4] Ep 34/40 | Train Acc: 0.927 | Val Acc: 0.743 | Train Loss: 0.2914 | Val Loss: 1.0695\n",
      "[Run 4] Ep 34/40 | Train Acc: 0.927 | Val Acc: 0.743 | Train Loss: 0.2914 | Val Loss: 1.0695\n",
      "[Run 4] Ep 35/40 | Train Acc: 0.944 | Val Acc: 0.760 | Train Loss: 0.2645 | Val Loss: 0.9497\n",
      "[Run 4] Ep 35/40 | Train Acc: 0.944 | Val Acc: 0.760 | Train Loss: 0.2645 | Val Loss: 0.9497\n",
      "[Run 4] Ep 36/40 | Train Acc: 0.944 | Val Acc: 0.747 | Train Loss: 0.2518 | Val Loss: 1.0240\n",
      "[Run 4] Ep 36/40 | Train Acc: 0.944 | Val Acc: 0.747 | Train Loss: 0.2518 | Val Loss: 1.0240\n",
      "[Run 4] Ep 37/40 | Train Acc: 0.947 | Val Acc: 0.703 | Train Loss: 0.2572 | Val Loss: 1.1118\n",
      "[Run 4] Ep 37/40 | Train Acc: 0.947 | Val Acc: 0.703 | Train Loss: 0.2572 | Val Loss: 1.1118\n",
      "[Run 4] Ep 38/40 | Train Acc: 0.958 | Val Acc: 0.740 | Train Loss: 0.2340 | Val Loss: 1.0126\n",
      "[Run 4] Ep 38/40 | Train Acc: 0.958 | Val Acc: 0.740 | Train Loss: 0.2340 | Val Loss: 1.0126\n",
      "[Run 4] Ep 39/40 | Train Acc: 0.960 | Val Acc: 0.707 | Train Loss: 0.2187 | Val Loss: 1.1726\n",
      "[Run 4] Ep 39/40 | Train Acc: 0.960 | Val Acc: 0.707 | Train Loss: 0.2187 | Val Loss: 1.1726\n",
      "[Run 4] Ep 40/40 | Train Acc: 0.968 | Val Acc: 0.697 | Train Loss: 0.2037 | Val Loss: 1.0754\n",
      "✅ [Run 4] Mejor Val Acc: 0.760\n",
      "[Run 4] Ep 40/40 | Train Acc: 0.968 | Val Acc: 0.697 | Train Loss: 0.2037 | Val Loss: 1.0754\n",
      "✅ [Run 4] Mejor Val Acc: 0.760\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▂▃▄▄▄▅▅▅▅▄▆▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇████▇█▇▇</td></tr><tr><td>val_f1_macro</td><td>▁▂▂▂▃▄▄▄▅▄▅▅▄▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████▇█▇▇</td></tr><tr><td>val_f1_weighted</td><td>▁▂▂▂▃▄▄▄▅▄▅▅▄▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████▇█▇▇</td></tr><tr><td>val_loss</td><td>█▆▆▇▆▄▅▄▄▃▃▃▄▂▃▂▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁</td></tr><tr><td>val_precision_macro</td><td>▁▂▂▂▄▄▄▄▅▅▆▅▆▆▆▆▆▇▇▇▇▆▆▇▇▇█▇█▇█▇████▇██▇</td></tr><tr><td>val_recall_macro</td><td>▁▂▃▂▃▄▄▄▅▅▅▅▄▆▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇████▇█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.76</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00084</td></tr><tr><td>train_acc</td><td>0.96786</td></tr><tr><td>train_loss</td><td>0.20368</td></tr><tr><td>val_acc</td><td>0.69667</td></tr><tr><td>val_f1_macro</td><td>0.69227</td></tr><tr><td>val_f1_weighted</td><td>0.69227</td></tr><tr><td>val_loss</td><td>1.07535</td></tr><tr><td>val_precision_macro</td><td>0.7246</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br><code>wandb sync /home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/offline-run-20251027_224651-dw9hpx9h<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20251027_224651-dw9hpx9h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Iniciando experimento 5 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/offline-run-20251027_233141-qhg5vto3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Ep 01/40 | Train Acc: 0.085 | Val Acc: 0.143 | Train Loss: 3.4951 | Val Loss: 3.1591\n",
      "[Run 5] Ep 02/40 | Train Acc: 0.156 | Val Acc: 0.200 | Train Loss: 2.9497 | Val Loss: 2.7942\n",
      "[Run 5] Ep 02/40 | Train Acc: 0.156 | Val Acc: 0.200 | Train Loss: 2.9497 | Val Loss: 2.7942\n",
      "[Run 5] Ep 03/40 | Train Acc: 0.208 | Val Acc: 0.247 | Train Loss: 2.7928 | Val Loss: 2.7179\n",
      "[Run 5] Ep 03/40 | Train Acc: 0.208 | Val Acc: 0.247 | Train Loss: 2.7928 | Val Loss: 2.7179\n",
      "[Run 5] Ep 04/40 | Train Acc: 0.250 | Val Acc: 0.283 | Train Loss: 2.5605 | Val Loss: 2.4131\n",
      "[Run 5] Ep 04/40 | Train Acc: 0.250 | Val Acc: 0.283 | Train Loss: 2.5605 | Val Loss: 2.4131\n",
      "[Run 5] Ep 05/40 | Train Acc: 0.283 | Val Acc: 0.320 | Train Loss: 2.4381 | Val Loss: 2.4872\n",
      "[Run 5] Ep 05/40 | Train Acc: 0.283 | Val Acc: 0.320 | Train Loss: 2.4381 | Val Loss: 2.4872\n",
      "[Run 5] Ep 06/40 | Train Acc: 0.334 | Val Acc: 0.250 | Train Loss: 2.2161 | Val Loss: 2.7545\n",
      "[Run 5] Ep 06/40 | Train Acc: 0.334 | Val Acc: 0.250 | Train Loss: 2.2161 | Val Loss: 2.7545\n",
      "[Run 5] Ep 07/40 | Train Acc: 0.361 | Val Acc: 0.337 | Train Loss: 2.1088 | Val Loss: 2.1822\n",
      "[Run 5] Ep 07/40 | Train Acc: 0.361 | Val Acc: 0.337 | Train Loss: 2.1088 | Val Loss: 2.1822\n",
      "[Run 5] Ep 08/40 | Train Acc: 0.419 | Val Acc: 0.477 | Train Loss: 1.9348 | Val Loss: 1.8996\n",
      "[Run 5] Ep 08/40 | Train Acc: 0.419 | Val Acc: 0.477 | Train Loss: 1.9348 | Val Loss: 1.8996\n",
      "[Run 5] Ep 09/40 | Train Acc: 0.479 | Val Acc: 0.420 | Train Loss: 1.7477 | Val Loss: 1.8735\n",
      "[Run 5] Ep 09/40 | Train Acc: 0.479 | Val Acc: 0.420 | Train Loss: 1.7477 | Val Loss: 1.8735\n",
      "[Run 5] Ep 10/40 | Train Acc: 0.531 | Val Acc: 0.530 | Train Loss: 1.6250 | Val Loss: 1.6791\n",
      "[Run 5] Ep 10/40 | Train Acc: 0.531 | Val Acc: 0.530 | Train Loss: 1.6250 | Val Loss: 1.6791\n",
      "[Run 5] Ep 11/40 | Train Acc: 0.516 | Val Acc: 0.493 | Train Loss: 1.6278 | Val Loss: 1.8272\n",
      "[Run 5] Ep 11/40 | Train Acc: 0.516 | Val Acc: 0.493 | Train Loss: 1.6278 | Val Loss: 1.8272\n",
      "[Run 5] Ep 12/40 | Train Acc: 0.581 | Val Acc: 0.480 | Train Loss: 1.4414 | Val Loss: 1.7191\n",
      "[Run 5] Ep 12/40 | Train Acc: 0.581 | Val Acc: 0.480 | Train Loss: 1.4414 | Val Loss: 1.7191\n",
      "[Run 5] Ep 13/40 | Train Acc: 0.566 | Val Acc: 0.540 | Train Loss: 1.3893 | Val Loss: 1.5679\n",
      "[Run 5] Ep 13/40 | Train Acc: 0.566 | Val Acc: 0.540 | Train Loss: 1.3893 | Val Loss: 1.5679\n",
      "[Run 5] Ep 14/40 | Train Acc: 0.602 | Val Acc: 0.550 | Train Loss: 1.3615 | Val Loss: 1.5107\n",
      "[Run 5] Ep 14/40 | Train Acc: 0.602 | Val Acc: 0.550 | Train Loss: 1.3615 | Val Loss: 1.5107\n",
      "[Run 5] Ep 15/40 | Train Acc: 0.630 | Val Acc: 0.457 | Train Loss: 1.2305 | Val Loss: 2.0493\n",
      "[Run 5] Ep 15/40 | Train Acc: 0.630 | Val Acc: 0.457 | Train Loss: 1.2305 | Val Loss: 2.0493\n",
      "[Run 5] Ep 16/40 | Train Acc: 0.626 | Val Acc: 0.557 | Train Loss: 1.2181 | Val Loss: 1.5318\n",
      "[Run 5] Ep 16/40 | Train Acc: 0.626 | Val Acc: 0.557 | Train Loss: 1.2181 | Val Loss: 1.5318\n",
      "[Run 5] Ep 17/40 | Train Acc: 0.699 | Val Acc: 0.403 | Train Loss: 1.0539 | Val Loss: 3.1636\n",
      "[Run 5] Ep 17/40 | Train Acc: 0.699 | Val Acc: 0.403 | Train Loss: 1.0539 | Val Loss: 3.1636\n",
      "[Run 5] Ep 18/40 | Train Acc: 0.709 | Val Acc: 0.653 | Train Loss: 1.0050 | Val Loss: 1.2486\n",
      "[Run 5] Ep 18/40 | Train Acc: 0.709 | Val Acc: 0.653 | Train Loss: 1.0050 | Val Loss: 1.2486\n",
      "[Run 5] Ep 19/40 | Train Acc: 0.731 | Val Acc: 0.587 | Train Loss: 0.9378 | Val Loss: 1.4789\n",
      "[Run 5] Ep 19/40 | Train Acc: 0.731 | Val Acc: 0.587 | Train Loss: 0.9378 | Val Loss: 1.4789\n",
      "[Run 5] Ep 20/40 | Train Acc: 0.725 | Val Acc: 0.647 | Train Loss: 0.9536 | Val Loss: 1.1983\n",
      "[Run 5] Ep 20/40 | Train Acc: 0.725 | Val Acc: 0.647 | Train Loss: 0.9536 | Val Loss: 1.1983\n",
      "[Run 5] Ep 21/40 | Train Acc: 0.732 | Val Acc: 0.623 | Train Loss: 0.8884 | Val Loss: 1.3944\n",
      "[Run 5] Ep 21/40 | Train Acc: 0.732 | Val Acc: 0.623 | Train Loss: 0.8884 | Val Loss: 1.3944\n",
      "[Run 5] Ep 22/40 | Train Acc: 0.771 | Val Acc: 0.633 | Train Loss: 0.8093 | Val Loss: 1.3189\n",
      "[Run 5] Ep 22/40 | Train Acc: 0.771 | Val Acc: 0.633 | Train Loss: 0.8093 | Val Loss: 1.3189\n",
      "[Run 5] Ep 23/40 | Train Acc: 0.754 | Val Acc: 0.623 | Train Loss: 0.8233 | Val Loss: 1.3177\n",
      "[Run 5] Ep 23/40 | Train Acc: 0.754 | Val Acc: 0.623 | Train Loss: 0.8233 | Val Loss: 1.3177\n",
      "[Run 5] Ep 24/40 | Train Acc: 0.793 | Val Acc: 0.647 | Train Loss: 0.7507 | Val Loss: 1.1988\n",
      "[Run 5] Ep 24/40 | Train Acc: 0.793 | Val Acc: 0.647 | Train Loss: 0.7507 | Val Loss: 1.1988\n",
      "[Run 5] Ep 25/40 | Train Acc: 0.813 | Val Acc: 0.687 | Train Loss: 0.6763 | Val Loss: 1.0842\n",
      "[Run 5] Ep 25/40 | Train Acc: 0.813 | Val Acc: 0.687 | Train Loss: 0.6763 | Val Loss: 1.0842\n",
      "[Run 5] Ep 26/40 | Train Acc: 0.843 | Val Acc: 0.690 | Train Loss: 0.6032 | Val Loss: 1.1136\n",
      "[Run 5] Ep 26/40 | Train Acc: 0.843 | Val Acc: 0.690 | Train Loss: 0.6032 | Val Loss: 1.1136\n",
      "[Run 5] Ep 27/40 | Train Acc: 0.830 | Val Acc: 0.620 | Train Loss: 0.5884 | Val Loss: 1.4255\n",
      "[Run 5] Ep 27/40 | Train Acc: 0.830 | Val Acc: 0.620 | Train Loss: 0.5884 | Val Loss: 1.4255\n",
      "[Run 5] Ep 28/40 | Train Acc: 0.832 | Val Acc: 0.653 | Train Loss: 0.6008 | Val Loss: 1.2522\n",
      "[Run 5] Ep 28/40 | Train Acc: 0.832 | Val Acc: 0.653 | Train Loss: 0.6008 | Val Loss: 1.2522\n",
      "[Run 5] Ep 29/40 | Train Acc: 0.860 | Val Acc: 0.673 | Train Loss: 0.5470 | Val Loss: 1.1155\n",
      "[Run 5] Ep 29/40 | Train Acc: 0.860 | Val Acc: 0.673 | Train Loss: 0.5470 | Val Loss: 1.1155\n",
      "[Run 5] Ep 30/40 | Train Acc: 0.871 | Val Acc: 0.693 | Train Loss: 0.5245 | Val Loss: 1.0840\n",
      "[Run 5] Ep 30/40 | Train Acc: 0.871 | Val Acc: 0.693 | Train Loss: 0.5245 | Val Loss: 1.0840\n",
      "[Run 5] Ep 31/40 | Train Acc: 0.885 | Val Acc: 0.713 | Train Loss: 0.4714 | Val Loss: 1.0551\n",
      "[Run 5] Ep 31/40 | Train Acc: 0.885 | Val Acc: 0.713 | Train Loss: 0.4714 | Val Loss: 1.0551\n",
      "[Run 5] Ep 32/40 | Train Acc: 0.874 | Val Acc: 0.637 | Train Loss: 0.4909 | Val Loss: 1.2485\n",
      "[Run 5] Ep 32/40 | Train Acc: 0.874 | Val Acc: 0.637 | Train Loss: 0.4909 | Val Loss: 1.2485\n",
      "[Run 5] Ep 33/40 | Train Acc: 0.901 | Val Acc: 0.707 | Train Loss: 0.4111 | Val Loss: 1.0512\n",
      "[Run 5] Ep 33/40 | Train Acc: 0.901 | Val Acc: 0.707 | Train Loss: 0.4111 | Val Loss: 1.0512\n",
      "[Run 5] Ep 34/40 | Train Acc: 0.916 | Val Acc: 0.700 | Train Loss: 0.3749 | Val Loss: 1.0303\n",
      "[Run 5] Ep 34/40 | Train Acc: 0.916 | Val Acc: 0.700 | Train Loss: 0.3749 | Val Loss: 1.0303\n",
      "[Run 5] Ep 35/40 | Train Acc: 0.923 | Val Acc: 0.713 | Train Loss: 0.3559 | Val Loss: 0.9574\n",
      "[Run 5] Ep 35/40 | Train Acc: 0.923 | Val Acc: 0.713 | Train Loss: 0.3559 | Val Loss: 0.9574\n",
      "[Run 5] Ep 36/40 | Train Acc: 0.934 | Val Acc: 0.700 | Train Loss: 0.3317 | Val Loss: 1.1320\n",
      "[Run 5] Ep 36/40 | Train Acc: 0.934 | Val Acc: 0.700 | Train Loss: 0.3317 | Val Loss: 1.1320\n",
      "[Run 5] Ep 37/40 | Train Acc: 0.932 | Val Acc: 0.690 | Train Loss: 0.3218 | Val Loss: 1.0903\n",
      "[Run 5] Ep 37/40 | Train Acc: 0.932 | Val Acc: 0.690 | Train Loss: 0.3218 | Val Loss: 1.0903\n",
      "[Run 5] Ep 38/40 | Train Acc: 0.931 | Val Acc: 0.697 | Train Loss: 0.3197 | Val Loss: 1.0843\n",
      "[Run 5] Early stopping en epoch 38.\n",
      "✅ [Run 5] Mejor Val Acc: 0.713\n",
      "[Run 5] Ep 38/40 | Train Acc: 0.931 | Val Acc: 0.697 | Train Loss: 0.3197 | Val Loss: 1.0843\n",
      "[Run 5] Early stopping en epoch 38.\n",
      "✅ [Run 5] Mejor Val Acc: 0.713\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▂▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▃▃▂▃▅▄▆▅▅▆▆▅▆▄▇▆▇▇▇▇▇██▇▇███▇██████</td></tr><tr><td>val_f1_macro</td><td>▁▁▂▃▃▂▃▅▄▆▅▅▆▆▅▆▄▇▆▇▇▇▇▇██▇▇███▇██████</td></tr><tr><td>val_f1_weighted</td><td>▁▁▂▃▃▂▃▅▄▆▅▅▆▆▅▆▄▇▆▇▇▇▇▇██▇▇███▇██████</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▇▅▄▄▃▄▃▃▃▄▃█▂▃▂▂▂▂▂▁▁▂▂▂▁▁▂▁▁▁▂▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▃▃▃▂▄▅▅▆▆▆▆▆▅▆▅▇▇▇▇▇▇▇██▇▇██████████</td></tr><tr><td>val_recall_macro</td><td>▁▂▂▃▃▂▃▅▄▆▅▅▆▆▅▆▄▇▆▇▇▇▇▇██▇▇███▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.71333</td></tr><tr><td>epoch</td><td>38</td></tr><tr><td>lr</td><td>0.00012</td></tr><tr><td>train_acc</td><td>0.93143</td></tr><tr><td>train_loss</td><td>0.31975</td></tr><tr><td>val_acc</td><td>0.69667</td></tr><tr><td>val_f1_macro</td><td>0.69116</td></tr><tr><td>val_f1_weighted</td><td>0.69116</td></tr><tr><td>val_loss</td><td>1.08429</td></tr><tr><td>val_precision_macro</td><td>0.72348</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br><code>wandb sync /home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/offline-run-20251027_233141-qhg5vto3<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20251027_233141-qhg5vto3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===========================================\n",
    "# ENTRENAMIENTO - MODELO B (ResNet-18 Audio)\n",
    "# Dataset: data/spectrograms1/base (RAW, sin augment)\n",
    "# Imagen: 228x228\n",
    "# GPU: <= 4 GB compatible\n",
    "# ===========================================\n",
    "\n",
    "import os, random, gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Configuración y utilidades\n",
    "# -----------------------------\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Data (RAW)\n",
    "# -----------------------------\n",
    "DATA_DIR = \"data/spectrograms2/base\"\n",
    "IMG_SIZE = (228, 228)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # [-1,1]\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\",   transform=transform)\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "class_names = train_data.classes\n",
    "print(\"Clases detectadas:\", num_classes)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Experimentos\n",
    "# -----------------------------\n",
    "experiments = [\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 3e-4,  \"batch_size\": 8, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 1e-4,  \"batch_size\": 8, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",   \"lr\": 0.01,  \"batch_size\": 8, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",   \"lr\": 0.005, \"batch_size\": 8, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"AdamW\", \"lr\": 5e-4,  \"batch_size\": 12, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "EPOCHS   = 40\n",
    "PATIENCE = 6\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Loop multi-run\n",
    "# -----------------------------\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    print(f\"\\n===== Iniciando experimento {i} =====\")\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"esc50-modelB_stratified\",\n",
    "        name=f\"resnet18B_run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp,\n",
    "        mode=\"offline\",\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # Modelo (ResNet-18 personalizada)\n",
    "    # -------------------------------\n",
    "    model = resnet18_audio(num_classes=num_classes, in_channels=1, small_input=True).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if config.optimizer == \"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "    scaler = GradScaler('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    # -------------------------------\n",
    "    # Entrenamiento por épocas\n",
    "    # -------------------------------\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            # Limpieza batch\n",
    "            del imgs, labels, outputs, loss, preds\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "\n",
    "        # --------- Validación ---------\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        val_y_true, val_y_pred = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs = imgs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item()\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "                val_y_true.extend(labels.cpu().tolist())\n",
    "                val_y_pred.extend(preds.cpu().tolist())\n",
    "\n",
    "                del imgs, labels, outputs, preds, loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss = val_loss / max(1, len(val_loader))\n",
    "\n",
    "        # --- Métricas adicionales\n",
    "        prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"macro\", zero_division=0\n",
    "        )\n",
    "        prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"weighted\", zero_division=0\n",
    "        )\n",
    "\n",
    "        scheduler.step()\n",
    "        gc.collect()\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1_macro\": f1_m,\n",
    "            \"val_f1_weighted\": f1_w,\n",
    "            \"val_precision_macro\": prec_m,\n",
    "            \"val_recall_macro\": rec_m,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "            \"val_confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                y_true=val_y_true,\n",
    "                preds=val_y_pred,\n",
    "                class_names=class_names\n",
    "            )\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Ep {epoch+1:02d}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # --- Early stopping y guardado\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/MODEL_B_resnet18_audio_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > PATIENCE:\n",
    "                print(f\"[Run {i}] Early stopping en epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "\n",
    "    wandb.finish()\n",
    "    del model, optimizer, scheduler, scaler\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2e509",
   "metadata": {},
   "source": [
    "## Entrenamiento Dataset Augmented Modelo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5965d754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javialroro/miniconda3/envs/ml/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/javialroro/miniconda3/envs/ml/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Clases: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjavialroro\u001b[0m (\u001b[33mjavialroro-tecnologico-de-costa-rica\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_124130-vx6l8e6e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/vx6l8e6e' target=\"_blank\">run_1_opt-Adam_lr-0.001_bs-8</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/vx6l8e6e' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/vx6l8e6e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] Epoch 01/40 | Train Acc: 0.028 | Val Acc: 0.062 | Train Loss: 3.9371 | Val Loss: 3.7019\n",
      "[Run 1] Epoch 02/40 | Train Acc: 0.052 | Val Acc: 0.065 | Train Loss: 3.6587 | Val Loss: 3.5678\n",
      "[Run 1] Epoch 02/40 | Train Acc: 0.052 | Val Acc: 0.065 | Train Loss: 3.6587 | Val Loss: 3.5678\n",
      "[Run 1] Epoch 03/40 | Train Acc: 0.059 | Val Acc: 0.095 | Train Loss: 3.5390 | Val Loss: 3.6986\n",
      "[Run 1] Epoch 03/40 | Train Acc: 0.059 | Val Acc: 0.095 | Train Loss: 3.5390 | Val Loss: 3.6986\n",
      "[Run 1] Epoch 04/40 | Train Acc: 0.114 | Val Acc: 0.125 | Train Loss: 3.2836 | Val Loss: 3.1744\n",
      "[Run 1] Epoch 04/40 | Train Acc: 0.114 | Val Acc: 0.125 | Train Loss: 3.2836 | Val Loss: 3.1744\n",
      "[Run 1] Epoch 05/40 | Train Acc: 0.128 | Val Acc: 0.188 | Train Loss: 3.1629 | Val Loss: 2.9689\n",
      "[Run 1] Epoch 05/40 | Train Acc: 0.128 | Val Acc: 0.188 | Train Loss: 3.1629 | Val Loss: 2.9689\n",
      "[Run 1] Epoch 06/40 | Train Acc: 0.149 | Val Acc: 0.087 | Train Loss: 2.9977 | Val Loss: 4.6198\n",
      "[Run 1] Epoch 06/40 | Train Acc: 0.149 | Val Acc: 0.087 | Train Loss: 2.9977 | Val Loss: 4.6198\n",
      "[Run 1] Epoch 07/40 | Train Acc: 0.159 | Val Acc: 0.198 | Train Loss: 2.9176 | Val Loss: 2.9035\n",
      "[Run 1] Epoch 07/40 | Train Acc: 0.159 | Val Acc: 0.198 | Train Loss: 2.9176 | Val Loss: 2.9035\n",
      "[Run 1] Epoch 08/40 | Train Acc: 0.192 | Val Acc: 0.242 | Train Loss: 2.8454 | Val Loss: 2.8034\n",
      "[Run 1] Epoch 08/40 | Train Acc: 0.192 | Val Acc: 0.242 | Train Loss: 2.8454 | Val Loss: 2.8034\n",
      "[Run 1] Epoch 09/40 | Train Acc: 0.223 | Val Acc: 0.263 | Train Loss: 2.6965 | Val Loss: 2.6547\n",
      "[Run 1] Epoch 09/40 | Train Acc: 0.223 | Val Acc: 0.263 | Train Loss: 2.6965 | Val Loss: 2.6547\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.259 | Val Acc: 0.312 | Train Loss: 2.5843 | Val Loss: 2.4316\n",
      "[Run 1] Epoch 10/40 | Train Acc: 0.259 | Val Acc: 0.312 | Train Loss: 2.5843 | Val Loss: 2.4316\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.278 | Val Acc: 0.323 | Train Loss: 2.5161 | Val Loss: 2.4470\n",
      "[Run 1] Epoch 11/40 | Train Acc: 0.278 | Val Acc: 0.323 | Train Loss: 2.5161 | Val Loss: 2.4470\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.314 | Val Acc: 0.278 | Train Loss: 2.3134 | Val Loss: 2.4421\n",
      "[Run 1] Epoch 12/40 | Train Acc: 0.314 | Val Acc: 0.278 | Train Loss: 2.3134 | Val Loss: 2.4421\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.333 | Val Acc: 0.290 | Train Loss: 2.3123 | Val Loss: 2.3562\n",
      "[Run 1] Epoch 13/40 | Train Acc: 0.333 | Val Acc: 0.290 | Train Loss: 2.3123 | Val Loss: 2.3562\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.329 | Val Acc: 0.370 | Train Loss: 2.2095 | Val Loss: 2.1918\n",
      "[Run 1] Epoch 14/40 | Train Acc: 0.329 | Val Acc: 0.370 | Train Loss: 2.2095 | Val Loss: 2.1918\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.371 | Val Acc: 0.250 | Train Loss: 2.0918 | Val Loss: 3.4596\n",
      "[Run 1] Epoch 15/40 | Train Acc: 0.371 | Val Acc: 0.250 | Train Loss: 2.0918 | Val Loss: 3.4596\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.372 | Val Acc: 0.357 | Train Loss: 2.0553 | Val Loss: 2.5266\n",
      "[Run 1] Epoch 16/40 | Train Acc: 0.372 | Val Acc: 0.357 | Train Loss: 2.0553 | Val Loss: 2.5266\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.452 | Val Acc: 0.250 | Train Loss: 1.8779 | Val Loss: 2.9011\n",
      "[Run 1] Epoch 17/40 | Train Acc: 0.452 | Val Acc: 0.250 | Train Loss: 1.8779 | Val Loss: 2.9011\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.465 | Val Acc: 0.398 | Train Loss: 1.7674 | Val Loss: 2.0458\n",
      "[Run 1] Epoch 18/40 | Train Acc: 0.465 | Val Acc: 0.398 | Train Loss: 1.7674 | Val Loss: 2.0458\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.468 | Val Acc: 0.492 | Train Loss: 1.7097 | Val Loss: 1.7265\n",
      "[Run 1] Epoch 19/40 | Train Acc: 0.468 | Val Acc: 0.492 | Train Loss: 1.7097 | Val Loss: 1.7265\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.490 | Val Acc: 0.403 | Train Loss: 1.6468 | Val Loss: 2.0795\n",
      "[Run 1] Epoch 20/40 | Train Acc: 0.490 | Val Acc: 0.403 | Train Loss: 1.6468 | Val Loss: 2.0795\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.518 | Val Acc: 0.443 | Train Loss: 1.5951 | Val Loss: 1.8512\n",
      "[Run 1] Epoch 21/40 | Train Acc: 0.518 | Val Acc: 0.443 | Train Loss: 1.5951 | Val Loss: 1.8512\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.535 | Val Acc: 0.475 | Train Loss: 1.5320 | Val Loss: 1.7528\n",
      "[Run 1] Epoch 22/40 | Train Acc: 0.535 | Val Acc: 0.475 | Train Loss: 1.5320 | Val Loss: 1.7528\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.553 | Val Acc: 0.448 | Train Loss: 1.4703 | Val Loss: 1.7990\n",
      "[Run 1] Epoch 23/40 | Train Acc: 0.553 | Val Acc: 0.448 | Train Loss: 1.4703 | Val Loss: 1.7990\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.593 | Val Acc: 0.485 | Train Loss: 1.4058 | Val Loss: 1.6817\n",
      "[Run 1] Epoch 24/40 | Train Acc: 0.593 | Val Acc: 0.485 | Train Loss: 1.4058 | Val Loss: 1.6817\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.623 | Val Acc: 0.525 | Train Loss: 1.2568 | Val Loss: 1.7353\n",
      "[Run 1] Epoch 25/40 | Train Acc: 0.623 | Val Acc: 0.525 | Train Loss: 1.2568 | Val Loss: 1.7353\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.646 | Val Acc: 0.520 | Train Loss: 1.1870 | Val Loss: 1.5795\n",
      "[Run 1] Epoch 26/40 | Train Acc: 0.646 | Val Acc: 0.520 | Train Loss: 1.1870 | Val Loss: 1.5795\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.666 | Val Acc: 0.540 | Train Loss: 1.0975 | Val Loss: 1.5546\n",
      "[Run 1] Epoch 27/40 | Train Acc: 0.666 | Val Acc: 0.540 | Train Loss: 1.0975 | Val Loss: 1.5546\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.692 | Val Acc: 0.515 | Train Loss: 1.0489 | Val Loss: 1.5603\n",
      "[Run 1] Epoch 28/40 | Train Acc: 0.692 | Val Acc: 0.515 | Train Loss: 1.0489 | Val Loss: 1.5603\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.691 | Val Acc: 0.560 | Train Loss: 1.0516 | Val Loss: 1.4767\n",
      "[Run 1] Epoch 29/40 | Train Acc: 0.691 | Val Acc: 0.560 | Train Loss: 1.0516 | Val Loss: 1.4767\n",
      "[Run 1] Epoch 30/40 | Train Acc: 0.705 | Val Acc: 0.505 | Train Loss: 0.9799 | Val Loss: 1.5722\n",
      "[Run 1] Epoch 30/40 | Train Acc: 0.705 | Val Acc: 0.505 | Train Loss: 0.9799 | Val Loss: 1.5722\n",
      "[Run 1] Epoch 31/40 | Train Acc: 0.737 | Val Acc: 0.532 | Train Loss: 0.9117 | Val Loss: 1.6251\n",
      "[Run 1] Epoch 31/40 | Train Acc: 0.737 | Val Acc: 0.532 | Train Loss: 0.9117 | Val Loss: 1.6251\n",
      "[Run 1] Epoch 32/40 | Train Acc: 0.746 | Val Acc: 0.487 | Train Loss: 0.8565 | Val Loss: 1.7569\n",
      "[Run 1] Epoch 32/40 | Train Acc: 0.746 | Val Acc: 0.487 | Train Loss: 0.8565 | Val Loss: 1.7569\n",
      "[Run 1] Epoch 33/40 | Train Acc: 0.802 | Val Acc: 0.557 | Train Loss: 0.7377 | Val Loss: 1.3800\n",
      "[Run 1] Epoch 33/40 | Train Acc: 0.802 | Val Acc: 0.557 | Train Loss: 0.7377 | Val Loss: 1.3800\n",
      "[Run 1] Epoch 34/40 | Train Acc: 0.813 | Val Acc: 0.605 | Train Loss: 0.6909 | Val Loss: 1.3365\n",
      "[Run 1] Epoch 34/40 | Train Acc: 0.813 | Val Acc: 0.605 | Train Loss: 0.6909 | Val Loss: 1.3365\n",
      "[Run 1] Epoch 35/40 | Train Acc: 0.836 | Val Acc: 0.600 | Train Loss: 0.6527 | Val Loss: 1.3606\n",
      "[Run 1] Epoch 35/40 | Train Acc: 0.836 | Val Acc: 0.600 | Train Loss: 0.6527 | Val Loss: 1.3606\n",
      "[Run 1] Epoch 36/40 | Train Acc: 0.838 | Val Acc: 0.510 | Train Loss: 0.6393 | Val Loss: 1.6568\n",
      "[Run 1] Epoch 36/40 | Train Acc: 0.838 | Val Acc: 0.510 | Train Loss: 0.6393 | Val Loss: 1.6568\n",
      "[Run 1] Epoch 37/40 | Train Acc: 0.841 | Val Acc: 0.613 | Train Loss: 0.6007 | Val Loss: 1.3336\n",
      "[Run 1] Epoch 37/40 | Train Acc: 0.841 | Val Acc: 0.613 | Train Loss: 0.6007 | Val Loss: 1.3336\n",
      "[Run 1] Epoch 38/40 | Train Acc: 0.859 | Val Acc: 0.515 | Train Loss: 0.5464 | Val Loss: 1.5264\n",
      "[Run 1] Epoch 38/40 | Train Acc: 0.859 | Val Acc: 0.515 | Train Loss: 0.5464 | Val Loss: 1.5264\n",
      "[Run 1] Epoch 39/40 | Train Acc: 0.859 | Val Acc: 0.550 | Train Loss: 0.5712 | Val Loss: 1.5111\n",
      "[Run 1] Epoch 39/40 | Train Acc: 0.859 | Val Acc: 0.550 | Train Loss: 0.5712 | Val Loss: 1.5111\n",
      "[Run 1] Epoch 40/40 | Train Acc: 0.891 | Val Acc: 0.588 | Train Loss: 0.4625 | Val Loss: 1.4529\n",
      "✅ [Run 1] Mejor Val Acc: 0.613\n",
      "[Run 1] Epoch 40/40 | Train Acc: 0.891 | Val Acc: 0.588 | Train Loss: 0.4625 | Val Loss: 1.4529\n",
      "✅ [Run 1] Mejor Val Acc: 0.613\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▂▃▁▃▃▄▄▄▄▄▅▃▅▃▅▆▅▆▆▆▆▇▇▇▇▇▇▇▆▇██▇█▇▇█</td></tr><tr><td>val_f1_macro</td><td>▁▁▁▂▂▁▃▃▄▄▄▄▄▅▃▅▃▅▆▅▆▆▆▆▇▇▇▇▇▇▇▆▇██▇█▇▇▇</td></tr><tr><td>val_f1_weighted</td><td>▁▁▁▂▂▁▃▃▄▄▄▄▄▅▃▅▃▅▆▅▆▆▆▆▇▇▇▇▇▇▇▆▇██▇█▇▇▇</td></tr><tr><td>val_loss</td><td>▆▆▆▅▄█▄▄▄▃▃▃▃▃▆▄▄▃▂▃▂▂▂▂▂▂▁▁▁▂▂▂▁▁▁▂▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▁▂▂▂▃▂▄▄▅▄▄▅▄▅▄▆▆▆▆▆▆▇▇▇▇▇██▇▇▇▇█▇█▇██</td></tr><tr><td>val_recall_macro</td><td>▁▁▁▂▃▁▃▃▄▄▄▄▄▅▃▅▃▅▆▅▆▆▆▆▇▇▇▇▇▇▇▆▇██▇█▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6125</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.89083</td></tr><tr><td>train_loss</td><td>0.46251</td></tr><tr><td>val_acc</td><td>0.5875</td></tr><tr><td>val_f1_macro</td><td>0.55876</td></tr><tr><td>val_f1_weighted</td><td>0.55876</td></tr><tr><td>val_loss</td><td>1.45288</td></tr><tr><td>val_precision_macro</td><td>0.61456</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1_opt-Adam_lr-0.001_bs-8</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/vx6l8e6e' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/vx6l8e6e</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_124130-vx6l8e6e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_132022-x58mqrbm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/x58mqrbm' target=\"_blank\">run_2_opt-Adam_lr-0.0005_bs-8</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/x58mqrbm' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/x58mqrbm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 2] Epoch 01/40 | Train Acc: 0.057 | Val Acc: 0.060 | Train Loss: 3.7364 | Val Loss: 3.7073\n",
      "[Run 2] Epoch 02/40 | Train Acc: 0.084 | Val Acc: 0.090 | Train Loss: 3.3562 | Val Loss: 3.4327\n",
      "[Run 2] Epoch 02/40 | Train Acc: 0.084 | Val Acc: 0.090 | Train Loss: 3.3562 | Val Loss: 3.4327\n",
      "[Run 2] Epoch 03/40 | Train Acc: 0.111 | Val Acc: 0.152 | Train Loss: 3.2064 | Val Loss: 3.1589\n",
      "[Run 2] Epoch 03/40 | Train Acc: 0.111 | Val Acc: 0.152 | Train Loss: 3.2064 | Val Loss: 3.1589\n",
      "[Run 2] Epoch 04/40 | Train Acc: 0.147 | Val Acc: 0.205 | Train Loss: 3.0393 | Val Loss: 2.8981\n",
      "[Run 2] Epoch 04/40 | Train Acc: 0.147 | Val Acc: 0.205 | Train Loss: 3.0393 | Val Loss: 2.8981\n",
      "[Run 2] Epoch 05/40 | Train Acc: 0.145 | Val Acc: 0.182 | Train Loss: 2.9506 | Val Loss: 3.0472\n",
      "[Run 2] Epoch 05/40 | Train Acc: 0.145 | Val Acc: 0.182 | Train Loss: 2.9506 | Val Loss: 3.0472\n",
      "[Run 2] Epoch 06/40 | Train Acc: 0.227 | Val Acc: 0.302 | Train Loss: 2.7572 | Val Loss: 2.6592\n",
      "[Run 2] Epoch 06/40 | Train Acc: 0.227 | Val Acc: 0.302 | Train Loss: 2.7572 | Val Loss: 2.6592\n",
      "[Run 2] Epoch 07/40 | Train Acc: 0.247 | Val Acc: 0.295 | Train Loss: 2.6283 | Val Loss: 2.5033\n",
      "[Run 2] Epoch 07/40 | Train Acc: 0.247 | Val Acc: 0.295 | Train Loss: 2.6283 | Val Loss: 2.5033\n",
      "[Run 2] Epoch 08/40 | Train Acc: 0.286 | Val Acc: 0.217 | Train Loss: 2.4979 | Val Loss: 2.8006\n",
      "[Run 2] Epoch 08/40 | Train Acc: 0.286 | Val Acc: 0.217 | Train Loss: 2.4979 | Val Loss: 2.8006\n",
      "[Run 2] Epoch 09/40 | Train Acc: 0.310 | Val Acc: 0.347 | Train Loss: 2.3209 | Val Loss: 2.2354\n",
      "[Run 2] Epoch 09/40 | Train Acc: 0.310 | Val Acc: 0.347 | Train Loss: 2.3209 | Val Loss: 2.2354\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.334 | Val Acc: 0.398 | Train Loss: 2.2498 | Val Loss: 2.1357\n",
      "[Run 2] Epoch 10/40 | Train Acc: 0.334 | Val Acc: 0.398 | Train Loss: 2.2498 | Val Loss: 2.1357\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.375 | Val Acc: 0.380 | Train Loss: 2.1132 | Val Loss: 2.1397\n",
      "[Run 2] Epoch 11/40 | Train Acc: 0.375 | Val Acc: 0.380 | Train Loss: 2.1132 | Val Loss: 2.1397\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.390 | Val Acc: 0.338 | Train Loss: 2.1025 | Val Loss: 2.3779\n",
      "[Run 2] Epoch 12/40 | Train Acc: 0.390 | Val Acc: 0.338 | Train Loss: 2.1025 | Val Loss: 2.3779\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.405 | Val Acc: 0.355 | Train Loss: 1.9691 | Val Loss: 2.2254\n",
      "[Run 2] Epoch 13/40 | Train Acc: 0.405 | Val Acc: 0.355 | Train Loss: 1.9691 | Val Loss: 2.2254\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.395 | Val Acc: 0.400 | Train Loss: 1.9904 | Val Loss: 2.0466\n",
      "[Run 2] Epoch 14/40 | Train Acc: 0.395 | Val Acc: 0.400 | Train Loss: 1.9904 | Val Loss: 2.0466\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.439 | Val Acc: 0.395 | Train Loss: 1.8581 | Val Loss: 2.2147\n",
      "[Run 2] Epoch 15/40 | Train Acc: 0.439 | Val Acc: 0.395 | Train Loss: 1.8581 | Val Loss: 2.2147\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.466 | Val Acc: 0.443 | Train Loss: 1.8039 | Val Loss: 1.9718\n",
      "[Run 2] Epoch 16/40 | Train Acc: 0.466 | Val Acc: 0.443 | Train Loss: 1.8039 | Val Loss: 1.9718\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.493 | Val Acc: 0.458 | Train Loss: 1.6285 | Val Loss: 1.9257\n",
      "[Run 2] Epoch 17/40 | Train Acc: 0.493 | Val Acc: 0.458 | Train Loss: 1.6285 | Val Loss: 1.9257\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.525 | Val Acc: 0.482 | Train Loss: 1.5869 | Val Loss: 1.8082\n",
      "[Run 2] Epoch 18/40 | Train Acc: 0.525 | Val Acc: 0.482 | Train Loss: 1.5869 | Val Loss: 1.8082\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.532 | Val Acc: 0.430 | Train Loss: 1.5767 | Val Loss: 1.9489\n",
      "[Run 2] Epoch 19/40 | Train Acc: 0.532 | Val Acc: 0.430 | Train Loss: 1.5767 | Val Loss: 1.9489\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.568 | Val Acc: 0.517 | Train Loss: 1.4269 | Val Loss: 1.7752\n",
      "[Run 2] Epoch 20/40 | Train Acc: 0.568 | Val Acc: 0.517 | Train Loss: 1.4269 | Val Loss: 1.7752\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.567 | Val Acc: 0.455 | Train Loss: 1.4461 | Val Loss: 1.9663\n",
      "[Run 2] Epoch 21/40 | Train Acc: 0.567 | Val Acc: 0.455 | Train Loss: 1.4461 | Val Loss: 1.9663\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.598 | Val Acc: 0.477 | Train Loss: 1.3198 | Val Loss: 1.7585\n",
      "[Run 2] Epoch 22/40 | Train Acc: 0.598 | Val Acc: 0.477 | Train Loss: 1.3198 | Val Loss: 1.7585\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.601 | Val Acc: 0.522 | Train Loss: 1.2991 | Val Loss: 1.7107\n",
      "[Run 2] Epoch 23/40 | Train Acc: 0.601 | Val Acc: 0.522 | Train Loss: 1.2991 | Val Loss: 1.7107\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.631 | Val Acc: 0.573 | Train Loss: 1.2533 | Val Loss: 1.5624\n",
      "[Run 2] Epoch 24/40 | Train Acc: 0.631 | Val Acc: 0.573 | Train Loss: 1.2533 | Val Loss: 1.5624\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.656 | Val Acc: 0.552 | Train Loss: 1.1943 | Val Loss: 1.5512\n",
      "[Run 2] Epoch 25/40 | Train Acc: 0.656 | Val Acc: 0.552 | Train Loss: 1.1943 | Val Loss: 1.5512\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.690 | Val Acc: 0.527 | Train Loss: 1.0865 | Val Loss: 1.6282\n",
      "[Run 2] Epoch 26/40 | Train Acc: 0.690 | Val Acc: 0.527 | Train Loss: 1.0865 | Val Loss: 1.6282\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.682 | Val Acc: 0.552 | Train Loss: 1.0407 | Val Loss: 1.5878\n",
      "[Run 2] Epoch 27/40 | Train Acc: 0.682 | Val Acc: 0.552 | Train Loss: 1.0407 | Val Loss: 1.5878\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.713 | Val Acc: 0.555 | Train Loss: 1.0006 | Val Loss: 1.6150\n",
      "[Run 2] Epoch 28/40 | Train Acc: 0.713 | Val Acc: 0.555 | Train Loss: 1.0006 | Val Loss: 1.6150\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.734 | Val Acc: 0.570 | Train Loss: 0.9243 | Val Loss: 1.5095\n",
      "[Run 2] Epoch 29/40 | Train Acc: 0.734 | Val Acc: 0.570 | Train Loss: 0.9243 | Val Loss: 1.5095\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.750 | Val Acc: 0.475 | Train Loss: 0.8718 | Val Loss: 1.8375\n",
      "[Run 2] Epoch 30/40 | Train Acc: 0.750 | Val Acc: 0.475 | Train Loss: 0.8718 | Val Loss: 1.8375\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.729 | Val Acc: 0.545 | Train Loss: 0.9299 | Val Loss: 1.5824\n",
      "[Run 2] Early stopping triggered at epoch 31.\n",
      "✅ [Run 2] Mejor Val Acc: 0.573\n",
      "[Run 2] Epoch 31/40 | Train Acc: 0.729 | Val Acc: 0.545 | Train Loss: 0.9299 | Val Loss: 1.5824\n",
      "[Run 2] Early stopping triggered at epoch 31.\n",
      "✅ [Run 2] Mejor Val Acc: 0.573\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▅▄▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▄▄▃▅▆▅▅▅▆▆▆▆▇▆▇▆▇▇██▇███▇█</td></tr><tr><td>val_f1_macro</td><td>▁▁▂▃▃▄▄▃▅▅▅▅▅▆▅▆▆▇▆▇▆▇▇██▇███▇█</td></tr><tr><td>val_f1_weighted</td><td>▁▁▂▃▃▄▄▃▅▅▅▅▅▆▅▆▆▇▆▇▆▇▇██▇███▇█</td></tr><tr><td>val_loss</td><td>█▇▆▅▆▅▄▅▃▃▃▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▂▃▃▄▄▃▅▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇█▇█▇█</td></tr><tr><td>val_recall_macro</td><td>▁▁▂▃▃▄▄▃▅▆▅▅▅▆▆▆▆▇▆▇▆▇▇██▇███▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.5725</td></tr><tr><td>epoch</td><td>31</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.72917</td></tr><tr><td>train_loss</td><td>0.92986</td></tr><tr><td>val_acc</td><td>0.545</td></tr><tr><td>val_f1_macro</td><td>0.53383</td></tr><tr><td>val_f1_weighted</td><td>0.53383</td></tr><tr><td>val_loss</td><td>1.58241</td></tr><tr><td>val_precision_macro</td><td>0.62073</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2_opt-Adam_lr-0.0005_bs-8</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/x58mqrbm' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/x58mqrbm</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a><br>Synced 5 W&B file(s), 31 media file(s), 62 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_132022-x58mqrbm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_134934-g0tr9k06</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/g0tr9k06' target=\"_blank\">run_3_opt-Adam_lr-0.001_bs-16</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/g0tr9k06' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/g0tr9k06</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 3] Epoch 01/40 | Train Acc: 0.037 | Val Acc: 0.040 | Train Loss: 3.8082 | Val Loss: 3.8550\n",
      "[Run 3] Epoch 02/40 | Train Acc: 0.077 | Val Acc: 0.080 | Train Loss: 3.4639 | Val Loss: 3.2861\n",
      "[Run 3] Epoch 02/40 | Train Acc: 0.077 | Val Acc: 0.080 | Train Loss: 3.4639 | Val Loss: 3.2861\n",
      "[Run 3] Epoch 03/40 | Train Acc: 0.111 | Val Acc: 0.090 | Train Loss: 3.2120 | Val Loss: 3.2970\n",
      "[Run 3] Epoch 03/40 | Train Acc: 0.111 | Val Acc: 0.090 | Train Loss: 3.2120 | Val Loss: 3.2970\n",
      "[Run 3] Epoch 04/40 | Train Acc: 0.159 | Val Acc: 0.168 | Train Loss: 2.9609 | Val Loss: 2.8582\n",
      "[Run 3] Epoch 04/40 | Train Acc: 0.159 | Val Acc: 0.168 | Train Loss: 2.9609 | Val Loss: 2.8582\n",
      "[Run 3] Epoch 05/40 | Train Acc: 0.218 | Val Acc: 0.228 | Train Loss: 2.7222 | Val Loss: 2.7622\n",
      "[Run 3] Epoch 05/40 | Train Acc: 0.218 | Val Acc: 0.228 | Train Loss: 2.7222 | Val Loss: 2.7622\n",
      "[Run 3] Epoch 06/40 | Train Acc: 0.255 | Val Acc: 0.320 | Train Loss: 2.5501 | Val Loss: 2.4695\n",
      "[Run 3] Epoch 06/40 | Train Acc: 0.255 | Val Acc: 0.320 | Train Loss: 2.5501 | Val Loss: 2.4695\n",
      "[Run 3] Epoch 07/40 | Train Acc: 0.315 | Val Acc: 0.352 | Train Loss: 2.3456 | Val Loss: 2.4830\n",
      "[Run 3] Epoch 07/40 | Train Acc: 0.315 | Val Acc: 0.352 | Train Loss: 2.3456 | Val Loss: 2.4830\n",
      "[Run 3] Epoch 08/40 | Train Acc: 0.331 | Val Acc: 0.323 | Train Loss: 2.3270 | Val Loss: 2.2868\n",
      "[Run 3] Epoch 08/40 | Train Acc: 0.331 | Val Acc: 0.323 | Train Loss: 2.3270 | Val Loss: 2.2868\n",
      "[Run 3] Epoch 09/40 | Train Acc: 0.394 | Val Acc: 0.268 | Train Loss: 2.0510 | Val Loss: 2.5865\n",
      "[Run 3] Epoch 09/40 | Train Acc: 0.394 | Val Acc: 0.268 | Train Loss: 2.0510 | Val Loss: 2.5865\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.402 | Val Acc: 0.278 | Train Loss: 1.9586 | Val Loss: 2.7120\n",
      "[Run 3] Epoch 10/40 | Train Acc: 0.402 | Val Acc: 0.278 | Train Loss: 1.9586 | Val Loss: 2.7120\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.443 | Val Acc: 0.323 | Train Loss: 1.8411 | Val Loss: 2.5708\n",
      "[Run 3] Epoch 11/40 | Train Acc: 0.443 | Val Acc: 0.323 | Train Loss: 1.8411 | Val Loss: 2.5708\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.470 | Val Acc: 0.378 | Train Loss: 1.7646 | Val Loss: 2.1311\n",
      "[Run 3] Epoch 12/40 | Train Acc: 0.470 | Val Acc: 0.378 | Train Loss: 1.7646 | Val Loss: 2.1311\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.485 | Val Acc: 0.370 | Train Loss: 1.6602 | Val Loss: 2.1597\n",
      "[Run 3] Epoch 13/40 | Train Acc: 0.485 | Val Acc: 0.370 | Train Loss: 1.6602 | Val Loss: 2.1597\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.499 | Val Acc: 0.372 | Train Loss: 1.6041 | Val Loss: 2.2521\n",
      "[Run 3] Epoch 14/40 | Train Acc: 0.499 | Val Acc: 0.372 | Train Loss: 1.6041 | Val Loss: 2.2521\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.527 | Val Acc: 0.372 | Train Loss: 1.5445 | Val Loss: 2.1446\n",
      "[Run 3] Epoch 15/40 | Train Acc: 0.527 | Val Acc: 0.372 | Train Loss: 1.5445 | Val Loss: 2.1446\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.532 | Val Acc: 0.333 | Train Loss: 1.5123 | Val Loss: 2.4156\n",
      "[Run 3] Epoch 16/40 | Train Acc: 0.532 | Val Acc: 0.333 | Train Loss: 1.5123 | Val Loss: 2.4156\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.594 | Val Acc: 0.507 | Train Loss: 1.3623 | Val Loss: 1.6454\n",
      "[Run 3] Epoch 17/40 | Train Acc: 0.594 | Val Acc: 0.507 | Train Loss: 1.3623 | Val Loss: 1.6454\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.593 | Val Acc: 0.398 | Train Loss: 1.3235 | Val Loss: 2.2316\n",
      "[Run 3] Epoch 18/40 | Train Acc: 0.593 | Val Acc: 0.398 | Train Loss: 1.3235 | Val Loss: 2.2316\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.620 | Val Acc: 0.430 | Train Loss: 1.2335 | Val Loss: 1.9023\n",
      "[Run 3] Epoch 19/40 | Train Acc: 0.620 | Val Acc: 0.430 | Train Loss: 1.2335 | Val Loss: 1.9023\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.633 | Val Acc: 0.500 | Train Loss: 1.2446 | Val Loss: 1.6839\n",
      "[Run 3] Epoch 20/40 | Train Acc: 0.633 | Val Acc: 0.500 | Train Loss: 1.2446 | Val Loss: 1.6839\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.647 | Val Acc: 0.547 | Train Loss: 1.1229 | Val Loss: 1.5366\n",
      "[Run 3] Epoch 21/40 | Train Acc: 0.647 | Val Acc: 0.547 | Train Loss: 1.1229 | Val Loss: 1.5366\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.663 | Val Acc: 0.532 | Train Loss: 1.0921 | Val Loss: 1.5345\n",
      "[Run 3] Epoch 22/40 | Train Acc: 0.663 | Val Acc: 0.532 | Train Loss: 1.0921 | Val Loss: 1.5345\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.719 | Val Acc: 0.453 | Train Loss: 1.0108 | Val Loss: 1.8609\n",
      "[Run 3] Epoch 23/40 | Train Acc: 0.719 | Val Acc: 0.453 | Train Loss: 1.0108 | Val Loss: 1.8609\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.689 | Val Acc: 0.438 | Train Loss: 0.9977 | Val Loss: 1.8792\n",
      "[Run 3] Epoch 24/40 | Train Acc: 0.689 | Val Acc: 0.438 | Train Loss: 0.9977 | Val Loss: 1.8792\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.748 | Val Acc: 0.515 | Train Loss: 0.8795 | Val Loss: 1.6302\n",
      "[Run 3] Epoch 25/40 | Train Acc: 0.748 | Val Acc: 0.515 | Train Loss: 0.8795 | Val Loss: 1.6302\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.777 | Val Acc: 0.545 | Train Loss: 0.7779 | Val Loss: 1.3980\n",
      "[Run 3] Epoch 26/40 | Train Acc: 0.777 | Val Acc: 0.545 | Train Loss: 0.7779 | Val Loss: 1.3980\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.796 | Val Acc: 0.547 | Train Loss: 0.7367 | Val Loss: 1.4535\n",
      "[Run 3] Epoch 27/40 | Train Acc: 0.796 | Val Acc: 0.547 | Train Loss: 0.7367 | Val Loss: 1.4535\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.813 | Val Acc: 0.590 | Train Loss: 0.6790 | Val Loss: 1.3610\n",
      "[Run 3] Epoch 28/40 | Train Acc: 0.813 | Val Acc: 0.590 | Train Loss: 0.6790 | Val Loss: 1.3610\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.808 | Val Acc: 0.477 | Train Loss: 0.6856 | Val Loss: 1.9058\n",
      "[Run 3] Epoch 29/40 | Train Acc: 0.808 | Val Acc: 0.477 | Train Loss: 0.6856 | Val Loss: 1.9058\n",
      "[Run 3] Epoch 30/40 | Train Acc: 0.802 | Val Acc: 0.590 | Train Loss: 0.6669 | Val Loss: 1.4305\n",
      "[Run 3] Epoch 30/40 | Train Acc: 0.802 | Val Acc: 0.590 | Train Loss: 0.6669 | Val Loss: 1.4305\n",
      "[Run 3] Epoch 31/40 | Train Acc: 0.823 | Val Acc: 0.608 | Train Loss: 0.6307 | Val Loss: 1.3938\n",
      "[Run 3] Epoch 31/40 | Train Acc: 0.823 | Val Acc: 0.608 | Train Loss: 0.6307 | Val Loss: 1.3938\n",
      "[Run 3] Epoch 32/40 | Train Acc: 0.840 | Val Acc: 0.552 | Train Loss: 0.5856 | Val Loss: 1.5072\n",
      "[Run 3] Epoch 32/40 | Train Acc: 0.840 | Val Acc: 0.552 | Train Loss: 0.5856 | Val Loss: 1.5072\n",
      "[Run 3] Epoch 33/40 | Train Acc: 0.865 | Val Acc: 0.590 | Train Loss: 0.5388 | Val Loss: 1.3528\n",
      "[Run 3] Epoch 33/40 | Train Acc: 0.865 | Val Acc: 0.590 | Train Loss: 0.5388 | Val Loss: 1.3528\n",
      "[Run 3] Epoch 34/40 | Train Acc: 0.893 | Val Acc: 0.552 | Train Loss: 0.4515 | Val Loss: 1.4852\n",
      "[Run 3] Epoch 34/40 | Train Acc: 0.893 | Val Acc: 0.552 | Train Loss: 0.4515 | Val Loss: 1.4852\n",
      "[Run 3] Epoch 35/40 | Train Acc: 0.908 | Val Acc: 0.583 | Train Loss: 0.3971 | Val Loss: 1.4419\n",
      "[Run 3] Epoch 35/40 | Train Acc: 0.908 | Val Acc: 0.583 | Train Loss: 0.3971 | Val Loss: 1.4419\n",
      "[Run 3] Epoch 36/40 | Train Acc: 0.922 | Val Acc: 0.593 | Train Loss: 0.3638 | Val Loss: 1.3408\n",
      "[Run 3] Epoch 36/40 | Train Acc: 0.922 | Val Acc: 0.593 | Train Loss: 0.3638 | Val Loss: 1.3408\n",
      "[Run 3] Epoch 37/40 | Train Acc: 0.914 | Val Acc: 0.620 | Train Loss: 0.3837 | Val Loss: 1.2451\n",
      "[Run 3] Epoch 37/40 | Train Acc: 0.914 | Val Acc: 0.620 | Train Loss: 0.3837 | Val Loss: 1.2451\n",
      "[Run 3] Epoch 38/40 | Train Acc: 0.919 | Val Acc: 0.590 | Train Loss: 0.3597 | Val Loss: 1.4065\n",
      "[Run 3] Epoch 38/40 | Train Acc: 0.919 | Val Acc: 0.590 | Train Loss: 0.3597 | Val Loss: 1.4065\n",
      "[Run 3] Epoch 39/40 | Train Acc: 0.934 | Val Acc: 0.588 | Train Loss: 0.3454 | Val Loss: 1.4321\n",
      "[Run 3] Epoch 39/40 | Train Acc: 0.934 | Val Acc: 0.588 | Train Loss: 0.3454 | Val Loss: 1.4321\n",
      "[Run 3] Epoch 40/40 | Train Acc: 0.941 | Val Acc: 0.573 | Train Loss: 0.3014 | Val Loss: 1.5629\n",
      "✅ [Run 3] Mejor Val Acc: 0.620\n",
      "[Run 3] Epoch 40/40 | Train Acc: 0.941 | Val Acc: 0.573 | Train Loss: 0.3014 | Val Loss: 1.5629\n",
      "✅ [Run 3] Mejor Val Acc: 0.620\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▄▅▄▄▄▄▅▅▅▅▅▇▅▆▇▇▇▆▆▇▇▇█▆██▇█▇█████▇</td></tr><tr><td>val_f1_macro</td><td>▁▁▁▂▃▄▄▄▃▄▄▅▅▅▅▄▇▅▆▆▇▇▆▅▇▇▇█▆██▇█▇█████▇</td></tr><tr><td>val_f1_weighted</td><td>▁▁▁▂▃▄▄▄▃▄▄▅▅▅▅▄▇▅▆▆▇▇▆▅▇▇▇█▆██▇█▇█████▇</td></tr><tr><td>val_loss</td><td>█▆▇▅▅▄▄▄▅▅▅▃▃▄▃▄▂▄▃▂▂▂▃▃▂▁▂▁▃▁▁▂▁▂▂▁▁▁▂▂</td></tr><tr><td>val_precision_macro</td><td>▁▁▁▂▃▄▅▄▄▄▅▅▅▆▅▆▇▆▆▇▇▇▇▆▇▇▇▇▇██▇▇██▇███▇</td></tr><tr><td>val_recall_macro</td><td>▁▁▂▃▃▄▅▄▄▄▄▅▅▅▅▅▇▅▆▇▇▇▆▆▇▇▇█▆██▇█▇█████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.62</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.94083</td></tr><tr><td>train_loss</td><td>0.3014</td></tr><tr><td>val_acc</td><td>0.5725</td></tr><tr><td>val_f1_macro</td><td>0.55551</td></tr><tr><td>val_f1_weighted</td><td>0.55551</td></tr><tr><td>val_loss</td><td>1.56287</td></tr><tr><td>val_precision_macro</td><td>0.62847</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3_opt-Adam_lr-0.001_bs-16</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/g0tr9k06' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/g0tr9k06</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_134934-g0tr9k06/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_142658-yocrcvcv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/yocrcvcv' target=\"_blank\">run_4_opt-SGD_lr-0.01_bs-8</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/yocrcvcv' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/yocrcvcv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 4] Epoch 01/40 | Train Acc: 0.022 | Val Acc: 0.030 | Train Loss: 4.0767 | Val Loss: 3.9781\n",
      "[Run 4] Epoch 02/40 | Train Acc: 0.056 | Val Acc: 0.075 | Train Loss: 3.6328 | Val Loss: 4.0524\n",
      "[Run 4] Epoch 02/40 | Train Acc: 0.056 | Val Acc: 0.075 | Train Loss: 3.6328 | Val Loss: 4.0524\n",
      "[Run 4] Epoch 03/40 | Train Acc: 0.112 | Val Acc: 0.083 | Train Loss: 3.3671 | Val Loss: 4.7000\n",
      "[Run 4] Epoch 03/40 | Train Acc: 0.112 | Val Acc: 0.083 | Train Loss: 3.3671 | Val Loss: 4.7000\n",
      "[Run 4] Epoch 04/40 | Train Acc: 0.144 | Val Acc: 0.177 | Train Loss: 3.1378 | Val Loss: 2.8800\n",
      "[Run 4] Epoch 04/40 | Train Acc: 0.144 | Val Acc: 0.177 | Train Loss: 3.1378 | Val Loss: 2.8800\n",
      "[Run 4] Epoch 05/40 | Train Acc: 0.183 | Val Acc: 0.145 | Train Loss: 2.9245 | Val Loss: 3.5701\n",
      "[Run 4] Epoch 05/40 | Train Acc: 0.183 | Val Acc: 0.145 | Train Loss: 2.9245 | Val Loss: 3.5701\n",
      "[Run 4] Epoch 06/40 | Train Acc: 0.228 | Val Acc: 0.250 | Train Loss: 2.7629 | Val Loss: 2.7424\n",
      "[Run 4] Epoch 06/40 | Train Acc: 0.228 | Val Acc: 0.250 | Train Loss: 2.7629 | Val Loss: 2.7424\n",
      "[Run 4] Epoch 07/40 | Train Acc: 0.243 | Val Acc: 0.265 | Train Loss: 2.5859 | Val Loss: 2.6886\n",
      "[Run 4] Epoch 07/40 | Train Acc: 0.243 | Val Acc: 0.265 | Train Loss: 2.5859 | Val Loss: 2.6886\n",
      "[Run 4] Epoch 08/40 | Train Acc: 0.280 | Val Acc: 0.185 | Train Loss: 2.4662 | Val Loss: 2.7917\n",
      "[Run 4] Epoch 08/40 | Train Acc: 0.280 | Val Acc: 0.185 | Train Loss: 2.4662 | Val Loss: 2.7917\n",
      "[Run 4] Epoch 09/40 | Train Acc: 0.366 | Val Acc: 0.270 | Train Loss: 2.1606 | Val Loss: 2.5631\n",
      "[Run 4] Epoch 09/40 | Train Acc: 0.366 | Val Acc: 0.270 | Train Loss: 2.1606 | Val Loss: 2.5631\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.372 | Val Acc: 0.378 | Train Loss: 2.1083 | Val Loss: 2.2025\n",
      "[Run 4] Epoch 10/40 | Train Acc: 0.372 | Val Acc: 0.378 | Train Loss: 2.1083 | Val Loss: 2.2025\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.397 | Val Acc: 0.407 | Train Loss: 1.9819 | Val Loss: 2.0591\n",
      "[Run 4] Epoch 11/40 | Train Acc: 0.397 | Val Acc: 0.407 | Train Loss: 1.9819 | Val Loss: 2.0591\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.422 | Val Acc: 0.403 | Train Loss: 1.8883 | Val Loss: 2.5384\n",
      "[Run 4] Epoch 12/40 | Train Acc: 0.422 | Val Acc: 0.403 | Train Loss: 1.8883 | Val Loss: 2.5384\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.459 | Val Acc: 0.362 | Train Loss: 1.7679 | Val Loss: 2.2926\n",
      "[Run 4] Epoch 13/40 | Train Acc: 0.459 | Val Acc: 0.362 | Train Loss: 1.7679 | Val Loss: 2.2926\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.483 | Val Acc: 0.415 | Train Loss: 1.6775 | Val Loss: 2.0218\n",
      "[Run 4] Epoch 14/40 | Train Acc: 0.483 | Val Acc: 0.415 | Train Loss: 1.6775 | Val Loss: 2.0218\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.520 | Val Acc: 0.425 | Train Loss: 1.5931 | Val Loss: 2.0788\n",
      "[Run 4] Epoch 15/40 | Train Acc: 0.520 | Val Acc: 0.425 | Train Loss: 1.5931 | Val Loss: 2.0788\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.518 | Val Acc: 0.407 | Train Loss: 1.5234 | Val Loss: 2.0426\n",
      "[Run 4] Epoch 16/40 | Train Acc: 0.518 | Val Acc: 0.407 | Train Loss: 1.5234 | Val Loss: 2.0426\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.615 | Val Acc: 0.500 | Train Loss: 1.2427 | Val Loss: 1.8014\n",
      "[Run 4] Epoch 17/40 | Train Acc: 0.615 | Val Acc: 0.500 | Train Loss: 1.2427 | Val Loss: 1.8014\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.635 | Val Acc: 0.532 | Train Loss: 1.1709 | Val Loss: 1.6984\n",
      "[Run 4] Epoch 18/40 | Train Acc: 0.635 | Val Acc: 0.532 | Train Loss: 1.1709 | Val Loss: 1.6984\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.658 | Val Acc: 0.507 | Train Loss: 1.1210 | Val Loss: 1.7347\n",
      "[Run 4] Epoch 19/40 | Train Acc: 0.658 | Val Acc: 0.507 | Train Loss: 1.1210 | Val Loss: 1.7347\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.708 | Val Acc: 0.417 | Train Loss: 1.0026 | Val Loss: 2.3159\n",
      "[Run 4] Epoch 20/40 | Train Acc: 0.708 | Val Acc: 0.417 | Train Loss: 1.0026 | Val Loss: 2.3159\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.714 | Val Acc: 0.530 | Train Loss: 0.9364 | Val Loss: 1.7611\n",
      "[Run 4] Epoch 21/40 | Train Acc: 0.714 | Val Acc: 0.530 | Train Loss: 0.9364 | Val Loss: 1.7611\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.730 | Val Acc: 0.487 | Train Loss: 0.8995 | Val Loss: 1.7653\n",
      "[Run 4] Epoch 22/40 | Train Acc: 0.730 | Val Acc: 0.487 | Train Loss: 0.8995 | Val Loss: 1.7653\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.758 | Val Acc: 0.472 | Train Loss: 0.8080 | Val Loss: 2.0114\n",
      "[Run 4] Epoch 23/40 | Train Acc: 0.758 | Val Acc: 0.472 | Train Loss: 0.8080 | Val Loss: 2.0114\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.777 | Val Acc: 0.468 | Train Loss: 0.7889 | Val Loss: 2.1356\n",
      "[Run 4] Epoch 24/40 | Train Acc: 0.777 | Val Acc: 0.468 | Train Loss: 0.7889 | Val Loss: 2.1356\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.829 | Val Acc: 0.598 | Train Loss: 0.5846 | Val Loss: 1.4778\n",
      "[Run 4] Epoch 25/40 | Train Acc: 0.829 | Val Acc: 0.598 | Train Loss: 0.5846 | Val Loss: 1.4778\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.866 | Val Acc: 0.585 | Train Loss: 0.5119 | Val Loss: 1.5050\n",
      "[Run 4] Epoch 26/40 | Train Acc: 0.866 | Val Acc: 0.585 | Train Loss: 0.5119 | Val Loss: 1.5050\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.886 | Val Acc: 0.568 | Train Loss: 0.4599 | Val Loss: 1.5780\n",
      "[Run 4] Epoch 27/40 | Train Acc: 0.886 | Val Acc: 0.568 | Train Loss: 0.4599 | Val Loss: 1.5780\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.905 | Val Acc: 0.632 | Train Loss: 0.3988 | Val Loss: 1.3623\n",
      "[Run 4] Epoch 28/40 | Train Acc: 0.905 | Val Acc: 0.632 | Train Loss: 0.3988 | Val Loss: 1.3623\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.904 | Val Acc: 0.625 | Train Loss: 0.4166 | Val Loss: 1.4061\n",
      "[Run 4] Epoch 29/40 | Train Acc: 0.904 | Val Acc: 0.625 | Train Loss: 0.4166 | Val Loss: 1.4061\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.912 | Val Acc: 0.547 | Train Loss: 0.3617 | Val Loss: 1.8117\n",
      "[Run 4] Epoch 30/40 | Train Acc: 0.912 | Val Acc: 0.547 | Train Loss: 0.3617 | Val Loss: 1.8117\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.930 | Val Acc: 0.588 | Train Loss: 0.3152 | Val Loss: 1.4938\n",
      "[Run 4] Epoch 31/40 | Train Acc: 0.930 | Val Acc: 0.588 | Train Loss: 0.3152 | Val Loss: 1.4938\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.933 | Val Acc: 0.580 | Train Loss: 0.3090 | Val Loss: 1.6151\n",
      "[Run 4] Epoch 32/40 | Train Acc: 0.933 | Val Acc: 0.580 | Train Loss: 0.3090 | Val Loss: 1.6151\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.955 | Val Acc: 0.598 | Train Loss: 0.2444 | Val Loss: 1.4321\n",
      "[Run 4] Epoch 33/40 | Train Acc: 0.955 | Val Acc: 0.598 | Train Loss: 0.2444 | Val Loss: 1.4321\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.973 | Val Acc: 0.627 | Train Loss: 0.1740 | Val Loss: 1.3579\n",
      "[Run 4] Epoch 34/40 | Train Acc: 0.973 | Val Acc: 0.627 | Train Loss: 0.1740 | Val Loss: 1.3579\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.978 | Val Acc: 0.630 | Train Loss: 0.1784 | Val Loss: 1.5290\n",
      "[Run 4] Early stopping triggered at epoch 35.\n",
      "✅ [Run 4] Mejor Val Acc: 0.632\n",
      "[Run 4] Epoch 35/40 | Train Acc: 0.978 | Val Acc: 0.630 | Train Loss: 0.1784 | Val Loss: 1.5290\n",
      "[Run 4] Early stopping triggered at epoch 35.\n",
      "✅ [Run 4] Mejor Val Acc: 0.632\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▃▂▄▄▃▄▅▅▅▅▅▆▅▆▇▇▆▇▆▆▆█▇▇██▇▇▇███</td></tr><tr><td>val_f1_macro</td><td>▁▁▁▂▂▃▃▃▄▅▅▅▅▅▅▅▆▇▆▅▇▆▆▆█▇▇██▇▇▇███</td></tr><tr><td>val_f1_weighted</td><td>▁▁▁▂▂▃▃▃▄▅▅▅▅▅▅▅▆▇▆▅▇▆▆▆█▇▇██▇▇▇███</td></tr><tr><td>val_loss</td><td>▆▇█▄▆▄▄▄▄▃▂▃▃▂▃▂▂▂▂▃▂▂▂▃▁▁▁▁▁▂▁▂▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▁▂▂▃▃▃▄▅▆▆▅▅▆▆▇▇▆▆▇▆▆▆█▇▇██▇▇▇██▇</td></tr><tr><td>val_recall_macro</td><td>▁▂▂▃▂▄▄▃▄▅▅▅▅▅▆▅▆▇▇▆▇▆▆▆█▇▇██▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6325</td></tr><tr><td>epoch</td><td>35</td></tr><tr><td>lr</td><td>0.0024</td></tr><tr><td>train_acc</td><td>0.97833</td></tr><tr><td>train_loss</td><td>0.17839</td></tr><tr><td>val_acc</td><td>0.63</td></tr><tr><td>val_f1_macro</td><td>0.61419</td></tr><tr><td>val_f1_weighted</td><td>0.61419</td></tr><tr><td>val_loss</td><td>1.52899</td></tr><tr><td>val_precision_macro</td><td>0.64456</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_4_opt-SGD_lr-0.01_bs-8</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/yocrcvcv' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/yocrcvcv</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a><br>Synced 5 W&B file(s), 35 media file(s), 70 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_142658-yocrcvcv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javialroro/TEC/2025 II/IA/CNNVoiceRecognition/wandb/run-20251026_145937-kgvla8k7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/kgvla8k7' target=\"_blank\">run_5_opt-SGD_lr-0.001_bs-8</a></strong> to <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/kgvla8k7' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/kgvla8k7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 5] Epoch 01/40 | Train Acc: 0.025 | Val Acc: 0.060 | Train Loss: 3.9136 | Val Loss: 3.7168\n",
      "[Run 5] Epoch 02/40 | Train Acc: 0.042 | Val Acc: 0.055 | Train Loss: 3.6964 | Val Loss: 3.5477\n",
      "[Run 5] Epoch 02/40 | Train Acc: 0.042 | Val Acc: 0.055 | Train Loss: 3.6964 | Val Loss: 3.5477\n",
      "[Run 5] Epoch 03/40 | Train Acc: 0.061 | Val Acc: 0.072 | Train Loss: 3.5663 | Val Loss: 3.4538\n",
      "[Run 5] Epoch 03/40 | Train Acc: 0.061 | Val Acc: 0.072 | Train Loss: 3.5663 | Val Loss: 3.4538\n",
      "[Run 5] Epoch 04/40 | Train Acc: 0.090 | Val Acc: 0.102 | Train Loss: 3.3985 | Val Loss: 3.2162\n",
      "[Run 5] Epoch 04/40 | Train Acc: 0.090 | Val Acc: 0.102 | Train Loss: 3.3985 | Val Loss: 3.2162\n",
      "[Run 5] Epoch 05/40 | Train Acc: 0.118 | Val Acc: 0.138 | Train Loss: 3.2274 | Val Loss: 3.2526\n",
      "[Run 5] Epoch 05/40 | Train Acc: 0.118 | Val Acc: 0.138 | Train Loss: 3.2274 | Val Loss: 3.2526\n",
      "[Run 5] Epoch 06/40 | Train Acc: 0.142 | Val Acc: 0.160 | Train Loss: 3.0723 | Val Loss: 3.1945\n",
      "[Run 5] Epoch 06/40 | Train Acc: 0.142 | Val Acc: 0.160 | Train Loss: 3.0723 | Val Loss: 3.1945\n",
      "[Run 5] Epoch 07/40 | Train Acc: 0.169 | Val Acc: 0.125 | Train Loss: 2.9561 | Val Loss: 3.4166\n",
      "[Run 5] Epoch 07/40 | Train Acc: 0.169 | Val Acc: 0.125 | Train Loss: 2.9561 | Val Loss: 3.4166\n",
      "[Run 5] Epoch 08/40 | Train Acc: 0.187 | Val Acc: 0.170 | Train Loss: 2.8557 | Val Loss: 3.1217\n",
      "[Run 5] Epoch 08/40 | Train Acc: 0.187 | Val Acc: 0.170 | Train Loss: 2.8557 | Val Loss: 3.1217\n",
      "[Run 5] Epoch 09/40 | Train Acc: 0.231 | Val Acc: 0.253 | Train Loss: 2.6860 | Val Loss: 2.6634\n",
      "[Run 5] Epoch 09/40 | Train Acc: 0.231 | Val Acc: 0.253 | Train Loss: 2.6860 | Val Loss: 2.6634\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.247 | Val Acc: 0.263 | Train Loss: 2.6462 | Val Loss: 2.6292\n",
      "[Run 5] Epoch 10/40 | Train Acc: 0.247 | Val Acc: 0.263 | Train Loss: 2.6462 | Val Loss: 2.6292\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.272 | Val Acc: 0.273 | Train Loss: 2.5480 | Val Loss: 2.5913\n",
      "[Run 5] Epoch 11/40 | Train Acc: 0.272 | Val Acc: 0.273 | Train Loss: 2.5480 | Val Loss: 2.5913\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.293 | Val Acc: 0.278 | Train Loss: 2.4894 | Val Loss: 2.5560\n",
      "[Run 5] Epoch 12/40 | Train Acc: 0.293 | Val Acc: 0.278 | Train Loss: 2.4894 | Val Loss: 2.5560\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.310 | Val Acc: 0.258 | Train Loss: 2.4087 | Val Loss: 2.5285\n",
      "[Run 5] Epoch 13/40 | Train Acc: 0.310 | Val Acc: 0.258 | Train Loss: 2.4087 | Val Loss: 2.5285\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.312 | Val Acc: 0.312 | Train Loss: 2.3283 | Val Loss: 2.4915\n",
      "[Run 5] Epoch 14/40 | Train Acc: 0.312 | Val Acc: 0.312 | Train Loss: 2.3283 | Val Loss: 2.4915\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.330 | Val Acc: 0.328 | Train Loss: 2.2923 | Val Loss: 2.3926\n",
      "[Run 5] Epoch 15/40 | Train Acc: 0.330 | Val Acc: 0.328 | Train Loss: 2.2923 | Val Loss: 2.3926\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.346 | Val Acc: 0.228 | Train Loss: 2.2058 | Val Loss: 2.8615\n",
      "[Run 5] Epoch 16/40 | Train Acc: 0.346 | Val Acc: 0.228 | Train Loss: 2.2058 | Val Loss: 2.8615\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.389 | Val Acc: 0.407 | Train Loss: 2.1050 | Val Loss: 2.2162\n",
      "[Run 5] Epoch 17/40 | Train Acc: 0.389 | Val Acc: 0.407 | Train Loss: 2.1050 | Val Loss: 2.2162\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.413 | Val Acc: 0.320 | Train Loss: 2.0529 | Val Loss: 2.3413\n",
      "[Run 5] Epoch 18/40 | Train Acc: 0.413 | Val Acc: 0.320 | Train Loss: 2.0529 | Val Loss: 2.3413\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.429 | Val Acc: 0.357 | Train Loss: 1.9867 | Val Loss: 2.2600\n",
      "[Run 5] Epoch 19/40 | Train Acc: 0.429 | Val Acc: 0.357 | Train Loss: 1.9867 | Val Loss: 2.2600\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.422 | Val Acc: 0.360 | Train Loss: 1.9664 | Val Loss: 2.4245\n",
      "[Run 5] Epoch 20/40 | Train Acc: 0.422 | Val Acc: 0.360 | Train Loss: 1.9664 | Val Loss: 2.4245\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.448 | Val Acc: 0.422 | Train Loss: 1.9025 | Val Loss: 2.0285\n",
      "[Run 5] Epoch 21/40 | Train Acc: 0.448 | Val Acc: 0.422 | Train Loss: 1.9025 | Val Loss: 2.0285\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.464 | Val Acc: 0.375 | Train Loss: 1.8706 | Val Loss: 2.2227\n",
      "[Run 5] Epoch 22/40 | Train Acc: 0.464 | Val Acc: 0.375 | Train Loss: 1.8706 | Val Loss: 2.2227\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.438 | Val Acc: 0.427 | Train Loss: 1.8298 | Val Loss: 1.9948\n",
      "[Run 5] Epoch 23/40 | Train Acc: 0.438 | Val Acc: 0.427 | Train Loss: 1.8298 | Val Loss: 1.9948\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.485 | Val Acc: 0.427 | Train Loss: 1.7889 | Val Loss: 1.9478\n",
      "[Run 5] Epoch 24/40 | Train Acc: 0.485 | Val Acc: 0.427 | Train Loss: 1.7889 | Val Loss: 1.9478\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.501 | Val Acc: 0.448 | Train Loss: 1.7448 | Val Loss: 1.9631\n",
      "[Run 5] Epoch 25/40 | Train Acc: 0.501 | Val Acc: 0.448 | Train Loss: 1.7448 | Val Loss: 1.9631\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.518 | Val Acc: 0.475 | Train Loss: 1.6664 | Val Loss: 1.9550\n",
      "[Run 5] Epoch 26/40 | Train Acc: 0.518 | Val Acc: 0.475 | Train Loss: 1.6664 | Val Loss: 1.9550\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.530 | Val Acc: 0.487 | Train Loss: 1.6505 | Val Loss: 1.8646\n",
      "[Run 5] Epoch 27/40 | Train Acc: 0.530 | Val Acc: 0.487 | Train Loss: 1.6505 | Val Loss: 1.8646\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.533 | Val Acc: 0.487 | Train Loss: 1.6001 | Val Loss: 1.7842\n",
      "[Run 5] Epoch 28/40 | Train Acc: 0.533 | Val Acc: 0.487 | Train Loss: 1.6001 | Val Loss: 1.7842\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.542 | Val Acc: 0.427 | Train Loss: 1.5773 | Val Loss: 1.9734\n",
      "[Run 5] Epoch 29/40 | Train Acc: 0.542 | Val Acc: 0.427 | Train Loss: 1.5773 | Val Loss: 1.9734\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.548 | Val Acc: 0.468 | Train Loss: 1.5459 | Val Loss: 1.8589\n",
      "[Run 5] Epoch 30/40 | Train Acc: 0.548 | Val Acc: 0.468 | Train Loss: 1.5459 | Val Loss: 1.8589\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.549 | Val Acc: 0.443 | Train Loss: 1.5186 | Val Loss: 1.8761\n",
      "[Run 5] Epoch 31/40 | Train Acc: 0.549 | Val Acc: 0.443 | Train Loss: 1.5186 | Val Loss: 1.8761\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.572 | Val Acc: 0.468 | Train Loss: 1.4892 | Val Loss: 1.8209\n",
      "[Run 5] Epoch 32/40 | Train Acc: 0.572 | Val Acc: 0.468 | Train Loss: 1.4892 | Val Loss: 1.8209\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.599 | Val Acc: 0.497 | Train Loss: 1.4254 | Val Loss: 1.8233\n",
      "[Run 5] Epoch 33/40 | Train Acc: 0.599 | Val Acc: 0.497 | Train Loss: 1.4254 | Val Loss: 1.8233\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.605 | Val Acc: 0.482 | Train Loss: 1.3956 | Val Loss: 1.7269\n",
      "[Run 5] Epoch 34/40 | Train Acc: 0.605 | Val Acc: 0.482 | Train Loss: 1.3956 | Val Loss: 1.7269\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.596 | Val Acc: 0.512 | Train Loss: 1.4095 | Val Loss: 1.6855\n",
      "[Run 5] Epoch 35/40 | Train Acc: 0.596 | Val Acc: 0.512 | Train Loss: 1.4095 | Val Loss: 1.6855\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.623 | Val Acc: 0.510 | Train Loss: 1.3452 | Val Loss: 1.6772\n",
      "[Run 5] Epoch 36/40 | Train Acc: 0.623 | Val Acc: 0.510 | Train Loss: 1.3452 | Val Loss: 1.6772\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.637 | Val Acc: 0.480 | Train Loss: 1.3183 | Val Loss: 1.7318\n",
      "[Run 5] Epoch 37/40 | Train Acc: 0.637 | Val Acc: 0.480 | Train Loss: 1.3183 | Val Loss: 1.7318\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.625 | Val Acc: 0.485 | Train Loss: 1.3377 | Val Loss: 1.8042\n",
      "[Run 5] Epoch 38/40 | Train Acc: 0.625 | Val Acc: 0.485 | Train Loss: 1.3377 | Val Loss: 1.8042\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.632 | Val Acc: 0.475 | Train Loss: 1.3039 | Val Loss: 1.7827\n",
      "[Run 5] Epoch 39/40 | Train Acc: 0.632 | Val Acc: 0.475 | Train Loss: 1.3039 | Val Loss: 1.7827\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.649 | Val Acc: 0.490 | Train Loss: 1.2828 | Val Loss: 1.7889\n",
      "✅ [Run 5] Mejor Val Acc: 0.512\n",
      "[Run 5] Epoch 40/40 | Train Acc: 0.649 | Val Acc: 0.490 | Train Loss: 1.2828 | Val Loss: 1.7889\n",
      "✅ [Run 5] Mejor Val Acc: 0.512\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▂▂▃▂▃▄▄▄▄▄▅▅▄▆▅▆▆▇▆▇▇▇▇██▇▇▇▇██████▇█</td></tr><tr><td>val_f1_macro</td><td>▁▁▁▂▂▂▂▂▃▄▄▄▄▅▅▄▆▅▅▅▆▅▇▇▇▇█▇▇▇▇▇██████▇▇</td></tr><tr><td>val_f1_weighted</td><td>▁▁▁▂▂▂▂▂▃▄▄▄▄▅▅▄▆▅▅▅▆▅▇▇▇▇█▇▇▇▇▇██████▇▇</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▆▇▆▄▄▄▄▄▄▃▅▃▃▃▄▂▃▂▂▂▂▂▁▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▁▁▂▃▃▂▂▄▄▄▄▄▅▆▅▇▆▆▅▇▅▇▇▇█▇▇▇▇▇▇██████▇█</td></tr><tr><td>val_recall_macro</td><td>▁▁▁▂▂▃▂▃▄▄▄▄▄▅▅▄▆▅▆▆▇▆▇▇▇▇██▇▇▇▇██████▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.5125</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>lr</td><td>0.00017</td></tr><tr><td>train_acc</td><td>0.64917</td></tr><tr><td>train_loss</td><td>1.28283</td></tr><tr><td>val_acc</td><td>0.49</td></tr><tr><td>val_f1_macro</td><td>0.45799</td></tr><tr><td>val_f1_weighted</td><td>0.45799</td></tr><tr><td>val_loss</td><td>1.78888</td></tr><tr><td>val_precision_macro</td><td>0.53778</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_5_opt-SGD_lr-0.001_bs-8</strong> at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/kgvla8k7' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2/runs/kgvla8k7</a><br> View project at: <a href='https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2' target=\"_blank\">https://wandb.ai/javialroro-tecnologico-de-costa-rica/esc50-modelB-augmented2</a><br>Synced 5 W&B file(s), 40 media file(s), 80 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_145937-kgvla8k7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===========================================\n",
    "# ENTRENAMIENTO - MODELO B (ResNet-18 Audio)\n",
    "# Dataset: data/spectrograms1/augmented\n",
    "# Optimizado para GPUs pequeñas (≤ 4 GB)\n",
    "# ===========================================\n",
    "\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# ---- 0) Setup\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---- 1) Data\n",
    "DATA_DIR = \"data/spectrograms1/augmented\"\n",
    "IMG_SIZE = (224, 224)   \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(f\"{DATA_DIR}/val\",   transform=transform)\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "class_names = train_data.classes\n",
    "print(\"Clases:\", num_classes)\n",
    "\n",
    "# ---- 2) Experimentos\n",
    "experiments = [\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001,  \"batch_size\": 8,  \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.0005, \"batch_size\": 8,  \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"Adam\", \"lr\": 0.001,  \"batch_size\": 16, \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.01,   \"batch_size\": 8,  \"weight_decay\": 1e-4},\n",
    "    {\"optimizer\": \"SGD\",  \"lr\": 0.001,  \"batch_size\": 8,  \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "EPOCHS   = 40\n",
    "PATIENCE = 6\n",
    "\n",
    "# ---- 3) Loop multi-run\n",
    "for i, exp in enumerate(experiments, start=1):\n",
    "    # Cerrar cualquier run previo de W&B para evitar duplicados\n",
    "    if wandb.run is not None:\n",
    "        wandb.finish()\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"esc50-resnet18-augmented\",  # ← Nombre único del proyecto\n",
    "        name=f\"run_{i}_opt-{exp['optimizer']}_lr-{exp['lr']}_bs-{exp['batch_size']}\",\n",
    "        config=exp,\n",
    "        reinit=True  # Permite reinicialización si hay conflictos\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_data, batch_size=config.batch_size, shuffle=True, num_workers=2, pin_memory=True\n",
    "    )\n",
    "    val_loader   = DataLoader(\n",
    "        val_data,   batch_size=config.batch_size, shuffle=False, num_workers=2, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # --- Modelo B (tu ResNet-18)\n",
    "    model = resnet18_audio(num_classes=num_classes, in_channels=1, small_input=True).to(device)\n",
    "\n",
    "    # --- Criterio / Optimizador / Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "    scaler = GradScaler('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    # ---- Entrenamiento\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "\n",
    "        # ---- Validación\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        val_y_true, val_y_pred = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                \n",
    "                val_y_true.extend(labels.cpu().tolist())\n",
    "                val_y_pred.extend(preds.cpu().tolist())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss = val_loss / max(1, len(val_loader))\n",
    "\n",
    "        # --- Métricas adicionales\n",
    "        prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"macro\", zero_division=0\n",
    "        )\n",
    "        prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
    "            val_y_true, val_y_pred, average=\"weighted\", zero_division=0\n",
    "        )\n",
    "\n",
    "        scheduler.step()\n",
    "        torch.cuda.empty_cache()  # Liberar VRAM\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1_macro\": f1_m,\n",
    "            \"val_f1_weighted\": f1_w,\n",
    "            \"val_precision_macro\": prec_m,\n",
    "            \"val_recall_macro\": rec_m,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "            \"val_confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                y_true=val_y_true,\n",
    "                preds=val_y_pred,\n",
    "                class_names=class_names\n",
    "            )\n",
    "        })\n",
    "\n",
    "        print(f\"[Run {i}] Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # ---- Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/resnet18_audio_AUG_best_run{i}.pth\")\n",
    "            wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > PATIENCE:\n",
    "                print(f\"[Run {i}] Early stopping triggered at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ [Run {i}] Mejor Val Acc: {best_val_acc:.3f}\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2a743",
   "metadata": {},
   "source": [
    "# Evaluacion de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2655c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
